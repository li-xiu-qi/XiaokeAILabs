{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [00:07<00:00,  7.94s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>埃菲尔铁塔位于哪里？</td>\n",
       "      <td>[巴黎是法国的首都。]</td>\n",
       "      <td>埃菲尔铁塔位于巴黎。</td>\n",
       "      <td>埃菲尔铁塔位于巴黎。</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_input retrieved_contexts    response   reference  context_recall\n",
       "0  埃菲尔铁塔位于哪里？        [巴黎是法国的首都。]  埃菲尔铁塔位于巴黎。  埃菲尔铁塔位于巴黎。             1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from ragas.metrics import context_recall\n",
    "from ragas import evaluate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "# 从环境变量获取API密钥和基础URL\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "\n",
    "# 创建LLM实例\n",
    "llm = ChatOpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    "    model=\"Pro/deepseek-ai/DeepSeek-V3\"\n",
    ")\n",
    "\n",
    "# 创建Embedding模型实例\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    "    model=\"BAAI/bge-m3\"\n",
    ")\n",
    "\n",
    "# 准备数据样本\n",
    "data_samples = {\n",
    "    'user_input': ['埃菲尔铁塔位于哪里？'],\n",
    "    'response': ['埃菲尔铁塔位于巴黎。'],\n",
    "    'reference': ['埃菲尔铁塔位于巴黎。'],\n",
    "    'retrieved_contexts': [\n",
    "        ['巴黎是法国的首都。']\n",
    "    ]\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data_samples)\n",
    "\n",
    "# 评估上下文召回率\n",
    "score = evaluate(dataset, metrics=[context_recall], llm=llm, embeddings=embeddings)\n",
    "result = score.to_pandas()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [00:11<00:00, 11.90s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>context_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>埃菲尔铁塔在哪里？</td>\n",
       "      <td>[埃菲尔铁塔位于巴黎。]</td>\n",
       "      <td>埃菲尔铁塔位于巴黎。</td>\n",
       "      <td>埃菲尔铁塔位于巴黎，是法国的标志性建筑。</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_input retrieved_contexts    response             reference  \\\n",
       "0  埃菲尔铁塔在哪里？       [埃菲尔铁塔位于巴黎。]  埃菲尔铁塔位于巴黎。  埃菲尔铁塔位于巴黎，是法国的标志性建筑。   \n",
       "\n",
       "   context_precision  \n",
       "0                1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from ragas.metrics import context_precision\n",
    "from ragas import evaluate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 加载环境变量与模型设置（与上例相同）\n",
    "# ...\n",
    "\n",
    "# 准备数据样本\n",
    "data_samples = {\n",
    "    'user_input': ['埃菲尔铁塔在哪里？'],\n",
    "    'response': ['埃菲尔铁塔位于巴黎。'],\n",
    "    'reference': ['埃菲尔铁塔位于巴黎，是法国的标志性建筑。'],\n",
    "    'retrieved_contexts': [\n",
    "        ['埃菲尔铁塔位于巴黎。']\n",
    "    ]\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data_samples)\n",
    "\n",
    "# 评估上下文精确度\n",
    "score = evaluate(dataset, metrics=[context_precision], llm=llm, embeddings=embeddings)\n",
    "result = score.to_pandas()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 2/2 [00:14<00:00,  7.06s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>answer_correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>第一届超级碗是什么时候举行的？</td>\n",
       "      <td>第一届超级碗于1967年1月15日举行</td>\n",
       "      <td>第一届超级碗于1967年1月15日举行</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>谁赢得的超级碗最多？</td>\n",
       "      <td>新英格兰爱国者队赢得的超级碗最多</td>\n",
       "      <td>新英格兰爱国者队创纪录地六次赢得超级碗</td>\n",
       "      <td>0.609829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_input             response            reference  \\\n",
       "0  第一届超级碗是什么时候举行的？  第一届超级碗于1967年1月15日举行  第一届超级碗于1967年1月15日举行   \n",
       "1       谁赢得的超级碗最多？     新英格兰爱国者队赢得的超级碗最多  新英格兰爱国者队创纪录地六次赢得超级碗   \n",
       "\n",
       "   answer_correctness  \n",
       "0            1.000000  \n",
       "1            0.609829  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from ragas.metrics import answer_correctness\n",
    "from ragas import evaluate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings  \n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 加载环境变量与模型设置（与上例相同）\n",
    "# ...\n",
    "\n",
    "# 准备数据样本\n",
    "data_samples = {\n",
    "    'question': ['第一届超级碗是什么时候举行的？', '谁赢得的超级碗最多？'],\n",
    "    'answer': ['第一届超级碗于1967年1月15日举行', '新英格兰爱国者队赢得的超级碗最多'],\n",
    "    'ground_truth': ['第一届超级碗于1967年1月15日举行', '新英格兰爱国者队创纪录地六次赢得超级碗']\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data_samples)\n",
    "\n",
    "# 评估答案正确性\n",
    "score = evaluate(dataset, metrics=[answer_correctness], llm=llm, embeddings=embeddings)\n",
    "result = score.to_pandas()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "两个句子的余弦相似度: 0.9979\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 加载预训练的 BERT 模型和分词器\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 定义两个句子\n",
    "sentence1 = \"我喜欢看电影。\"\n",
    "sentence2 = \"我很享受看电影。\"\n",
    "\n",
    "# 对句子进行编码\n",
    "inputs1 = tokenizer(sentence1, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "inputs2 = tokenizer(sentence2, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "\n",
    "# 获取 BERT 输出\n",
    "with torch.no_grad():\n",
    "    outputs1 = model(**inputs1)\n",
    "    outputs2 = model(**inputs2)\n",
    "\n",
    "# 提取 [CLS] token 的表示（也可以用 mean pooling）\n",
    "cls_embedding1 = outputs1.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "cls_embedding2 = outputs2.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "\n",
    "# 计算余弦相似度\n",
    "cos_sim = np.dot(cls_embedding1, cls_embedding2) / (np.linalg.norm(cls_embedding1) * np.linalg.norm(cls_embedding2))\n",
    "print(f\"两个句子的余弦相似度: {cos_sim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建更全面的评估数据集\n",
    "eval_data = {\n",
    "    'user_input': [\n",
    "        '人工智能的三个主要分支是什么？',\n",
    "        '什么是向量数据库？它在RAG系统中有什么作用？',\n",
    "        '解释一下大语言模型的微调过程'\n",
    "    ],\n",
    "    'response': [\n",
    "        '人工智能的三个主要分支是机器学习、深度学习和自然语言处理。',\n",
    "        '向量数据库是专门存储和检索向量嵌入的数据库系统，在RAG系统中用于高效地检索语义相似的文档。',\n",
    "        '大语言模型的微调是在预训练模型的基础上，使用特定任务的数据进一步训练模型的过程。'\n",
    "    ],\n",
    "    'reference': [\n",
    "        '人工智能的三个主要分支是机器学习、自然语言处理和计算机视觉。',\n",
    "        '向量数据库是专门设计用于存储和检索向量嵌入的数据库系统。在RAG系统中，它用于存储文档的向量表示，并通过相似性搜索快速检索与查询最相关的文档。',\n",
    "        '大语言模型的微调是一个过程，其中预训练的基础模型使用特定领域或任务的数据进行额外训练，以优化其在特定应用场景的性能。'\n",
    "    ],\n",
    "    'retrieved_contexts': [\n",
    "        ['人工智能主要包括机器学习、深度学习、自然语言处理和计算机视觉等领域。'],\n",
    "        ['向量数据库是专门用于向量数据存储和检索的系统。在RAG应用中，向量数据库存储文档嵌入，通过计算相似度快速找到匹配查询的文档。'],\n",
    "        ['大语言模型微调是在已预训练的模型基础上，使用特定数据集进行额外训练的过程，目的是使模型适应特定任务或领域。']\n",
    "    ]\n",
    "}\n",
    "\n",
    "comprehensive_dataset = Dataset.from_dict(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'context_relevancy' from 'ragas.metrics' (c:\\Users\\k\\.conda\\envs\\XiaokeAILabs\\lib\\site-packages\\ragas\\metrics\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     context_recall,\n\u001b[0;32m      3\u001b[0m     context_precision,\n\u001b[0;32m      4\u001b[0m     answer_correctness,\n\u001b[0;32m      5\u001b[0m     answer_similarity,\n\u001b[0;32m      6\u001b[0m     answer_relevancy,\n\u001b[0;32m      7\u001b[0m     faithfulness,\n\u001b[0;32m      8\u001b[0m     context_relevancy\n\u001b[0;32m      9\u001b[0m     \n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 定义评估指标\u001b[39;00m\n\u001b[0;32m     13\u001b[0m metrics \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     14\u001b[0m     faithfulness,\n\u001b[0;32m     15\u001b[0m     answer_relevancy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     context_recall,\n\u001b[0;32m     20\u001b[0m ]\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'context_relevancy' from 'ragas.metrics' (c:\\Users\\k\\.conda\\envs\\XiaokeAILabs\\lib\\site-packages\\ragas\\metrics\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from ragas.metrics import (\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness,\n",
    "    answer_similarity,\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    \n",
    ")\n",
    "\n",
    "# 定义评估指标\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    answer_similarity,\n",
    "    answer_correctness,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "]\n",
    "\n",
    "# 综合评估\n",
    "comprehensive_score = evaluate(\n",
    "    comprehensive_dataset,\n",
    "    metrics=metrics,\n",
    "    llm=llm,\n",
    "    embeddings=embeddings\n",
    ")\n",
    "\n",
    "# 结果分析\n",
    "result_df = comprehensive_score.to_pandas()\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XiaokeAILabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
