# ä½œè€…: ç­±å¯
# æ—¥æœŸ: 2025 å¹´ 2 æœˆ 11 æ—¥
# ç‰ˆæƒæ‰€æœ‰ (c) 2025 ç­±å¯ & ç­±å¯AIç ”ä¹ ç¤¾. ä¿ç•™æ‰€æœ‰æƒåˆ©.
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


from datetime import datetime

import os
import openai
from openai import OpenAI
import streamlit as st
import fitz  # PyMuPDF
from io import BytesIO
from dotenv import load_dotenv


import os


def find_dotenv_path(dir_name: str = "XiaokeAILabs"):
    # é¦–å…ˆåœ¨å½“å‰å·¥ä½œç›®å½•ä¸‹æŸ¥æ‰¾ .env æ–‡ä»¶
    current_working_dir = os.getcwd()
    env_path = os.path.join(current_working_dir, ".env")
    if os.path.exists(env_path):
        return env_path

    # å¦‚æœæ²¡æœ‰æŒ‡å®šç›®å½•åï¼Œä¸”å½“å‰å·¥ä½œç›®å½•ä¸‹æ²¡æœ‰ .env æ–‡ä»¶ï¼Œåˆ™è¿”å› None
    if not dir_name:
        return None

    # ä»å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•å¼€å§‹å‘ä¸ŠæŸ¥æ‰¾æŒ‡å®šç›®å½•
    current_dir = os.path.dirname(os.path.abspath(__file__))
    while True:
        # æ£€æŸ¥å½“å‰ç›®å½•æ˜¯å¦ä¸ºæŒ‡å®šç›®å½•
        if os.path.basename(current_dir) == dir_name:
            # åœ¨æŒ‡å®šç›®å½•ä¸‹æŸ¥æ‰¾ .env æ–‡ä»¶
            env_path_in_specified_dir = os.path.join(current_dir, ".env")
            if os.path.exists(env_path_in_specified_dir):
                return env_path_in_specified_dir
            else:
                return None
        # åˆ°è¾¾æ ¹ç›®å½•æ—¶åœæ­¢æŸ¥æ‰¾
        if current_dir == os.path.dirname(current_dir):
            break
        # å‘ä¸Šç§»åŠ¨ä¸€å±‚ç›®å½•
        current_dir = os.path.dirname(current_dir)

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æŒ‡å®šç›®å½•ï¼Œè¿”å› None
    return None


DOT_ENV_PATH = find_dotenv_path()
load_dotenv(dotenv_path=DOT_ENV_PATH)
api_key = os.getenv("API_KEY")
base_url = os.getenv("BASE_URL")
client = OpenAI(api_key=api_key, base_url=base_url)

# æ¨¡å‹åˆ—è¡¨
model_list = {
    "DeepSeek-R1-1.5B": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
    "DeepSeek-R1": "deepseek-ai/DeepSeek-R1",
    "DeepSeek-V3": "deepseek-ai/DeepSeek-V3",
}


# åˆå§‹åŒ– session_state
def init_session():
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "uploaded_content" not in st.session_state:
        st.session_state.uploaded_content = None
    if "context_length" not in st.session_state:
        st.session_state.context_length = 12000
    if "file_content_length" not in st.session_state:
        st.session_state.file_content_length = 15000


init_session()
AUTHOR = "ç­±å¯"
CURRENT_DATE = datetime.now().strftime("%Y-%m-%d")
WECHAT_PLATFORM = "ç­±å¯AIç ”ä¹ ç¤¾"


# æ–‡ä»¶å¤„ç†å‡½æ•°
def process_uploaded_file(uploaded_file):
    try:
        content = ""
        if uploaded_file.type == "application/pdf":
            # å¤„ç†PDFæ–‡ä»¶
            doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
            for page in doc:
                content += page.get_text()
        else:
            # å¤„ç†æ–‡æœ¬æ–‡ä»¶
            content = uploaded_file.getvalue().decode("utf-8")

        # æˆªå–å‰ file_content_length ä¸ªå­—ç¬¦
        max_length = st.session_state.file_content_length
        return content[:max_length] + "..." if len(content) > max_length else content

    except Exception as e:
        st.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
        return None


# ä¾§è¾¹æ è®¾ç½®
with st.sidebar:
    st.header("é…ç½®å‚æ•°")
    selected_model = st.selectbox("é€‰æ‹©æ¨¡å‹", options=list(model_list.keys()), index=2)
    temperature = st.slider("æ¸©åº¦å‚æ•°", 0.0, 1.0, 0.3, 0.1)
    max_tokens = st.slider("æœ€å¤§é•¿åº¦", 100, 4096, 2048, 100)
    st.session_state.context_length = st.slider("ä¸Šä¸‹æ–‡é•¿åº¦", 1000, 100000, 32000, 500)
    st.session_state.file_content_length = st.slider(
        "æ–‡ä»¶å†…å®¹è¯»å–é•¿åº¦", 1000, 100000, 15000, 500
    )

    # æ–°å»ºå¯¹è¯æŒ‰é’®
    if st.button("æ–°å»ºå¯¹è¯"):
        st.session_state.messages = []
        st.session_state.uploaded_content = None
        st.session_state.current_file = None
        st.success("æ–°å¯¹è¯å·²åˆ›å»ºï¼")

st.title("ğŸ“‘ DeepSeek æ™ºèƒ½æ–‡æ¡£åŠ©æ‰‹ âœ¨")

st.markdown(
    """<hr style="border:2px solid #FFA07A; border-radius: 5px;">""",
    unsafe_allow_html=True,
)

st.markdown(
    f"""
    <div style='
        text-align: center;
        padding: 15px;
        background: linear-gradient(45deg, #FFD700, #FFA07A);
        border-radius: 15px;
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        margin: 20px 0;
    '>
        <h4 style='color: #2F4F4F; margin: 0;'>ğŸ° ä½œè€…ï¼š{AUTHOR}</h4>
        <p style='color: #800080; margin: 10px 0 0;'>
            ğŸŒ¸ å…¬ä¼—å·ï¼šã€Œ<strong style='color: #FF4500;'>{WECHAT_PLATFORM}</strong>ã€
            <br>
            <span style='font-size:14px; color: #4682B4;'>âœ¨ æ¢ç´¢AIçš„æ— é™å¯èƒ½ âœ¨</span>
        </p>
    </div>
    """,
    unsafe_allow_html=True,
)

if "first_load" not in st.session_state:
    st.balloons()
    st.session_state.first_load = True


# æ–‡ä»¶ä¸Šä¼ éƒ¨ä»¶
uploaded_file = st.file_uploader("ä¸Šä¼ æ–‡æ¡£ï¼ˆæ”¯æŒPDF/TXTï¼‰", type=["pdf", "txt"])
if uploaded_file and uploaded_file != st.session_state.get("current_file"):
    processed_content = process_uploaded_file(uploaded_file)
    if processed_content:
        st.session_state.uploaded_content = processed_content
        st.session_state.current_file = uploaded_file

        # æ„å»ºCRISPEæ¡†æ¶ç³»ç»Ÿæç¤º
        system_prompt = f"""
<system>
    [å½“å‰æ—¥æœŸ] {CURRENT_DATE}
    [è§’è‰²] æ‚¨æ˜¯ä¸€åä¸“ä¸šçš„æ–‡æ¡£åˆ†æåŠ©ç†ï¼Œæ“…é•¿ä»æŠ€æœ¯æ–‡æ¡£ä¸­æå–å…³é”®ä¿¡æ¯
    
    [èƒŒæ™¯] 
    - ç”¨æˆ·ä¸Šä¼ äº†æ–‡æ¡£ï¼š{uploaded_file.name}
    - æ–‡æ¡£ç±»å‹ï¼š{uploaded_file.type.split('/')[-1].upper()}
    - æ–‡æ¡£å†…å®¹ï¼š{processed_content[:st.session_state.file_content_length]}...
    
    [æ ¸å¿ƒä»»åŠ¡]
    1. å½“ç”¨æˆ·æé—®æ—¶ï¼Œä¼˜å…ˆä»æ–‡æ¡£ä¸­å¯»æ‰¾ç­”æ¡ˆ
    2. å¯¹å¤æ‚é—®é¢˜è¿›è¡Œåˆ†æ­¥éª¤æ€è€ƒ
    3. ä¸è¦ç”Ÿæˆæ–‡æ¡£æ²¡æœ‰æä¾›çš„ä¿¡æ¯
    4. ä¿æŒä¸“ä¸šä¸”æ˜“æ‡‚çš„è¯­æ°”
    5. ä¸ç¡®å®šæ—¶ï¼Œå¯ä»¥è¯·æ±‚ç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯

    
    [äº¤äº’è¦æ±‚]
    - ä¿æŒä¸“ä¸šä¸”æ˜“æ‡‚çš„è¯­æ°”
    - å…³é”®æ•°æ®ç”¨**åŠ ç²—**æ˜¾ç¤º
    - ä»£ç å—ä½¿ç”¨```åŒ…è£¹
</system>
        """
        # æ¸…ç©ºå†å²æ¶ˆæ¯
        st.session_state.messages = [{"role": "system", "content": system_prompt}]
        st.success(f"æ–‡æ¡£ {uploaded_file.name} è§£æå®Œæˆï¼")
else:
    # é»˜è®¤ç³»ç»Ÿæç¤ºè¯æ¨¡æ¿
    default_system_prompt = f"""
    <system>
        [å½“å‰æ—¥æœŸ] {CURRENT_DATE}
        [è§’è‰²] æ‚¨æ˜¯ä¸€åä¸“ä¸šçš„æ–‡æ¡£åˆ†æåŠ©ç†ã€‚
        
        [æ ¸å¿ƒä»»åŠ¡]
        1. å½“ç”¨æˆ·æé—®æ—¶ï¼Œå¯ä»¥è¯¢é—®ç”¨æˆ·æ˜¯å¦éœ€è¦æä¾›èµ„æ–™å¢å¼ºå›ç­”
        2. å¯¹å¤æ‚é—®é¢˜è¿›è¡Œåˆ†æ­¥éª¤æ€è€ƒ
        3. ä¸è¦ç”Ÿæˆæ–‡æ¡£æ²¡æœ‰æä¾›çš„ä¿¡æ¯
        4. ä¿æŒä¸“ä¸šä¸”æ˜“æ‡‚çš„è¯­æ°”
        5. ä¸ç¡®å®šæ—¶ï¼Œå¯ä»¥è¯·æ±‚ç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯
    
        
        [äº¤äº’è¦æ±‚]
        - ä¿æŒä¸“ä¸šä¸”æ˜“æ‡‚çš„è¯­æ°”
        - å…³é”®æ•°æ®ç”¨**åŠ ç²—**æ˜¾ç¤º
        - ä»£ç å—ä½¿ç”¨```åŒ…è£¹
    </system>
    """
    if not st.session_state.messages:
        st.session_state.messages = [
            {"role": "system", "content": default_system_prompt}
        ]

# èŠå¤©è®°å½•æ˜¾ç¤º
for msg in st.session_state.messages:
    if msg["role"] != "system":
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

# ç”¨æˆ·è¾“å…¥å¤„ç†
if prompt := st.chat_input("è¯·è¾“å…¥é—®é¢˜..."):
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # æ„å»ºAPIè¯·æ±‚
    keep_messages = 10
    system_message = st.session_state.messages[0]  # ä¿ç•™ç¬¬ä¸€ä¸ªsystemæ¶ˆæ¯
    messages_for_api = [
        {"role": m["role"], "content": m["content"]}
        for m in st.session_state.messages
        if m["role"] != "system"
    ]

    # æˆªæ–­ä¸Šä¸‹æ–‡ä»¥æ»¡è¶³ä¸Šä¸‹æ–‡é•¿åº¦è¦æ±‚
    total_length = sum(len(m["content"]) for m in messages_for_api)
    while total_length > st.session_state.context_length:
        messages_for_api.pop(0)
        total_length = sum(len(m["content"]) for m in messages_for_api)

    messages_for_api.insert(0, system_message)  # å°†systemæ¶ˆæ¯é‡æ–°æ’å…¥åˆ°ç¬¬ä¸€æ¡

    try:
        # ç”Ÿæˆæµå¼å›å¤
        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            collected_response = []

            response = client.chat.completions.create(
                model=model_list[selected_model],
                messages=messages_for_api,
                stream=True,
                temperature=temperature,
                max_tokens=max_tokens,
            )

            for chunk in response:
                if chunk.choices[0].delta.content:
                    token = chunk.choices[0].delta.content
                    collected_response.append(token)
                    response_placeholder.markdown("".join(collected_response) + "â–Œ")

            final_response = "".join(collected_response)
            response_placeholder.markdown(final_response)

            # æ›´æ–°æ¶ˆæ¯è®°å½•
            st.session_state.messages.append(
                {"role": "assistant", "content": final_response}
            )

    except openai.APIError as e:
        error_msg = f"""
        <error>
            [é”™è¯¯åˆ†æ]
            APIè¯·æ±‚å¤±è´¥ï¼Œå¯èƒ½åŸå› ï¼š
            1. ä¸Šä¸‹æ–‡è¿‡é•¿ï¼ˆå½“å‰ï¼š{len(str(messages_for_api))}å­—ç¬¦ï¼‰
            
            [ä¿®æ­£å»ºè®®]
            è¯·å°è¯•ä»¥ä¸‹æ“ä½œï¼š
            - è°ƒæ•´ä¸Šä¸‹æ–‡é•¿åº¦è‡³16000å­—ç¬¦å†…
            - é‡æ–°ç»„ç»‡é—®é¢˜è¡¨è¿°
            - æ–°å»ºå¯¹è¯ä»¥é‡è¯•
        </error>
        """
        st.error(error_msg, icon="ğŸš¨")
