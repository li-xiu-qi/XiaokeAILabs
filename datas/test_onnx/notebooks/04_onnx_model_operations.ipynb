{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2558c08e",
   "metadata": {},
   "source": [
    "# ONNX教程 - 第4部分：ONNX模型的基本操作\n",
    "\n",
    "这个notebook展示如何读取、分析、可视化和修改ONNX模型。本教程将引导您完成以下步骤：\n",
    "\n",
    "1. 检查ONNX安装\n",
    "2. 加载和验证ONNX模型\n",
    "3. 探索模型元数据\n",
    "4. 分析模型图结构\n",
    "5. 提取特定节点信息\n",
    "6. 修改模型元数据\n",
    "7. 将模型转换为文本格式\n",
    "8. 可视化模型\n",
    "\n",
    "让我们开始吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8fe7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import onnx\n",
    "from onnx import helper, shape_inference\n",
    "from onnx import AttributeProto, TensorProto, GraphProto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8becc6",
   "metadata": {},
   "source": [
    "## 1. 检查ONNX安装\n",
    "\n",
    "首先，我们需要确保已正确安装ONNX及相关工具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb6ba080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX库已成功安装，版本：1.17.0\n",
      "ONNX Runtime已成功安装，版本：1.21.0\n",
      "Netron已成功安装，可用于可视化ONNX模型。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_onnx_installation():\n",
    "    \"\"\"检查ONNX库是否正确安装\"\"\"\n",
    "    try:\n",
    "        import onnx\n",
    "        print(f\"ONNX库已成功安装，版本：{onnx.__version__}\")\n",
    "        \n",
    "        # 检查ONNX Runtime\n",
    "        try:\n",
    "            import onnxruntime\n",
    "            print(f\"ONNX Runtime已成功安装，版本：{onnxruntime.__version__}\")\n",
    "        except ImportError:\n",
    "            print(\"警告：未安装ONNX Runtime，将无法执行推理。可使用 'pip install onnxruntime' 安装。\")\n",
    "        \n",
    "        # 检查可视化工具\n",
    "        try:\n",
    "            import netron\n",
    "            print(f\"Netron已成功安装，可用于可视化ONNX模型。\")\n",
    "        except ImportError:\n",
    "            print(\"提示：未安装Netron，无法进行图形化可视化。可使用 'pip install netron' 安装。\")\n",
    "        \n",
    "        return True\n",
    "    except ImportError:\n",
    "        print(\"错误：未安装ONNX库。请使用 'pip install onnx' 安装。\")\n",
    "        return False\n",
    "\n",
    "# 运行检查\n",
    "check_onnx_installation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e63503",
   "metadata": {},
   "source": [
    "## 2. 加载与验证模型\n",
    "\n",
    "接下来，我们将加载一个ONNX模型，并验证其格式是否正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f21a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载ONNX模型：./models/mnist_cnn.onnx\n",
      "验证ONNX模型格式...\n",
      "✓ 模型格式验证通过！\n",
      "正在进行形状推断...\n",
      "✓ 形状推断完成！\n"
     ]
    }
   ],
   "source": [
    "def load_and_validate_model(model_path):\n",
    "    \"\"\"加载并验证ONNX模型\"\"\"\n",
    "    try:\n",
    "        # 加载ONNX模型\n",
    "        print(f\"正在加载ONNX模型：{model_path}\")\n",
    "        model = onnx.load(model_path)\n",
    "        \n",
    "        # 检查模型是否格式正确\n",
    "        print(\"验证ONNX模型格式...\")\n",
    "        onnx.checker.check_model(model)\n",
    "        print(\"✓ 模型格式验证通过！\")\n",
    "        \n",
    "        # 运行形状推断，确保所有中间张量的形状都已知\n",
    "        print(\"正在进行形状推断...\")\n",
    "        inferred_model = shape_inference.infer_shapes(model)\n",
    "        print(\"✓ 形状推断完成！\")\n",
    "        \n",
    "        return model\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误：找不到模型文件 {model_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"错误：加载或验证模型时出错：{str(e)}\")\n",
    "        return None\n",
    "\n",
    "# 设置ONNX模型路径\n",
    "model_path = './models/mnist_cnn.onnx'\n",
    "\n",
    "# 创建models目录（如果不存在）\n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "\n",
    "# 加载模型\n",
    "model = load_and_validate_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491ca325",
   "metadata": {},
   "source": [
    "## 3. 探索模型元数据\n",
    "\n",
    "了解模型的基本信息，如版本、生产者和文档。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d92a7349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ONNX模型元数据\n",
      "==================================================\n",
      "IR版本：7\n",
      "Opset版本：12\n",
      "生产者名称：pytorch\n",
      "生产者版本：2.6.0\n",
      "模型版本：0\n"
     ]
    }
   ],
   "source": [
    "def explore_model_metadata(model):\n",
    "    \"\"\"探索ONNX模型的元数据\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"ONNX模型元数据\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 显示IR版本\n",
    "    print(f\"IR版本：{model.ir_version}\")\n",
    "    print(f\"Opset版本：{model.opset_import[0].version}\")\n",
    "    \n",
    "    # 显示生产者信息\n",
    "    print(f\"生产者名称：{model.producer_name}\")\n",
    "    print(f\"生产者版本：{model.producer_version}\")\n",
    "    \n",
    "    # 显示模型版本\n",
    "    print(f\"模型版本：{model.model_version}\")\n",
    "    \n",
    "    # 显示文档字符串\n",
    "    if model.doc_string:\n",
    "        print(f\"\\n模型文档：\\n{model.doc_string}\")\n",
    "    \n",
    "    # 检查并显示自定义元数据\n",
    "    if len(model.metadata_props) > 0:\n",
    "        print(\"\\n自定义元数据：\")\n",
    "        for prop in model.metadata_props:\n",
    "            print(f\"  - {prop.key}: {prop.value}\")\n",
    "\n",
    "# 探索模型元数据\n",
    "if model is not None:\n",
    "    explore_model_metadata(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c934c3",
   "metadata": {},
   "source": [
    "## 4. 分析模型图结构\n",
    "\n",
    "深入了解模型的计算图，包括输入、输出、计算节点和权重等信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67f4711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_model_graph(model):\n",
    "    \"\"\"分析ONNX模型的计算图结构\"\"\"\n",
    "    graph = model.graph\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"ONNX模型图结构分析\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 分析输入\n",
    "    print(\"\\n输入节点：\")\n",
    "    for i, input_node in enumerate(graph.input):\n",
    "        print(f\"  [{i}] 名称：{input_node.name}\")\n",
    "        # 获取输入形状\n",
    "        shape_info = []\n",
    "        if hasattr(input_node.type.tensor_type, 'shape'):\n",
    "            for dim in input_node.type.tensor_type.shape.dim:\n",
    "                if dim.dim_param:\n",
    "                    shape_info.append(dim.dim_param)\n",
    "                else:\n",
    "                    shape_info.append(dim.dim_value)\n",
    "        print(f\"      形状：{shape_info}\")\n",
    "        print(f\"      数据类型：{TensorProto.DataType.Name(input_node.type.tensor_type.elem_type)}\")\n",
    "    \n",
    "    # 分析输出\n",
    "    print(\"\\n输出节点：\")\n",
    "    for i, output_node in enumerate(graph.output):\n",
    "        print(f\"  [{i}] 名称：{output_node.name}\")\n",
    "        # 获取输出形状\n",
    "        shape_info = []\n",
    "        if hasattr(output_node.type.tensor_type, 'shape'):\n",
    "            for dim in output_node.type.tensor_type.shape.dim:\n",
    "                if dim.dim_param:\n",
    "                    shape_info.append(dim.dim_param)\n",
    "                else:\n",
    "                    shape_info.append(dim.dim_value)\n",
    "        print(f\"      形状：{shape_info}\")\n",
    "        print(f\"      数据类型：{TensorProto.DataType.Name(output_node.type.tensor_type.elem_type)}\")\n",
    "    \n",
    "    # 分析节点\n",
    "    print(f\"\\n计算节点总数：{len(graph.node)}\")\n",
    "    op_type_counts = {}\n",
    "    for node in graph.node:\n",
    "        if node.op_type in op_type_counts:\n",
    "            op_type_counts[node.op_type] += 1\n",
    "        else:\n",
    "            op_type_counts[node.op_type] = 1\n",
    "    \n",
    "    print(\"\\n操作类型统计：\")\n",
    "    for op_type, count in sorted(op_type_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  - {op_type}: {count}\")\n",
    "    \n",
    "    # 分析权重（初始化器）\n",
    "    print(f\"\\n权重（初始化器）总数：{len(graph.initializer)}\")\n",
    "    total_params = 0\n",
    "    for initializer in graph.initializer:\n",
    "        size = 1\n",
    "        for dim in initializer.dims:\n",
    "            size *= dim\n",
    "        total_params += size\n",
    "    \n",
    "    print(f\"总参数数量：{total_params:,}\")\n",
    "    \n",
    "    # 内存占用估计（粗略计算）\n",
    "    memory_bytes = total_params * 4  # 假设使用float32（4字节）\n",
    "    print(f\"估计内存占用：{memory_bytes / (1024*1024):.2f} MB\")\n",
    "\n",
    "# 分析模型图结构\n",
    "if model is not None:\n",
    "    analyze_model_graph(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c010488",
   "metadata": {},
   "source": [
    "## 5. 提取特定节点信息\n",
    "\n",
    "查找并提取模型中特定节点的详细信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70bc3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attribute_value(attr):\n",
    "    \"\"\"获取节点属性值的辅助函数\"\"\"\n",
    "    if attr.type == AttributeProto.FLOAT:\n",
    "        return attr.f\n",
    "    elif attr.type == AttributeProto.INT:\n",
    "        return attr.i\n",
    "    elif attr.type == AttributeProto.STRING:\n",
    "        return attr.s\n",
    "    elif attr.type == AttributeProto.TENSOR:\n",
    "        return \"<tensor>\"\n",
    "    elif attr.type == AttributeProto.FLOATS:\n",
    "        return list(attr.floats)\n",
    "    elif attr.type == AttributeProto.INTS:\n",
    "        return list(attr.ints)\n",
    "    elif attr.type == AttributeProto.STRINGS:\n",
    "        return list(attr.strings)\n",
    "    else:\n",
    "        return f\"<未知类型：{attr.type}>\"\n",
    "\n",
    "def extract_node_by_name(model, node_name):\n",
    "    \"\"\"通过名称查找并提取特定节点的信息\"\"\"\n",
    "    graph = model.graph\n",
    "    found = False\n",
    "    \n",
    "    # 在所有节点中查找\n",
    "    for node in graph.node:\n",
    "        if node.name == node_name or node_name in node.output:\n",
    "            found = True\n",
    "            print(f\"\\n找到节点：{node.name}\")\n",
    "            print(f\"操作类型：{node.op_type}\")\n",
    "            print(f\"输入：{node.input}\")\n",
    "            print(f\"输出：{node.output}\")\n",
    "            \n",
    "            # 显示属性\n",
    "            if len(node.attribute) > 0:\n",
    "                print(\"属性：\")\n",
    "                for attr in node.attribute:\n",
    "                    print(f\"  - {attr.name}: {get_attribute_value(attr)}\")\n",
    "    \n",
    "    if not found:\n",
    "        print(f\"\\n未找到名称为 '{node_name}' 的节点\")\n",
    "        \n",
    "        # 帮助用户找到可用节点\n",
    "        print(\"可用的节点输出名称有：\")\n",
    "        for node in graph.node[:10]:  # 只显示前10个，避免过多输出\n",
    "            if node.output:\n",
    "                print(f\"  - {node.output[0]} (操作类型: {node.op_type})\")\n",
    "        if len(graph.node) > 10:\n",
    "            print(f\"  ... 以及更多 {len(graph.node)-10} 个节点\")\n",
    "\n",
    "# 提取特定节点信息\n",
    "if model is not None:\n",
    "    # 尝试提取输出节点\n",
    "    extract_node_by_name(model, \"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3104e213",
   "metadata": {},
   "source": [
    "## 6. 修改模型元数据\n",
    "\n",
    "展示如何修改ONNX模型的元数据，并保存为新模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f366368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_model_metadata(model, output_path):\n",
    "    \"\"\"修改ONNX模型的元数据\"\"\"\n",
    "    # 添加描述\n",
    "    model.doc_string = \"这是在ONNX教程中修改过的MNIST模型\"\n",
    "    \n",
    "    # 添加自定义元数据属性\n",
    "    metadata_props = {\"修改时间\": \"2025-04-05\", \"修改者\": \"XiaokeAILabs\", \"用途\": \"教学演示\"}\n",
    "    for key, value in metadata_props.items():\n",
    "        meta = model.metadata_props.add()\n",
    "        meta.key = key\n",
    "        meta.value = value\n",
    "    \n",
    "    # 保存修改后的模型\n",
    "    onnx.save(model, output_path)\n",
    "    print(f\"\\n已修改模型元数据并保存到：{output_path}\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# 修改模型元数据\n",
    "if model is not None:\n",
    "    modified_model_path = '../models/mnist_cnn_modified.onnx'\n",
    "    modify_model_metadata(model, modified_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d74d35a",
   "metadata": {},
   "source": [
    "## 7. 将模型转换为文本格式\n",
    "\n",
    "将ONNX模型转换为可读的文本格式，便于检查和理解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bf0c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_model_to_text(model_path, output_path=None):\n",
    "    \"\"\"将ONNX模型转换为可读文本格式\"\"\"\n",
    "    model = onnx.load(model_path)\n",
    "    \n",
    "    if output_path is None:\n",
    "        output_path = os.path.splitext(model_path)[0] + \".txt\"\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(str(model))\n",
    "    \n",
    "    print(f\"\\n已将模型转换为文本格式并保存到：{output_path}\")\n",
    "    print(f\"文本文件大小：{os.path.getsize(output_path) / 1024:.2f} KB\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# 将修改后的模型转换为文本格式\n",
    "if model is not None and 'modified_model_path' in locals():\n",
    "    text_file_path = convert_model_to_text(modified_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe966204",
   "metadata": {},
   "source": [
    "## 8. 可视化模型\n",
    "\n",
    "使用Netron工具可视化ONNX模型，提供直观的图形界面。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59625778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model_path):\n",
    "    \"\"\"使用Netron可视化ONNX模型\"\"\"\n",
    "    try:\n",
    "        import netron\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ONNX模型可视化\")\n",
    "        print(\"=\" * 50)\n",
    "        print(\"\\n正在启动Netron服务器来可视化模型...\")\n",
    "        print(\"请在网页浏览器中查看模型（通常会自动打开）\")\n",
    "        print(\"完成查看后，请在此Notebook的'Kernel'菜单中选择'Interrupt Kernel'来终止服务器\")\n",
    "        \n",
    "        # 启动Netron服务器\n",
    "        netron.start(model_path)\n",
    "    except ImportError:\n",
    "        print(\"\\n无法可视化模型：未安装Netron。\")\n",
    "        print(\"请使用 'pip install netron' 安装Netron后再尝试。\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n可视化模型时出错：{str(e)}\")\n",
    "\n",
    "# 可视化修改后的模型\n",
    "# 注意：这将启动一个阻塞的Web服务器，需要手动中断内核来停止\n",
    "# 取消以下代码的注释以运行可视化\n",
    "# if model is not None and 'modified_model_path' in locals():\n",
    "#     visualize_model(modified_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963993ce",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "在本教程中，我们学习了如何：\n",
    "\n",
    "1. 检查ONNX及相关库的安装\n",
    "2. 加载和验证ONNX模型\n",
    "3. 探索模型的元数据\n",
    "4. 分析模型的计算图结构\n",
    "5. 提取特定节点的信息\n",
    "6. 修改模型的元数据\n",
    "7. 将模型转换为可读文本格式\n",
    "8. 使用Netron可视化模型\n",
    "\n",
    "这些技能对于理解、调试和修改ONNX模型非常有用，尤其是在模型部署和优化阶段。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyonnx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
