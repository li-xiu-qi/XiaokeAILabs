{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3edb9db9",
   "metadata": {},
   "source": [
    "# ONNX教程 - 第3部分：从PyTorch导出ONNX模型\n",
    "\n",
    "本notebook演示如何将PyTorch模型导出为ONNX格式，包括以下步骤：\n",
    "\n",
    "1. 加载PyTorch模型\n",
    "2. 解释ONNX导出参数\n",
    "3. 将模型导出为ONNX格式\n",
    "4. 验证ONNX模型格式\n",
    "5. 比较PyTorch和ONNX模型的输出\n",
    "\n",
    "让我们开始吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5327dee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270ee7b3",
   "metadata": {},
   "source": [
    "## 1. 定义和加载PyTorch模型\n",
    "\n",
    "首先，我们需要定义与训练时相同的模型结构，然后加载保存的权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcefc34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新定义模型结构（与训练时保持一致）\n",
    "class MNISTModel(nn.Module):\n",
    "    \"\"\"MNIST手写数字识别模型\"\"\"\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 7 * 7 * 64)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ed0e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pytorch_model(model_path):\n",
    "    \"\"\"加载已保存的PyTorch模型\"\"\"\n",
    "    # 创建模型实例\n",
    "    model = MNISTModel()\n",
    "    \n",
    "    # 加载模型权重\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "        print(f\"PyTorch模型成功从{model_path}加载\")\n",
    "    except Exception as e:\n",
    "        print(f\"加载模型时出错: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # 设置为评估模式\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# 设置文件路径\n",
    "pytorch_model_path = '../models/mnist_cnn.pth'\n",
    "onnx_model_path = '../models/mnist_cnn.onnx'\n",
    "\n",
    "# 确保目录存在\n",
    "os.makedirs(os.path.dirname(pytorch_model_path), exist_ok=True)\n",
    "\n",
    "# 加载PyTorch模型\n",
    "pytorch_model = load_pytorch_model(pytorch_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897d718d",
   "metadata": {},
   "source": [
    "## 2. 解释ONNX导出参数\n",
    "\n",
    "在导出模型前，我们先了解一下`torch.onnx.export`函数的主要参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f5c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_export_parameters():\n",
    "    \"\"\"解释torch.onnx.export的主要参数\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"torch.onnx.export 主要参数说明\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    parameters = [\n",
    "        (\"model\", \"要导出的PyTorch模型\"),\n",
    "        (\"args\", \"模型的输入参数(通常是一个样例输入张量)\"),\n",
    "        (\"f\", \"输出文件路径或类文件对象\"),\n",
    "        (\"export_params\", \"如果为True，将导出模型参数；如果为False，则只导出模型结构\"),\n",
    "        (\"opset_version\", \"导出模型使用的ONNX版本，默认为9\"),\n",
    "        (\"do_constant_folding\", \"如果为True，在导出期间执行常量折叠优化\"),\n",
    "        (\"input_names\", \"模型输入的名称列表\"),\n",
    "        (\"output_names\", \"模型输出的名称列表\"),\n",
    "        (\"dynamic_axes\", \"指定动态轴的字典，例如批处理维度\"),\n",
    "        (\"verbose\", \"如果为True，打印导出过程的详细信息\")\n",
    "    ]\n",
    "    \n",
    "    for param, desc in parameters:\n",
    "        print(f\"{param.ljust(20)}: {desc}\")\n",
    "\n",
    "# 显示导出参数解释\n",
    "explain_export_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92c5bbc",
   "metadata": {},
   "source": [
    "## 3. 导出为ONNX格式\n",
    "\n",
    "现在，我们将PyTorch模型导出为ONNX格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ea298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_onnx(model, onnx_path, input_shape=(1, 1, 28, 28)):\n",
    "    \"\"\"将PyTorch模型导出为ONNX格式\"\"\"\n",
    "    # 确保输出目录存在\n",
    "    os.makedirs(os.path.dirname(onnx_path), exist_ok=True)\n",
    "    \n",
    "    # 创建随机输入tensor（符合MNIST图像尺寸）\n",
    "    dummy_input = torch.randn(input_shape, requires_grad=True)\n",
    "    \n",
    "    # 设置输出名称（可选）\n",
    "    output_names = ['output']\n",
    "    \n",
    "    # 设置输入名称（可选）\n",
    "    input_names = ['input']\n",
    "    \n",
    "    # 设置动态轴（可选，允许批量大小可变）\n",
    "    dynamic_axes = {'input': {0: 'batch_size'},\n",
    "                   'output': {0: 'batch_size'}}\n",
    "    \n",
    "    # 导出模型到ONNX\n",
    "    try:\n",
    "        torch.onnx.export(\n",
    "            model,                     # 要导出的模型\n",
    "            dummy_input,               # 模型输入\n",
    "            onnx_path,                 # 输出ONNX文件路径\n",
    "            export_params=True,        # 存储训练后的参数权重\n",
    "            opset_version=12,          # ONNX算子集版本\n",
    "            do_constant_folding=True,  # 是否执行常量折叠优化\n",
    "            input_names=input_names,   # 输入名称\n",
    "            output_names=output_names, # 输出名称\n",
    "            dynamic_axes=dynamic_axes, # 动态轴\n",
    "            verbose=False              # 详细信息打印\n",
    "        )\n",
    "        print(f\"ONNX模型已成功导出到: {os.path.abspath(onnx_path)}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"导出ONNX模型时出错: {e}\")\n",
    "        return False\n",
    "\n",
    "# 导出模型（如果已成功加载PyTorch模型）\n",
    "if pytorch_model is not None:\n",
    "    export_success = export_to_onnx(pytorch_model, onnx_model_path)\n",
    "else:\n",
    "    print(\"错误: 无法加载PyTorch模型。请先运行第2部分教程以训练和保存模型。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678548f7",
   "metadata": {},
   "source": [
    "## 4. 验证ONNX模型\n",
    "\n",
    "导出后，我们需要验证ONNX模型的格式是否正确，并查看其基本信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af2d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_onnx_model(onnx_path):\n",
    "    \"\"\"验证导出的ONNX模型是否有效\"\"\"\n",
    "    try:\n",
    "        import onnx\n",
    "        # 加载ONNX模型\n",
    "        onnx_model = onnx.load(onnx_path)\n",
    "        \n",
    "        # 检查模型是否格式良好\n",
    "        onnx.checker.check_model(onnx_model)\n",
    "        \n",
    "        print(\"ONNX模型检查通过！\")\n",
    "        \n",
    "        # 打印一些基础模型信息\n",
    "        print(\"\\nONNX模型信息:\")\n",
    "        print(f\"IR版本: {onnx_model.ir_version}\")\n",
    "        print(f\"操作符集版本: {onnx_model.opset_import[0].version}\")\n",
    "        print(f\"生产者名称: {onnx_model.producer_name}\")\n",
    "        \n",
    "        # 打印输入输出信息\n",
    "        print(\"\\n输入信息:\")\n",
    "        for input in onnx_model.graph.input:\n",
    "            print(f\"  - 名称: {input.name}, 类型: {input.type.tensor_type.elem_type}, \"\n",
    "                  f\"形状: {[d.dim_value if d.dim_value else 'dynamic' for d in input.type.tensor_type.shape.dim]}\")\n",
    "            \n",
    "        print(\"\\n输出信息:\")\n",
    "        for output in onnx_model.graph.output:\n",
    "            print(f\"  - 名称: {output.name}, 类型: {output.type.tensor_type.elem_type}, \"\n",
    "                  f\"形状: {[d.dim_value if d.dim_value else 'dynamic' for d in output.type.tensor_type.shape.dim]}\")\n",
    "        \n",
    "        # 计算模型大小\n",
    "        model_size = os.path.getsize(onnx_path) / (1024 * 1024)  # 转换为MB\n",
    "        print(f\"\\nONNX模型大小: {model_size:.2f} MB\")\n",
    "        \n",
    "        return True\n",
    "    except ImportError:\n",
    "        print(\"警告: 未安装onnx库，无法验证模型。请使用pip install onnx安装。\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"验证ONNX模型时出错: {e}\")\n",
    "        return False\n",
    "\n",
    "# 验证模型（如果导出成功）\n",
    "if 'export_success' in locals() and export_success:\n",
    "    verify_success = verify_onnx_model(onnx_model_path)\n",
    "else:\n",
    "    print(\"跳过验证步骤，因为模型导出失败。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5f9c14",
   "metadata": {},
   "source": [
    "## 5. 比较PyTorch和ONNX模型输出\n",
    "\n",
    "最后，我们需要确保PyTorch模型和ONNX模型产生相同的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eac9ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_outputs(pytorch_model, onnx_path):\n",
    "    \"\"\"比较PyTorch模型与ONNX模型的输出是否一致\"\"\"\n",
    "    try:\n",
    "        import onnxruntime\n",
    "        \n",
    "        # 创建一个随机测试输入\n",
    "        test_input = torch.randn(1, 1, 28, 28)\n",
    "        \n",
    "        # PyTorch模型推理\n",
    "        with torch.no_grad():\n",
    "            pytorch_output = pytorch_model(test_input).numpy()\n",
    "        \n",
    "        # ONNX Runtime推理\n",
    "        ort_session = onnxruntime.InferenceSession(onnx_path)\n",
    "        ort_inputs = {ort_session.get_inputs()[0].name: test_input.numpy()}\n",
    "        ort_output = ort_session.run(None, ort_inputs)[0]\n",
    "        \n",
    "        # 比较两个输出\n",
    "        is_close = np.allclose(pytorch_output, ort_output, rtol=1e-03, atol=1e-05)\n",
    "        \n",
    "        if is_close:\n",
    "            print(\"✓ PyTorch和ONNX输出一致！\")\n",
    "        else:\n",
    "            print(\"✗ PyTorch和ONNX输出不一致！\")\n",
    "            # 显示差异\n",
    "            print(f\"最大绝对误差: {np.max(np.abs(pytorch_output - ort_output))}\")\n",
    "        \n",
    "        return is_close\n",
    "    except ImportError:\n",
    "        print(\"警告: 未安装onnxruntime库，无法比较输出。请使用pip install onnxruntime安装。\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"比较模型输出时出错: {e}\")\n",
    "        return False\n",
    "\n",
    "# 比较模型输出（如果验证成功）\n",
    "if pytorch_model is not None and 'verify_success' in locals() and verify_success:\n",
    "    compare_outputs(pytorch_model, onnx_model_path)\n",
    "else:\n",
    "    print(\"跳过比较步骤，因为模型加载或验证失败。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55823442",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "在本教程中，我们完成了以下任务：\n",
    "\n",
    "1. 加载了一个预训练的PyTorch MNIST模型\n",
    "2. 了解了ONNX导出的重要参数\n",
    "3. 将PyTorch模型导出为ONNX格式\n",
    "4. 验证了ONNX模型的结构和格式\n",
    "5. 比较了PyTorch和ONNX模型的输出，确保它们功能一致\n",
    "\n",
    "这些步骤是在实际项目中将深度学习模型部署到不同平台和框架的重要环节。通过ONNX，我们可以打破框架之间的壁垒，实现模型的互操作性。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
