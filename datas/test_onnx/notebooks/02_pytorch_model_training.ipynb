{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a0d8304",
   "metadata": {},
   "source": [
    "# ONNX教程 - 第2部分：PyTorch模型创建与训练\n",
    "\n",
    "本notebook展示如何创建、训练并保存一个简单的PyTorch模型，这是ONNX模型转换流程的第一步。我们将使用MNIST手写数字数据集训练一个卷积神经网络，并保存模型以便后续转换为ONNX格式。\n",
    "\n",
    "本教程包含以下步骤：\n",
    "\n",
    "1. 导入必要的库\n",
    "2. 定义模型架构\n",
    "3. 加载和准备数据\n",
    "4. 训练模型\n",
    "5. 评估模型性能\n",
    "6. 保存训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caf51fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4424df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查是否可以使用GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f4e729",
   "metadata": {},
   "source": [
    "## 1. 定义模型架构\n",
    "\n",
    "我们将定义一个简单的卷积神经网络用于MNIST手写数字识别。模型结构如下：\n",
    "\n",
    "- 两个卷积层，每个后面跟着ReLU激活函数和最大池化层\n",
    "- 两个全连接层\n",
    "- Dropout层以减少过拟合\n",
    "- 输出层使用log_softmax激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4257fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    \"\"\"MNIST手写数字识别模型\"\"\"\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        # 第一个卷积层：1通道输入，32通道输出，3x3卷积核\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        # 第二个卷积层：32通道输入，64通道输出，3x3卷积核\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        # 最大池化层\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        # 全连接层1：将7x7x64维张量展平为1维，然后映射到128维\n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 128)\n",
    "        # 全连接层2：将128维映射到10维（对应10个数字类别）\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        # Dropout层，用于减少过拟合\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 第一个卷积层+ReLU激活+最大池化\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 输出尺寸: [batch, 32, 14, 14]\n",
    "        # 第二个卷积层+ReLU激活+最大池化\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 输出尺寸: [batch, 64, 7, 7]\n",
    "        # 展平张量\n",
    "        x = x.view(-1, 7 * 7 * 64)  # 输出尺寸: [batch, 7*7*64]\n",
    "        # Dropout\n",
    "        x = self.dropout(x)\n",
    "        # 全连接层1+ReLU激活\n",
    "        x = F.relu(self.fc1(x))  # 输出尺寸: [batch, 128]\n",
    "        # Dropout\n",
    "        x = self.dropout(x)\n",
    "        # 全连接层2\n",
    "        x = self.fc2(x)  # 输出尺寸: [batch, 10]\n",
    "        # 输出层使用log_softmax\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f9f4a3",
   "metadata": {},
   "source": [
    "## 2. 加载和准备数据\n",
    "\n",
    "接下来，我们将加载MNIST数据集并应用必要的预处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d363cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"加载MNIST数据集\"\"\"\n",
    "    # 数据预处理和增强\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # 将图像转换为Tensor\n",
    "        transforms.Normalize((0.1307,), (0.3081,))  # 标准化（MNIST数据集的均值和标准差）\n",
    "    ])\n",
    "    \n",
    "    # 下载并加载训练集\n",
    "    train_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    # 下载并加载测试集\n",
    "    test_dataset = datasets.MNIST('../data', train=False, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# 加载数据\n",
    "print(\"[1] 加载MNIST数据集\")\n",
    "train_loader, test_loader = load_data()\n",
    "print(f\"训练集大小: {len(train_loader.dataset)}\")\n",
    "print(f\"测试集大小: {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61be0cf",
   "metadata": {},
   "source": [
    "## 3. 创建模型实例\n",
    "\n",
    "现在我们将创建模型实例并将其移动到适当的设备（CPU/GPU）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc22a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子以便结果可复现\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 创建模型\n",
    "print(\"[2] 创建MNIST识别模型\")\n",
    "model = MNISTModel().to(device)\n",
    "print(model)\n",
    "\n",
    "# 设置优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dbcd2e",
   "metadata": {},
   "source": [
    "## 4. 训练和评估函数\n",
    "\n",
    "接下来，我们定义用于训练和评估模型的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ce1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    \"\"\"训练模型的一个epoch\"\"\"\n",
    "    model.train()  # 设置为训练模式\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # 将数据移至GPU（如果可用）\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 前向传播\n",
    "        output = model(data)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = F.nll_loss(output, target)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        \n",
    "        # 更新参数\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 打印训练进度\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f'训练: Epoch {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\t损失: {loss.item():.6f}')\n",
    "    \n",
    "    # 计算平均损失和训练时间\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f'Epoch {epoch} 训练完成, 平均损失: {avg_loss:.6f}, 用时: {elapsed:.2f} 秒')\n",
    "    \n",
    "    return avg_loss\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    \"\"\"评估模型性能\"\"\"\n",
    "    model.eval()  # 设置为评估模式\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():  # 在评估时不需要计算梯度\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            # 累加批次损失\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            \n",
    "            # 获取最大对数概率的索引\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            \n",
    "            # 计算正确预测的数量\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    # 计算平均损失\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    # 打印测试结果\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print(f'测试集: 平均损失: {test_loss:.4f}, 准确率: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)')\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc859e28",
   "metadata": {},
   "source": [
    "## 5. 训练模型\n",
    "\n",
    "现在我们将训练模型并跟踪性能指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871e5e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "print(\"[3] 开始训练模型\")\n",
    "n_epochs = 5\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train_loss = train(model, device, train_loader, optimizer, epoch)\n",
    "    test_loss, accuracy = test(model, device, test_loader)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3cb0a",
   "metadata": {},
   "source": [
    "## 6. 保存模型\n",
    "\n",
    "训练完成后，将模型保存到文件中，以便后续用于ONNX转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5b981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path='model.pth'):\n",
    "    \"\"\"保存PyTorch模型\"\"\"\n",
    "    # 创建目录（如果不存在）\n",
    "    os.makedirs(os.path.dirname(path) if os.path.dirname(path) else '.', exist_ok=True)\n",
    "    \n",
    "    # 保存模型\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f'模型已保存到 {os.path.abspath(path)}')\n",
    "\n",
    "# 保存训练好的模型\n",
    "print(\"[4] 保存模型\")\n",
    "save_model(model, '../models/mnist_cnn.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b063036a",
   "metadata": {},
   "source": [
    "## 7. 显示训练结果\n",
    "\n",
    "让我们查看训练过程中的性能指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5e9bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印训练结果\n",
    "print(\"[5] 训练结束\")\n",
    "print(f\"最终测试准确率: {test_accuracies[-1]:.2f}%\")\n",
    "\n",
    "# 可选：绘制训练曲线\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # 损失曲线\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, n_epochs + 1), train_losses, 'b-', label='训练损失')\n",
    "    plt.plot(range(1, n_epochs + 1), test_losses, 'r-', label='测试损失')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('损失')\n",
    "    plt.legend()\n",
    "    plt.title('训练和测试损失')\n",
    "    \n",
    "    # 准确率曲线\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, n_epochs + 1), test_accuracies, 'g-')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('准确率 (%)')\n",
    "    plt.title('测试准确率')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print(\"matplotlib未安装，跳过绘图\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10487c9e",
   "metadata": {},
   "source": [
    "## 8. 检查模型文件\n",
    "\n",
    "验证模型文件是否已正确保存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e23ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查保存的模型文件\n",
    "model_path = '../models/mnist_cnn.pth'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    file_size = os.path.getsize(model_path) / (1024 * 1024)  # 转换为MB\n",
    "    print(f\"模型文件已保存: {model_path}\")\n",
    "    print(f\"文件大小: {file_size:.2f} MB\")\n",
    "    print(\"\\n模型训练和保存完成！下一步是将PyTorch模型转换为ONNX格式（第3部分）。\")\n",
    "else:\n",
    "    print(f\"错误: 模型文件未找到: {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
