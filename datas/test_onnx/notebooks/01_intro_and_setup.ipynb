{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d35e7734",
   "metadata": {},
   "source": [
    "# ONNX教程 - 第1部分：引言与基础准备\n",
    "\n",
    "欢迎来到ONNX教程系列的第一部分！在本notebook中，我们将介绍ONNX的基本概念，并设置必要的开发环境。\n",
    "\n",
    "## 什么是ONNX？\n",
    "\n",
    "ONNX (Open Neural Network Exchange) 是一种开放格式，用于表示深度学习模型。ONNX定义了一组公共操作符和通用数据类型，使AI开发人员能够使用各种框架（如PyTorch、TensorFlow、MXNet等）构建模型，然后将这些模型导出为ONNX格式，以便在不同平台和设备上运行。\n",
    "\n",
    "### ONNX的主要优势：\n",
    "\n",
    "1. **跨框架互操作性**：在不同深度学习框架之间迁移模型\n",
    "2. **硬件加速**：利用针对不同硬件优化的推理引擎（如ONNX Runtime）\n",
    "3. **部署灵活性**：在云端、边缘设备或移动设备上部署模型\n",
    "4. **模型优化**：通过ONNX工具进行模型压缩和优化\n",
    "\n",
    "### 教程概述\n",
    "\n",
    "本教程系列包含以下部分：\n",
    "\n",
    "1. 引言与基础准备（本部分）\n",
    "2. 创建和训练PyTorch模型\n",
    "3. 将PyTorch模型导出为ONNX格式\n",
    "4. ONNX模型的基本操作\n",
    "\n",
    "让我们开始检查环境并演示一个简单的PyTorch模型！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9ff11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ccaa42",
   "metadata": {},
   "source": [
    "## 1. 环境检查\n",
    "\n",
    "首先，我们需要检查已安装的库版本并确认ONNX及相关工具是否可用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8503b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_environment():\n",
    "    \"\"\"检查环境配置\"\"\"\n",
    "    print(\"Python版本:\", sys.version)\n",
    "    print(\"PyTorch版本:\", torch.__version__)\n",
    "    \n",
    "    # 检查ONNX是否已安装\n",
    "    try:\n",
    "        import onnx\n",
    "        print(\"ONNX版本:\", onnx.__version__)\n",
    "        onnx_available = True\n",
    "    except ImportError:\n",
    "        print(\"ONNX未安装，请使用pip install onnx安装\")\n",
    "        onnx_available = False\n",
    "    \n",
    "    # 检查ONNX Runtime是否已安装  \n",
    "    try:\n",
    "        import onnxruntime\n",
    "        print(\"ONNX Runtime版本:\", onnxruntime.__version__)\n",
    "        onnxruntime_available = True\n",
    "    except ImportError:\n",
    "        print(\"ONNX Runtime未安装，请使用pip install onnxruntime安装\")\n",
    "        onnxruntime_available = False\n",
    "    \n",
    "    # 检查CUDA是否可用\n",
    "    print(\"CUDA是否可用:\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA版本:\", torch.version.cuda)\n",
    "        print(\"当前CUDA设备:\", torch.cuda.current_device())\n",
    "        print(\"CUDA设备名称:\", torch.cuda.get_device_name(0))\n",
    "        \n",
    "    # 检查可视化工具Netron\n",
    "    try:\n",
    "        import netron\n",
    "        print(\"Netron版本: 可用\")\n",
    "        netron_available = True\n",
    "    except ImportError:\n",
    "        print(\"Netron未安装，请使用pip install netron安装 (用于可视化ONNX模型)\")\n",
    "        netron_available = False\n",
    "    \n",
    "    return onnx_available and onnxruntime_available\n",
    "\n",
    "# 执行环境检查\n",
    "print(\"[1] 环境检查\")\n",
    "env_ready = check_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c643f87",
   "metadata": {},
   "source": [
    "## 2. 安装缺失的包\n",
    "\n",
    "如果某些必要的包未安装，您可以使用以下命令进行安装："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51a9b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果需要安装缺失的包，取消以下注释\n",
    "# !pip install onnx onnxruntime netron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ee4deb",
   "metadata": {},
   "source": [
    "## 3. 创建简单的PyTorch模型\n",
    "\n",
    "接下来，我们将定义一个简单的全连接神经网络作为示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6cad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    \"\"\"一个简单的全连接神经网络\"\"\"\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 20)\n",
    "        self.fc2 = nn.Linear(20, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 实例化模型\n",
    "model = SimpleModel()\n",
    "print(\"\\n模型结构:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad08c08f",
   "metadata": {},
   "source": [
    "## 4. 测试模型的前向传播\n",
    "\n",
    "现在让我们创建一个随机输入并测试模型的前向传播："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed7a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_simple_model(model):\n",
    "    \"\"\"测试简单模型的前向传播\"\"\"\n",
    "    model.eval()  # 设置为评估模式\n",
    "    \n",
    "    # 创建一个随机输入\n",
    "    dummy_input = torch.randn(1, 10)\n",
    "    print(\"\\n输入形状:\", dummy_input.shape)\n",
    "    print(\"输入数据:\\n\", dummy_input)\n",
    "    \n",
    "    # 前向传播\n",
    "    with torch.no_grad():\n",
    "        output = model(dummy_input)\n",
    "    \n",
    "    print(\"\\n输出形状:\", output.shape)\n",
    "    print(\"输出数据:\\n\", output)\n",
    "    \n",
    "    return dummy_input\n",
    "\n",
    "# 执行模型测试\n",
    "print(\"[2] 简单PyTorch模型测试\")\n",
    "dummy_input = test_simple_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6397357",
   "metadata": {},
   "source": [
    "## 5. ONNX格式简介\n",
    "\n",
    "ONNX模型由以下关键组件组成：\n",
    "\n",
    "1. **模型元数据**：包含版本信息、生产者信息等\n",
    "2. **图 (Graph)**：模型的计算图表示\n",
    "3. **节点 (Node)**：图中的操作（如卷积、ReLU等）\n",
    "4. **张量 (Tensor)**：数据和参数\n",
    "5. **属性 (Attribute)**：节点的参数配置\n",
    "\n",
    "下面我们将展示ONNX模型的结构示意图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f554028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用ASCII来表示ONNX模型的结构\n",
    "onnx_structure = \"\"\"\n",
    "+------------------------+\n",
    "| ONNX Model             |\n",
    "+------------------------+\n",
    "| - IR Version           |\n",
    "| - Opset Version        |\n",
    "| - Producer Name        |\n",
    "| - Model Version        |\n",
    "+----------+-------------+\n",
    "|          |\n",
    "|          v\n",
    "+----------+-------------+\n",
    "| Graph                  |\n",
    "+------------------------+\n",
    "| - Input Tensors        |\n",
    "| - Output Tensors       |\n",
    "| - Initializers (Weights)|\n",
    "+----------+-------------+\n",
    "|          |\n",
    "|          v\n",
    "+----------+-------------+\n",
    "| Nodes (Operations)     |\n",
    "+------------------------+\n",
    "| - Operators (Conv, ReLU)|\n",
    "| - Attributes           |\n",
    "| - Input/Output Edges   |\n",
    "+------------------------+\n",
    "\"\"\"\n",
    "\n",
    "print(onnx_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedefe3f",
   "metadata": {},
   "source": [
    "## 6. 预览PyTorch转ONNX流程\n",
    "\n",
    "在下一个教程部分中，我们将详细介绍如何将PyTorch模型导出为ONNX格式，但这里先简要预览一下流程的代码结构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e1855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预览代码 - 不执行\n",
    "def preview_export_code():\n",
    "    print(\"\"\"# PyTorch模型转换为ONNX的基本步骤\n",
    "import torch\n",
    "import onnx\n",
    "\n",
    "# 1. 准备模型和输入\n",
    "model = SimpleModel()  # 定义模型\n",
    "dummy_input = torch.randn(1, 10)  # 创建样本输入\n",
    "\n",
    "# 2. 导出为ONNX格式\n",
    "torch.onnx.export(model,               # 模型\n",
    "                  dummy_input,         # 模型输入\n",
    "                  \"simple_model.onnx\", # 输出文件名\n",
    "                  export_params=True,  # 存储训练参数权重\n",
    "                  opset_version=12,    # ONNX版本\n",
    "                  input_names=[\"input\"],    # 输入名\n",
    "                  output_names=[\"output\"],  # 输出名\n",
    "                  dynamic_axes={\"input\": {0: \"batch_size\"},\n",
    "                               \"output\": {0: \"batch_size\"}})\n",
    "\n",
    "# 3. 验证ONNX模型\n",
    "onnx_model = onnx.load(\"simple_model.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\"\"\")\n",
    "\n",
    "# 显示预览代码\n",
    "preview_export_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f5ea8b",
   "metadata": {},
   "source": [
    "## 7. ONNX生态系统\n",
    "\n",
    "ONNX生态系统包含许多工具和库，下面是一些常用的组件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c63712",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_ecosystem = {\n",
    "    \"核心库\": [\n",
    "        \"ONNX: 定义模型格式和操作符\",\n",
    "        \"ONNX Runtime: 高性能推理引擎\"\n",
    "    ],\n",
    "    \"转换工具\": [\n",
    "        \"PyTorch: torch.onnx.export()\",\n",
    "        \"TensorFlow: tf2onnx\",\n",
    "        \"Keras: keras2onnx\"\n",
    "    ],\n",
    "    \"优化工具\": [\n",
    "        \"ONNX Runtime: 图优化\",\n",
    "        \"ONNX Simplifier: 模型简化\",\n",
    "        \"TensorRT: NVIDIA GPU优化\"\n",
    "    ],\n",
    "    \"可视化工具\": [\n",
    "        \"Netron: 图形化查看ONNX模型\"\n",
    "    ],\n",
    "    \"部署平台\": [\n",
    "        \"云端: Azure ML, AWS SageMaker\",\n",
    "        \"边缘设备: NVIDIA Jetson, Intel NCS\",\n",
    "        \"移动设备: Android NNAPI, iOS CoreML\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 打印ONNX生态系统信息\n",
    "print(\"ONNX生态系统组件:\")\n",
    "for category, tools in onnx_ecosystem.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for tool in tools:\n",
    "        print(f\"  - {tool}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae367f6",
   "metadata": {},
   "source": [
    "## 8. 总结\n",
    "\n",
    "在本教程中，我们：\n",
    "\n",
    "1. 介绍了ONNX的概念和优势\n",
    "2. 检查了开发环境和必要的库\n",
    "3. 创建并测试了一个简单的PyTorch模型\n",
    "4. 了解了ONNX模型的基本结构\n",
    "5. 预览了PyTorch模型导出为ONNX的流程\n",
    "6. 了解了ONNX生态系统的主要组件\n",
    "\n",
    "在下一个教程中，我们将创建和训练一个更实用的PyTorch模型（MNIST手写数字识别），为后续的ONNX转换做准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd89020",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n环境检查完成。\")\n",
    "if env_ready:\n",
    "    print(\"所有必要的库都已正确安装，您可以继续下一部分的学习！\")\n",
    "else:\n",
    "    print(\"请安装缺少的库后继续。\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
