# ================== ä»£ç ä¸»ä½“ ================

import os
import time
import yaml
import openai
import streamlit as st
from pocketflow import Node, Flow, build_mermaid # ç§»é™¤ DDGS
from dotenv import load_dotenv
import random

from financial_search_prompt import INDUSTRY_RESEARCH_PROMPT, JUDGE_LINK_USEFULNESS_PROMPT
from google_search import GoogleSearchPool # æ–°å¢ï¼šå¯¼å…¥GoogleSearchPool

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(page_title="æ·±åº¦æœç´¢åŠ©æ‰‹", layout="wide")

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ä»ç¯å¢ƒå˜é‡ä¸­åˆå§‹åŒ– OpenAI API å¯†é’¥
openai.api_key = os.getenv("OPENAI_API_KEY")
openai.api_base = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")

def call_llm(prompt: str) -> str:
    response = openai.chat.completions.create(
        model=os.getenv("OPENAI_MODEL", "gpt-4"),
        messages=[{"role": "user", "content": prompt}],
        temperature=0.4,
        max_tokens=8196,  # 16k=16384,8k=8196æ ¹æ®éœ€è¦è°ƒæ•´
    )
    return response.choices[0].message.content.strip()


def search_web(term: str, search_pool: GoogleSearchPool): # ä¿®æ”¹ï¼šæ·»åŠ  search_pool å‚æ•°
    """ä½¿ç”¨ GoogleSearchPool æ‰§è¡Œç½‘ç»œæœç´¢"""
    try:
        # Google API æ¯æ¬¡æœ€å¤šè¿”å›10æ¡
        results = search_pool.search(term, num_results=10)
        return results
    except Exception as e:
        st.error(f"Google æœç´¢ '{term}' æ—¶å‡ºé”™: {e}") # ä½¿ç”¨ Streamlit çš„é”™è¯¯æç¤º
        return []


def parse_custom_structured_text(text, fields):
    """
    è§£æè‡ªå®šä¹‰ç»“æ„åŒ–æ–‡æœ¬ï¼Œfieldsä¸ºéœ€è¦æå–çš„å­—æ®µåˆ—è¡¨ã€‚
    è¿”å›dictã€‚
    """
    # æå–```custom_structrue_textåŒ…å›´å†…å®¹
    if '```custom_structrue_text' in text:
        text = text.split('```custom_structrue_text',1)[1].split('```',1)[0].strip()
    lines = [line.strip() for line in text.splitlines() if line.strip()]
    result = {k: None for k in fields}
    for idx, line in enumerate(lines):
        for field in fields:
            tag = f'[{field}]'
            if line.startswith(tag):
                val = line.split(']',1)[1].strip()
                if field == 'search_inputs':
                    # åç»­çš„-è¡Œéƒ½æ˜¯æœç´¢è¾“å…¥
                    search_inputs = []
                    for l in lines[idx+1:]:
                        if l.startswith('- '):
                            search_inputs.append(l[2:].strip())
                        else:
                            break
                    result['search_inputs'] = search_inputs
                else:
                    result[field] = val
    return result


# ================== å·¥ä½œæµæ ¸å¿ƒéƒ¨åˆ† ==================

class SearchDecisionFlow(Node):  # æœç´¢å†³ç­–èŠ‚ç‚¹
    """
    æœç´¢å†³ç­–èŠ‚ç‚¹ï¼š
    - åˆ†æå½“å‰å·²æ”¶é›†çš„ä¿¡æ¯å’Œå†å²æœç´¢è®°å½•
    - åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­æœç´¢ï¼Œè¿˜æ˜¯å¯ä»¥è¿›å…¥æœç´¢æŠ¥å‘Šæ±‡æ€»
    - ç”Ÿæˆä¸‹ä¸€è½®æœç´¢çš„å…³é”®è¯åˆ—è¡¨
    - æ§åˆ¶æœ€å¤§è½®æ•°å’Œæ— æ•ˆè½®æ•°æå‰ç»ˆæ­¢
    """
    def prep(self, shared):
        # æå–ä¸Šä¸‹æ–‡ã€æœç´¢ä¸»é¢˜ã€å½“å‰è½®æ¬¡
        search_context = shared.get("search_context", [])
        context_str = yaml.dump(search_context, allow_unicode=True)
        search_topic = shared["search_topic"]
        search_round = shared.get("search_round", 0)
        return search_topic, context_str, search_round

    def exec(self, inputs):
        search_topic, context_yaml_str, search_round = inputs
        st.info(f"æ­£åœ¨åˆ†æ {search_topic} æœç´¢è¿›åº¦... (ç¬¬ {search_round + 1} è½®)")
        # è§£æå†å²æœç´¢å…³é”®è¯ï¼Œé¿å…é‡å¤
        previous_search_terms = []
        if search_round > 0:
            try:
                context_data = yaml.safe_load(context_yaml_str)
                if isinstance(context_data, list):
                    for search_batch in context_data:
                        if isinstance(search_batch, dict) and 'search_query' in search_batch: # ä¿®æ”¹ 'term' ä¸º 'search_query'
                            previous_search_terms.append(search_batch['search_query'])
                        elif isinstance(search_batch, list):
                            for item in search_batch:
                                if isinstance(item, dict) and 'search_query' in item: # ä¿®æ”¹ 'term' ä¸º 'search_query'
                                    previous_search_terms.append(item['search_query'])
            except Exception:
                pass # Silently ignore parsing errors for now
        previous_search_terms_str = '\n'.join(f'- {term}' for term in previous_search_terms)
        if not previous_search_terms_str:
            previous_search_terms_str = 'ï¼ˆæ— ï¼‰'
        # æ„é€  LLM æç¤ºè¯ï¼Œè‡ªåŠ¨ç”Ÿæˆä¸‹ä¸€è½®æœç´¢å»ºè®®
        prompt = INDUSTRY_RESEARCH_PROMPT.format(
            industry=search_topic,
            context_yaml_str=context_yaml_str,
            previous_search_terms_str=previous_search_terms_str,
            search_round=search_round
        )
        with st.spinner("æ­£åœ¨åˆ†æå·²æ”¶é›†ä¿¡æ¯å¹¶ç”Ÿæˆæ–°çš„æœç´¢å…³é”®è¯..."):
            llm_response = call_llm(prompt)
            result = parse_custom_structured_text(llm_response, ['continue_search', 'reason', 'search_inputs'])
        
        # ç±»å‹è½¬æ¢
        result['continue_search'] = str(result['continue_search']).strip().lower() == 'true'
        if result['search_inputs'] is None:
            result['search_inputs'] = []
        
        st.write(f"ç»§ç»­æœç´¢: {result['continue_search']}")
        st.write(f"æœç´¢åŸå› : {result['reason']}")
        st.write("æœ¬è½®æœç´¢è¾“å…¥:", result["search_inputs"])
        return result

    def post(self, shared, prep_res, exec_res):
        # æ§åˆ¶æœ€å¤§è½®æ•°å’Œæ— æ•ˆè½®æ•°ï¼Œå†³å®šæ˜¯å¦æå‰ç»ˆæ­¢
        max_rounds = shared.get("max_rounds")
        max_invalid_rounds = shared.get("max_invalid_rounds", 3)
        current_round = shared.get("search_round", 0)
        invalid_search_rounds = shared.get("invalid_search_rounds", 0)
        # æœ€å¤§æœç´¢æ¬¡æ•°åˆ¤æ–­
        max_search_count = shared.get("max_search_count")
        total_search_count = shared.get("total_search_count", 0)
        if max_rounds is not None and current_round >= max_rounds:
            st.warning(f"å·²è¾¾åˆ°æœ€å¤§è½®æ•°({max_rounds})ï¼Œæœç´¢æµç¨‹ç»ˆæ­¢")
            return "complete"
        if max_invalid_rounds is not None and invalid_search_rounds >= max_invalid_rounds:
            st.warning(f"è¿ç»­{invalid_search_rounds}è½®æ— æœ‰æ•ˆä¿¡æ¯ï¼Œæå‰ç»ˆæ­¢æœç´¢æµç¨‹")
            return "complete"
        if max_search_count is not None and total_search_count >= max_search_count:
            st.warning(f"å·²è¾¾åˆ°æœ€å¤§æœç´¢æ¬¡æ•°({max_search_count})ï¼Œæœç´¢æµç¨‹ç»ˆæ­¢")
            return "complete"
        if exec_res.get("continue_search", True):
            shared["search_inputs"] = exec_res.get("search_inputs", [])
            shared["search_round"] = current_round + 1
            st.success("å¼€å§‹æ–°ä¸€è½®æœç´¢")
            return "search"
        else:
            st.success("æœç´¢æµç¨‹å®Œæˆ")
            return "complete"


class SearchInfo(Node):  # ä¿¡æ¯æœç´¢èŠ‚ç‚¹
    """
    ä¿¡æ¯æœç´¢èŠ‚ç‚¹ï¼š
    - æ ¹æ®å†³ç­–èŠ‚ç‚¹ç”Ÿæˆçš„å…³é”®è¯ï¼Œå®é™…æ‰§è¡Œç½‘ç»œæ£€ç´¢
    - å¯¹æ¯æ¡æœç´¢ç»“æœè°ƒç”¨ LLM åˆ¤æ–­å…¶æœ‰ç”¨æ€§
    - è‡ªåŠ¨å»é‡ï¼Œç´¯è®¡æœ‰ç”¨/æ— ç”¨é“¾æ¥
    - æ”¯æŒæ— æ‘˜è¦æ—¶ç›´æ¥åˆ¤ä¸ºæ— ç”¨é“¾æ¥
    """
    def prep(self, shared):
        # è·å–æœ¬è½®æœç´¢å…³é”®è¯ã€æœç´¢ä¸»é¢˜ã€å†å²æœ‰ç”¨/æ— ç”¨é“¾æ¥ã€æœç´¢æ± 
        return (
            shared.get("search_inputs", []),
            shared.get("search_topic"),
            shared.get("useful_links", []),
            shared.get("useless_links", []),
            shared.get("search_pool") # æ–°å¢ï¼šè·å– search_pool
        )

    def exec(self, inputs):
        search_queries, search_topic, useful_links, useless_links, search_pool = inputs # æ–°å¢ï¼šæ¥æ”¶ search_pool
        all_search_results = []
        total_queries = len(search_queries)
        
        st.subheader(f"æœ¬è½®æœç´¢è¾“å…¥: {', '.join(search_queries)}")
        seen_urls = set(link['href'] for link in useful_links + useless_links if link.get('href'))
        
        progress_bar = st.progress(0)
        shared = self.shared if hasattr(self, 'shared') else None # ä¿ç•™ shared å¼•ç”¨
        search_count_this_round = 0

        for idx, search_query in enumerate(search_queries, 1):
            st.write(f"æœç´¢è¾“å…¥ ({idx}/{total_queries}): {search_query}")
            if search_pool is None:
                st.error("é”™è¯¯ï¼šsearch_pool æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ‰§è¡Œæœç´¢ã€‚")
                all_search_results.append({"search_query": search_query, "results": [], "error": "Search pool not available"})
                continue
            try:
                with st.spinner(f"æ­£åœ¨æœç´¢ '{search_query}'..."):
                    search_results_list = search_web(search_query, search_pool) # ä¿®æ”¹ï¼šä¼ é€’ search_pool
                search_count_this_round += 1
                
                st.write(f"æ‰¾åˆ° {len(search_results_list)} æ¡ç›¸å…³ä¿¡æ¯")
                round_useful_links = []
                
                with st.expander(f"æŸ¥è¯¢: {search_query} çš„æœç´¢ç»“æœ"):
                    for i, search_result_item in enumerate(search_results_list): # é‡å‘½åå˜é‡é¿å…ä¸å¤–å±‚å†²çª
                        url = search_result_item.get("link", "") # ä¿®æ”¹ï¼šGoogle API ä½¿ç”¨ "link"
                        title = search_result_item.get("title", "")
                        snippet = search_result_item.get("snippet", "") # ä¿®æ”¹ï¼šGoogle API ä½¿ç”¨ "snippet"

                        if not url or url in seen_urls:
                            continue
                        
                        st.text(f"æ­£åœ¨åˆ†æç»“æœ {i+1}/{len(search_results_list)}...")
                        
                        temp_link_info_for_judge = {
                            "title": title,
                            "body": snippet, # å°† snippet æ˜ å°„åˆ° body
                            "href": url     # å°† link æ˜ å°„åˆ° href
                        }
                        is_useful, reason = judge_link_usefulness(temp_link_info_for_judge, search_topic)  
                        
                        link_info = {
                            "search_query": search_query,
                            "title": title,
                            "body": snippet, # å­˜å‚¨ä¸º body
                            "href": url,     # å­˜å‚¨ä¸º href
                            "reason": reason
                        }
                        seen_urls.add(url)
                        if is_useful:
                            useful_links.append(link_info)
                            round_useful_links.append(link_info)
                            st.success(f"**æœ‰ç”¨**: {link_info['title']}")
                            st.write(f"åŸå› : {reason}")
                        else:
                            useless_links.append(link_info)
                            st.error(f"**æ— ç”¨**: {link_info['title']}")
                            st.write(f"åŸå› : {reason}")
                
                all_search_results.append({"search_query": search_query, "results": round_useful_links})
                
                if round_useful_links:
                    st.success("æœ‰ç”¨æœç´¢ç»“æœé¢„è§ˆ:")
                    for j, useful_result in enumerate(round_useful_links[:3]):
                        st.write(f"{j+1}. {useful_result.get('title', 'æ— æ ‡é¢˜')}")
                        st.write(f"   {useful_result.get('body', 'æ— æ‘˜è¦')[:100]}...")
            except Exception as e:
                st.error(f"æœç´¢ '{search_query}' æ—¶å‡ºé”™: {str(e)}")
                all_search_results.append({"search_query": search_query, "results": [], "error": str(e)})
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.progress((idx) / total_queries)
            
            if idx < total_queries:
                sleep_time = random.randint(16, 30)
                with st.spinner(f"ç­‰å¾…{sleep_time}ç§’åç»§ç»­æœç´¢..."):
                    time.sleep(sleep_time)
        
        # æ›´æ–°ç´¯è®¡æœç´¢æ¬¡æ•°
        if shared is not None:
            shared["total_search_count"] = shared.get("total_search_count", 0) + search_count_this_round
        return all_search_results, useful_links, useless_links

    def post(self, shared, prep_res, exec_res):
        # æ›´æ–°ä¸Šä¸‹æ–‡å’Œæœ‰ç”¨/æ— ç”¨é“¾æ¥ç»Ÿè®¡ï¼Œç´¯è®¡æ— æ•ˆè½®æ•°
        all_results, useful_links, useless_links = exec_res
        search_context = shared.get("search_context", [])
        search_context.extend(all_results)
        shared["search_context"] = search_context
        shared["useful_links"] = useful_links
        shared["useless_links"] = useless_links
        total_results = sum(len(item.get("results", [])) for item in all_results)
        
        st.success("æœ¬è½®æœç´¢å®Œæˆï¼")
        st.write(f"å…±æ”¶é›†åˆ° {total_results} æ¡æœ‰ç”¨ä¿¡æ¯")
        st.write(f"ç´¯è®¡æœ‰ç”¨é“¾æ¥: {len(useful_links)}ï¼Œæ— ç”¨é“¾æ¥: {len(useless_links)}")
        st.info("è¿”å›å†³ç­–èŠ‚ç‚¹ï¼Œå‡†å¤‡ä¸‹ä¸€è½®æœç´¢...")
        
        if total_results == 0:
            shared["invalid_search_rounds"] = shared.get("invalid_search_rounds", 0) + 1
        else:
            shared["invalid_search_rounds"] = 0
        # è®°å½•æœ¬è½®æœç´¢æ—¶é—´
        record_search_time(shared, event="search_round_end")
        return "search"


class SearchSummary(Node):  # æœç´¢æŠ¥å‘Šæ±‡æ€»èŠ‚ç‚¹
    """
    æœç´¢æŠ¥å‘Šæ±‡æ€»èŠ‚ç‚¹ï¼š
    - æ±‡æ€»æ‰€æœ‰å·²æ”¶é›†çš„ä¿¡æ¯ï¼Œç»Ÿè®¡è½®æ¬¡å’Œæ¡æ•°
    - ç”Ÿæˆç»“æ„åŒ–çš„æœç´¢æŠ¥å‘Š
    - ä¿å­˜ä¸º Markdown æ–‡ä»¶ï¼Œä¾¿äºåç»­åˆ†æ
    """
    def prep(self, shared):
        # è·å–æœç´¢ä¸»é¢˜ã€ä¸Šä¸‹æ–‡ã€è½®æ¬¡
        return (
            shared.get("search_topic"),
            shared.get("search_context", []),
            shared.get("search_round", 0),
            shared.get("search_times", [])
        )

    def exec(self, inputs):
        search_topic, search_context, search_round, search_times = inputs
        st.header(f"{search_topic} æœç´¢æŠ¥å‘Šæ±‡æ€»")
        st.write(f"å®Œæˆæœç´¢è½®æ¬¡: {search_round}")
        # ç»Ÿè®¡æ”¶é›†çš„ä¿¡æ¯æ¡æ•°
        total_results = 0
        for search_batch in search_context:
            if isinstance(search_batch, dict):
                total_results += len(search_batch.get("results", []))
        # ç”Ÿæˆè¯¦ç»†çš„å‚è€ƒæ–‡çŒ®å†…å®¹
        reference_md = ""
        ref_idx = 1
        for search_batch in search_context:
            if isinstance(search_batch, dict):
                results = search_batch.get("results", [])
                for search_result_item in results: # å˜é‡åä¿®æ”¹é¿å…å†²çª
                    title = search_result_item.get("title", "æ— æ ‡é¢˜")
                    url = search_result_item.get("href", "") # ä¿æŒ href
                    body = search_result_item.get("body", "") # ä¿æŒ body
                    reference_md += (
                        f"\nã€ç¬¬{ref_idx}ç¯‡å‚è€ƒæ–‡ç« å¼€å§‹ã€‘\n"
                        f"[{ref_idx}] æ ‡é¢˜ï¼š{title}\n"
                        f"[{ref_idx}] åŸæ–‡é“¾æ¥: {url}\n"
                        f"[{ref_idx}] æ‘˜è¦ï¼š{body}\n"
                        f"ã€ç¬¬{ref_idx}ç¯‡å‚è€ƒæ–‡ç« ç»“æŸã€‘\n"
                    )
                    ref_idx += 1
        # è·å–æ‰€æœ‰æœç´¢æ—¶é—´
        search_time_md = "\n".join([
            f"- {item['event']}: {item['timestamp']}" for item in search_times
        ]) if search_times else "æ— "
        # ç”Ÿæˆæœç´¢æŠ¥å‘Š
        summary = f"""
# {search_topic} æœç´¢æŠ¥å‘Š

## æ”¶é›†ç»Ÿè®¡
- æœç´¢è½®æ¬¡: {search_round}
- æ”¶é›†ä¿¡æ¯æ¡æ•°: {total_results}

## æœç´¢æ—¶é—´è®°å½•
{search_time_md}

## æœç´¢å®Œæˆæ—¶é—´
{time.strftime('%Y-%m-%d %H:%M:%S')}

---

## å‚è€ƒæ–‡çŒ®ä¸æœç´¢ç»“æœ
{reference_md}

---
æ³¨: æ‰€æœ‰è¯¦ç»†ä¿¡æ¯å·²ä¿å­˜åœ¨ç³»ç»Ÿå†…å­˜ä¸­ï¼Œå¯ç”¨äºåç»­åˆ†æå¤„ç†ã€‚
"""
        st.write(f"æœç´¢æŠ¥å‘Šæ±‡æ€»:")
        st.write(f"- æœç´¢è½®æ¬¡: {search_round}")
        st.write(f"- æ”¶é›†ä¿¡æ¯æ¡æ•°: {total_results}")
        return summary

    def post(self, shared, prep_res, exec_res):
        # ä¿å­˜æœç´¢æŠ¥å‘Šåˆ°æœ¬åœ°æ–‡ä»¶
        st.success("æœç´¢æµç¨‹å®Œæˆï¼")
        shared["summary"] = exec_res
        filename = f"{shared['search_topic']}_æœç´¢æŠ¥å‘Š.md"
        with open(filename, "w", encoding="utf-8") as f:
            f.write(exec_res)
        st.success(f"æœç´¢æŠ¥å‘Šå·²ä¿å­˜åˆ° '{filename}' æ–‡ä»¶ä¸­")
        
        # æä¾›ä¸‹è½½é“¾æ¥
        st.download_button(
            label="ä¸‹è½½æœç´¢æŠ¥å‘Š",
            data=exec_res,
            file_name=filename,
            mime="text/markdown",
        )
        return None


def judge_link_usefulness(link_info, industry):
    """
    è°ƒç”¨ LLM åˆ¤æ–­é“¾æ¥æ˜¯å¦æœ‰ç”¨ã€‚
    link_info: dict, åŒ…å« title, body, href (ç”± SearchInfo.exec æ„é€ )
    industry: è¡Œä¸šå
    focus_areas: å…³æ³¨é¢†åŸŸ
    è¿”å›: (is_useful: bool, reason: str)
    """
    summary = link_info.get('body', '').strip() # ä½¿ç”¨ body
    if not summary:
        return False, 'æ— æ‘˜è¦ï¼Œæ— æ³•åˆ¤æ–­æœ‰ç”¨ä¿¡æ¯ï¼Œè§†ä¸ºæ— ç”¨é“¾æ¥'
    prompt = JUDGE_LINK_USEFULNESS_PROMPT.format(
        industry=industry,
        title=link_info.get('title', ''),
        body=summary, # ä½¿ç”¨ body
        href=link_info.get('href', '') # ä½¿ç”¨ href
    )
    resp = call_llm(prompt)
    result = parse_custom_structured_text(resp, ['reason', 'useful'])
    is_useful = str(result.get('useful','')).strip().lower() == 'true'
    return is_useful, result.get('reason','')


"""
ç¤ºä¾‹ç”¨æ³•
"""

# ================== æ”¯æŒå¤šä¸»é¢˜æ‰¹é‡æœç´¢ ==================
SEARCH_TOPICS = [
    # {
    #     "search_topic": "æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡",
    #     "max_rounds": 100,
    #     "desc": "èšåˆè¡Œä¸šå‘å±•ç›¸å…³æ•°æ®ï¼Œè¡Œä¸šç”Ÿå‘½å‘¨æœŸä¸ç»“æ„è§£è¯»ï¼Œæ”¿ç­–å½±å“ã€æŠ€æœ¯æ¼”è¿›ï¼Œè¡Œä¸šè¿›å…¥ä¸é€€å‡ºç­–ç•¥å»ºè®®ï¼Œä¸Šæ¸¸åŸææ–™ä»·æ ¼ï¼Œè¡Œä¸šè§„æ¨¡å˜åŠ¨ã€ç«äº‰æ ¼å±€"
    # },
    {
        "search_topic": "ç”Ÿæˆå¼AIåŸºå»ºä¸ç®—åŠ›æŠ•èµ„è¶‹åŠ¿ï¼ˆ2023-2026ï¼‰",
        "max_rounds": 6,
        "desc": "æ”¿ç­–ä¿¡æ¯ï¼Œæ”¿ç­–è”åŠ¨ä¸åŒºåŸŸå¯¹æ¯”ä¿¡æ¯ï¼Œç¾è”å‚¨åˆ©ç‡å˜åŠ¨å¯¹å…¨çƒèµ„æœ¬æµåŠ¨çš„å½±å“ï¼Œç°çŠ€ç‰›äº‹ä»¶"
    },
    # {
    #     "search_topic": "å•†æ±¤ç§‘æŠ€",
    #     "max_rounds": 100,
    #     "desc": "ä¸»è¥ä¸šåŠ¡ã€æ ¸å¿ƒç«äº‰åŠ›ä¸è¡Œä¸šåœ°ä½ï¼Œè¡Œä¸šå¯¹æ¯”åˆ†æï¼Œç«äº‰åˆ†æï¼Œå…¬å¼€æ•°æ®ä¸ç®¡ç†å±‚ä¿¡æ¯ï¼Œæ²»ç†ç»“æ„ä¸å‘å±•æˆ˜ç•¥"
    # }
]

# ================== æœç´¢æ—¶é—´è®°å½•å·¥å…· ==================

def record_search_time(shared, event="search"):
    if "search_times" not in shared:
        shared["search_times"] = []
    shared["search_times"].append({
        "event": event,
        "timestamp": time.strftime('%Y-%m-%d %H:%M:%S')
    })


# ================== Streamlité¡µé¢ä¸»ä½“ ==================
def main():
    st.title("æ·±åº¦æœç´¢åŠ©æ‰‹")
    st.markdown("""
    è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨äººå·¥æ™ºèƒ½å¢å¼ºçš„æ·±åº¦æœç´¢å·¥å…·ï¼Œå¯ä»¥é€šè¿‡å¤šè½®è¿­ä»£æœç´¢æ·±å…¥æ”¶é›†è¡Œä¸šä¿¡æ¯ã€‚
    """)

    # åˆå§‹åŒ– Google æœç´¢æ±  (åœ¨ä¼šè¯çŠ¶æ€ä¸­ç¼“å­˜)
    if "google_search_pool" not in st.session_state:
        pool = GoogleSearchPool()
        try:
            # ä»ç¯å¢ƒå˜é‡åŠ è½½ç¬¬ä¸€ä¸ªå®¢æˆ·ç«¯
            api_key_1 = os.getenv("GOOGLE_API_KEY")
            engine_id_1 = os.getenv("GOOGLE_ENGINE_ID")
            if api_key_1 and engine_id_1:
                pool.add_client(api_key_1, engine_id_1, daily_limit=90) # ç¤ºä¾‹é™åˆ¶
            
            # å¯ä»¥æ·»åŠ æ›´å¤šå®¢æˆ·ç«¯çš„é€»è¾‘ï¼Œä¾‹å¦‚ GOOGLE_API_KEY_2, GOOGLE_ENGINE_ID_2
            # api_key_2 = os.getenv("GOOGLE_API_KEY_2")
            # engine_id_2 = os.getenv("GOOGLE_ENGINE_ID_2")
            # if api_key_2 and engine_id_2:
            #     pool.add_client(api_key_2, engine_id_2, daily_limit=90)

        except Exception as e:
            st.sidebar.error(f"åˆå§‹åŒ–Googleæœç´¢æ± å¤±è´¥: {e}")
        st.session_state.google_search_pool = pool
        
    google_search_pool = st.session_state.google_search_pool

    # ä¾§è¾¹æ è®¾ç½®
    with st.sidebar:
        st.header("æœç´¢é…ç½®")
        search_topic = st.text_input("æœç´¢ä¸»é¢˜", value="ç”Ÿæˆå¼AIåŸºå»ºä¸ç®—åŠ›æŠ•èµ„è¶‹åŠ¿ï¼ˆ2023-2026ï¼‰")
        max_rounds = st.slider("æœ€å¤§æœç´¢è½®æ•°", min_value=1, max_value=10, value=6)
        max_invalid_rounds = st.slider("æœ€å¤§æ— æ•ˆè½®æ•°", min_value=1, max_value=5, value=3)
        # æ–°å¢ï¼šæœ€å¤§æœç´¢æ¬¡æ•°
        max_search_count = st.number_input("æœ€å¤§æœç´¢æ¬¡æ•°", min_value=1, max_value=100, value=15)
        topic_desc = st.text_area("æœç´¢è¯´æ˜", value="æ”¿ç­–ä¿¡æ¯ï¼Œæ”¿ç­–è”åŠ¨ä¸åŒºåŸŸå¯¹æ¯”ä¿¡æ¯ï¼Œç¾è”å‚¨åˆ©ç‡å˜åŠ¨å¯¹å…¨çƒèµ„æœ¬æµåŠ¨çš„å½±å“ï¼Œç°çŠ€ç‰›äº‹ä»¶")
        start_button = st.button("å¼€å§‹æœç´¢")
        
        # æ˜¾ç¤ºAPIå¯†é’¥çŠ¶æ€
        api_key_status = "å·²é…ç½® âœ“" if openai.api_key else "æœªé…ç½® âœ—"
        st.info(f"OpenAI APIå¯†é’¥: {api_key_status}")

        google_api_configured = bool(os.getenv("GOOGLE_API_KEY") and os.getenv("GOOGLE_ENGINE_ID"))
        google_api_status = "å·²é…ç½® âœ“" if google_api_configured else "æœªé…ç½® âœ—"
        st.info(f"Google APIå‡­æ®: {google_api_status}")
        if not google_api_configured:
            st.warning("Google APIå¯†é’¥æˆ–æœç´¢å¼•æ“IDæœªåœ¨.envæ–‡ä»¶ä¸­é…ç½®ã€‚æœç´¢åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚")
        
        if google_search_pool and google_search_pool.clients:
            st.success(f"Googleæœç´¢æ± å·²åŠ è½½ {len(google_search_pool.clients)} ä¸ªå®¢æˆ·ç«¯ã€‚")
            # google_search_pool.display_usage_stats() # ä¸é€‚åˆåœ¨sidebaré‡Œç›´æ¥æ‰“å°ï¼Œä¿¡æ¯å¤ªå¤š
        else:
            st.error("Googleæœç´¢æ± æœªæˆåŠŸåŠ è½½å®¢æˆ·ç«¯ã€‚")

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if "search_running" not in st.session_state:
        st.session_state.search_running = False
    if "search_complete" not in st.session_state:
        st.session_state.search_complete = False
    if "shared_state" not in st.session_state:
        st.session_state.shared_state = {}
    
    # å¤„ç†æœç´¢æŒ‰é’®ç‚¹å‡»äº‹ä»¶
    if start_button:
        if not openai.api_key:
            st.error("è¯·å…ˆé…ç½®OpenAI APIå¯†é’¥")
        elif not google_api_configured or not google_search_pool.clients:
            st.error("Google APIæœªé…ç½®æˆ–æœç´¢æ± æ— å®¢æˆ·ç«¯ï¼Œæ— æ³•å¼€å§‹æœç´¢ã€‚è¯·æ£€æŸ¥.envæ–‡ä»¶å’Œé…ç½®ã€‚")
        else:
            st.session_state.search_running = True
            st.session_state.search_complete = False
            st.session_state.shared_state = {
                "search_topic": search_topic,
                "max_rounds": max_rounds,
                "max_invalid_rounds": max_invalid_rounds,
                "max_search_count": max_search_count,  # æ–°å¢
                "total_search_count": 0,               # æ–°å¢
                "search_context": [],
                "search_round": 0,
                "useful_links": [],
                "useless_links": [],
                "search_times": [],
                "search_pool": google_search_pool # æ–°å¢ï¼šå°†æœç´¢æ± å®ä¾‹ä¼ é€’ç»™å…±äº«çŠ¶æ€
            }
            record_search_time(st.session_state.shared_state, event="search_start")
            st.rerun()  # æ›´æ–°: ä» experimental_rerun åˆ° rerun
    
    # æ˜¾ç¤ºæœç´¢çŠ¶æ€
    if st.session_state.search_running:
        if not st.session_state.search_complete:
            run_search_workflow()
        else:
            display_search_results()
    
    # æ˜¾ç¤ºAboutä¿¡æ¯
    with st.expander("å…³äºæ·±åº¦æœç´¢åŠ©æ‰‹"):
        st.markdown("""
        ### æ·±åº¦æœç´¢åŠ©æ‰‹
        
        è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨äººå·¥æ™ºèƒ½å¢å¼ºçš„æœç´¢å·¥å…·ï¼Œé€šè¿‡å¤šè½®è¿­ä»£æœç´¢æ·±å…¥æ”¶é›†ç›¸å…³ä¿¡æ¯ã€‚
        
        **ç‰¹ç‚¹:**
        - æ™ºèƒ½åˆ†æå·²æ”¶é›†ä¿¡æ¯å¹¶ç”Ÿæˆæ–°æœç´¢å…³é”®è¯
        - è‡ªåŠ¨åˆ¤æ–­æœç´¢ç»“æœçš„æœ‰ç”¨æ€§
        - å»é‡å¹¶ç´¯è®¡æœ‰ç”¨/æ— ç”¨é“¾æ¥
        - ç”Ÿæˆç»“æ„åŒ–æœç´¢æŠ¥å‘Š
        
        **ä½¿ç”¨æ–¹æ³•:**
        1. åœ¨ä¾§è¾¹æ è¾“å…¥æœç´¢ä¸»é¢˜
        2. è®¾ç½®æœ€å¤§æœç´¢è½®æ•°å’Œæ— æ•ˆè½®æ•°
        3. ç‚¹å‡»"å¼€å§‹æœç´¢"æŒ‰é’®
        4. ç­‰å¾…æœç´¢å®Œæˆå¹¶æŸ¥çœ‹ç»“æœ
        """)


def run_search_workflow():
    """æ‰§è¡Œæœç´¢å·¥ä½œæµ"""
    # åˆ›å»ºå·¥ä½œæµèŠ‚ç‚¹
    decision = SearchDecisionFlow()
    search = SearchInfo()
    summary = SearchSummary()
    
    # è®¾ç½®å·¥ä½œæµ
    shared_state = st.session_state.shared_state
    current_round = shared_state.get("search_round", 0)
    
    # åˆ›å»ºè¿›åº¦æŒ‡ç¤ºå™¨
    st.subheader("æœç´¢è¿›åº¦")
    st.write(f"å½“å‰è½®æ¬¡: {current_round + 1}/{shared_state['max_rounds']}")
    
    # æ ¹æ®å½“å‰çŠ¶æ€æ‰§è¡Œç›¸åº”çš„èŠ‚ç‚¹
    if "current_node" not in shared_state:
        shared_state["current_node"] = "decision"
    
    if shared_state["current_node"] == "decision":
        with st.spinner("æ­£åœ¨åˆ†æå¹¶å†³ç­–ä¸‹ä¸€æ­¥..."):
            prep_res = decision.prep(shared_state)
            exec_res = decision.exec(prep_res)
            next_node = decision.post(shared_state, prep_res, exec_res)
            shared_state["current_node"] = next_node
            st.rerun()  # æ›´æ–°: ä» experimental_rerun åˆ° rerun
    
    elif shared_state["current_node"] == "search":
        with st.spinner("æ­£åœ¨æ‰§è¡Œæœç´¢..."):
            prep_res = search.prep(shared_state)
            exec_res = search.exec(prep_res)
            next_node = search.post(shared_state, prep_res, exec_res)
            shared_state["current_node"] = next_node
            st.rerun()  # æ›´æ–°: ä» experimental_rerun åˆ° rerun
    
    elif shared_state["current_node"] == "complete":
        with st.spinner("æ­£åœ¨ç”Ÿæˆæœç´¢æŠ¥å‘Š..."):
            prep_res = summary.prep(shared_state)
            exec_res = summary.exec(prep_res)
            summary.post(shared_state, prep_res, exec_res)
            st.session_state.search_complete = True
            st.rerun()  # æ›´æ–°: ä» experimental_rerun åˆ° rerun


def display_search_results():
    """æ˜¾ç¤ºæœç´¢ç»“æœ"""
    shared_state = st.session_state.shared_state
    
    st.header("ğŸ‰ æœç´¢å®Œæˆ!")
    st.subheader(f"ä¸»é¢˜: {shared_state['search_topic']}")
    
    total_results = 0
    if "useful_links" in shared_state:
        total_results = len(shared_state["useful_links"])
    
    st.write(f"æ€»å…±æœç´¢è½®æ¬¡: {shared_state.get('search_round', 0)}")
    st.write(f"æ”¶é›†åˆ°æœ‰ç”¨ä¿¡æ¯: {total_results} æ¡")
    
    # æ˜¾ç¤ºæœç´¢æŠ¥å‘Š
    if "summary" in shared_state and shared_state["summary"]:
        with st.expander("æŸ¥çœ‹æœç´¢æŠ¥å‘Š", expanded=True):
            st.markdown(shared_state["summary"])
        
        # æä¾›ä¸‹è½½æŒ‰é’®
        st.download_button(
            label="ä¸‹è½½æœç´¢æŠ¥å‘Š",
            data=shared_state["summary"],
            file_name=f"{shared_state['search_topic']}_æœç´¢æŠ¥å‘Š.md",
            mime="text/markdown",
        )
    
    # æ·»åŠ é‡æ–°å¼€å§‹æŒ‰é’®
    if st.button("å¼€å§‹æ–°çš„æœç´¢"):
        st.session_state.search_running = False
        st.session_state.search_complete = False
        st.session_state.shared_state = {}
        st.rerun()  # æ›´æ–°: ä» experimental_rerun åˆ° rerun


if __name__ == "__main__":
    main()
