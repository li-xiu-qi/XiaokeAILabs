# -*- coding: utf-8 -*-
"""
åˆ©ç”¨å¤§æ¨¡å‹APIæ¸…ç†çº¢æ¥¼æ¢¦æ¯ä¸€å›çš„å™ªå£°å’Œæ’ç‰ˆ
"""

import os
import asyncio
from typing import List
from fallback_openai_client import AsyncFallbackOpenAIClient
import re

def _split_text_into_smart_chunks_helper(
    text_block: str, target_chunk_size: int = 1500, max_chunk_size: int = 3500
) -> list:
    """
    æŒ‰ç…§ç»“å°¾ç¬¦å·å’Œç›®æ ‡é•¿åº¦æ™ºèƒ½åˆ†å‰²æ–‡æœ¬ä¸ºå¤šä¸ªå—
    """
    sub_chunks = []
    if not text_block.strip():
        return sub_chunks

    sentence_end_punctuations = ["ã€‚", "ï¼", "ï¼Ÿ", "â€", "â€™", "â€¦", ".", "!", "?"]
    lines = text_block.splitlines(keepends=True)
    current_chunk_lines = []
    current_char_count = 0

    def ends_with_punctuation(line_list):
        if not line_list:
            return False
        for line_idx in range(len(line_list) - 1, -1, -1):
            last_line_stripped = line_list[line_idx].rstrip()
            if last_line_stripped:
                return last_line_stripped[-1] in sentence_end_punctuations
        return False

    i = 0
    while i < len(lines):
        current_chunk_lines.append(lines[i])
        current_char_count += len(lines[i])

        if current_char_count >= target_chunk_size:
            split_at_line_idx_in_current_chunk = -1
            search_end = len(current_chunk_lines) - 1
            for k in range(search_end, -1, -1):
                chunk_so_far = "".join(current_chunk_lines[:k+1])
                if len(chunk_so_far) < target_chunk_size:
                    break
                if len(chunk_so_far) <= max_chunk_size and ends_with_punctuation(current_chunk_lines[:k+1]):
                    split_at_line_idx_in_current_chunk = k
                    break
            if split_at_line_idx_in_current_chunk == -1 and current_char_count >= max_chunk_size:
                split_at_line_idx_in_current_chunk = len(current_chunk_lines) - 1

            if split_at_line_idx_in_current_chunk != -1:
                content = "".join(current_chunk_lines[:split_at_line_idx_in_current_chunk+1]).strip()
                if content:
                    sub_chunks.append(content)
                current_chunk_lines = current_chunk_lines[split_at_line_idx_in_current_chunk+1:]
                current_char_count = sum(len(l) for l in current_chunk_lines)
        i += 1

    if current_chunk_lines:
        content = "".join(current_chunk_lines).strip()
        if content:
            sub_chunks.append(content)
    return sub_chunks

async def clean_chapter_content(chapter_title: str, chapter_content: str, client: AsyncFallbackOpenAIClient, idx: int, total: int, semaphore: asyncio.Semaphore) -> str:
    """
    ä½¿ç”¨å¤§æ¨¡å‹APIæ¸…ç†å•ä¸ªç« èŠ‚å†…å®¹ï¼ˆå¸¦åˆ†å—å’Œå¹¶å‘æ§åˆ¶ï¼Œå…ˆåˆ¤æ–­æ˜¯å¦éœ€è¦æ¸…ç†ï¼‰
    """
    chunks = _split_text_into_smart_chunks_helper(chapter_content, target_chunk_size=1500, max_chunk_size=3500)
    cleaned_chunks = []
    for chunk_idx, chunk in enumerate(chunks):
        async with semaphore:
            # ç¬¬ä¸€æ­¥ï¼šè®©å¤§æ¨¡å‹åˆ¤æ–­æ˜¯å¦éœ€è¦æ¸…ç†ï¼Œè¦æ±‚è¾“å‡ºåŸå› å’Œç»“æœ
            judge_prompt = f"""è¯·åˆ¤æ–­ä¸‹é¢çš„æ–‡æœ¬æ˜¯å¦åŒ…å«å¦‚ä¸‹å†…å®¹ï¼šç‰ˆæƒå£°æ˜ã€é¡µç ã€æ³¨é‡Šã€æ— å…³å™ªå£°ã€æ’ç‰ˆæ··ä¹±ç­‰éæ­£æ–‡å†…å®¹ã€‚
<è¾“å‡ºæ ¼å¼è¦æ±‚>
åŸå› ï¼šï¼ˆä½¿ç”¨10-40å­—ç®€è¦è¯´æ˜ä½ çš„åˆ¤æ–­ç†ç”±,ä¸éœ€è¦æ¸…ç†åˆ™ä¸ºnullï¼‰
ç»“æœï¼šï¼ˆåªè¾“å‡ºâ€œéœ€è¦æ¸…ç†â€æˆ–â€œä¸éœ€è¦æ¸…ç†â€ï¼‰

æ–‡æœ¬å¦‚ä¸‹ï¼š
{chunk}
"""
            judge_messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„ä¸­æ–‡å¤å…¸å°è¯´æ–‡æœ¬æ¸…ç†åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": judge_prompt}
            ]
            try:
                judge_result = await client.chat_completions_create(
                    messages=judge_messages,
                    max_tokens=400,
                    temperature=0.0,
                    top_p=0.6,
                )
                judge_reply = judge_result.choices[0].message.content.strip()
                m = re.search(r"ç»“æœ[:ï¼š]\s*(éœ€è¦æ¸…ç†|ä¸éœ€è¦æ¸…ç†)", judge_reply)
                if m:
                    result_str = m.group(1)
                    need_clean = (result_str == "éœ€è¦æ¸…ç†")
                else:
                    print(f"âš ï¸ åˆ¤æ–­å›å¤æ— æ³•è¯†åˆ«ï¼Œé»˜è®¤è·³è¿‡æ¸…ç†æµç¨‹ï¼Œå›å¤å†…å®¹: {judge_reply}")
                    need_clean = False
            except Exception as e:
                print(f"âš ï¸ åˆ¤æ–­ç¬¬{idx+1}å›ç¬¬{chunk_idx+1}å—æ˜¯å¦éœ€è¦æ¸…ç†æ—¶å‡ºé”™: {e}ï¼Œé»˜è®¤è·³è¿‡æ¸…ç†æµç¨‹")
                need_clean = False
            # æ‰“å°ä¸‹chunkçš„é•¿åº¦
            print(f"ğŸ” åˆ¤æ–­ç¬¬{idx+1}/{total}å›ï¼Œç¬¬{chunk_idx+1}/{len(chunks)}å— | é•¿åº¦: {len(chunk)} | ç»“æœ: {result_str} | åŸå› : {judge_reply}")
            if need_clean:
                # ç¬¬äºŒæ­¥ï¼šçœŸæ­£æ¸…ç†
                prompt = f"""ä½ æ˜¯çº¢æ¥¼æ¢¦æ–‡æœ¬æ¸…ç†åŠ©æ‰‹ã€‚è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œæ¸…ç†ï¼š
1. åˆ é™¤æ‰€æœ‰ç‰ˆæƒå£°æ˜ã€é¡µç ã€æ³¨é‡Šã€æ— å…³å™ªå£°ï¼Œä»…ä¿ç•™æ­£æ–‡å†…å®¹ã€‚
2. ä¿®å¤æ’ç‰ˆé”™è¯¯ï¼Œä½¿æ–‡æœ¬æ®µè½æ¸…æ™°ã€æ ¼å¼è§„èŒƒã€‚
3. ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ³¨é‡Šï¼Œåªè¾“å‡ºæ¸…ç†åçš„æ­£æ–‡ã€‚

ç« èŠ‚æ ‡é¢˜ï¼š{chapter_title}
åŸå§‹æ–‡æœ¬å¦‚ä¸‹ï¼š
{chunk}
"""
                messages = [
                    {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„ä¸­æ–‡å¤å…¸å°è¯´æ–‡æœ¬æ¸…ç†åŠ©æ‰‹ã€‚"},
                    {"role": "user", "content": prompt}
                ]
                try:
                    completion = await client.chat_completions_create(
                        messages=messages,
                        max_tokens=4096,
                        temperature=0.1,
                        top_p=0.7,
                    )
                    cleaned = completion.choices[0].message.content.strip()
                    print(f"âœ… å·²æ¸…ç†ç¬¬{idx+1}/{total}å›ï¼Œç¬¬{chunk_idx+1}/{len(chunks)}å— | åŸé•¿åº¦: {len(chunk)}ï¼Œæ¸…ç†å: {len(cleaned)}")
                    cleaned_chunks.append(cleaned)
                except Exception as e:
                    print(f"âŒ æ¸…ç†ç¬¬{idx+1}å›ç¬¬{chunk_idx+1}å—å¤±è´¥: {e}")
                    cleaned_chunks.append(chunk)
            else:
                print(f"â¡ï¸ è·³è¿‡æ¸…ç†ç¬¬{idx+1}/{total}å›ï¼Œç¬¬{chunk_idx+1}/{len(chunks)}å—ï¼ˆæ— éœ€æ¸…ç†ï¼‰ | é•¿åº¦: {len(chunk)}")
                cleaned_chunks.append(chunk)
    # æ‰“å°æ¯å›æ•´ä½“é•¿åº¦å¯¹æ¯”
    cleaned_text = "\n".join(cleaned_chunks)
    print(f"ğŸ“ å›ç›®ã€Š{chapter_title}ã€‹æ¸…ç†å‰æ€»é•¿åº¦: {len(chapter_content)}ï¼Œæ¸…ç†åæ€»é•¿åº¦: {len(cleaned_text)}")
    return cleaned_text

async def main():
    input_file = "./çº¢æ¥¼æ¢¦ç®€ä½“ç‰ˆæœ¬_async.txt"
    output_dir = "./çº¢æ¥¼æ¢¦_æŒ‰å›æ¸…ç†"
    max_concurrent = 200  # æœ€å¤§å¹¶å‘æ•°
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # è¯»å–å…¨ä¹¦æ–‡æœ¬
    with open(input_file, "r", encoding="utf-8") as f:
        text = f.read()

    # æŒ‰å›åˆ†å‰²ï¼ˆå¤ç”¨split_by_chapter.pyçš„æ­£åˆ™é€»è¾‘ï¼‰
    pattern = re.compile(r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ\d]+å›[^\n]*', re.MULTILINE)
    matches = list(pattern.finditer(text))
    chapters = []
    for idx, match in enumerate(matches):
        start = match.start()
        if idx > 0:
            prev_match = matches[idx-1]
            chapter_title = prev_match.group(0)
            chapter_content = text[prev_match.start():start]
            chapters.append((chapter_title, chapter_content.strip()))
    if matches:
        last_match = matches[-1]
        chapter_title = last_match.group(0)
        chapter_content = text[last_match.start():]
        chapters.append((chapter_title, chapter_content.strip()))

    print(f"å…±æ£€æµ‹åˆ° {len(chapters)} å›ï¼Œå¼€å§‹æ¸…ç†...")

    # å†—ä½™è®¾è®¡ï¼šä¸»APIå’Œå¤‡ç”¨APIå‡ä»ç¯å¢ƒå˜é‡è¯»å–
    zhipu_api_key = os.getenv("ZHIPU_API_KEY")
    zhipu_base_url = os.getenv("ZHIPU_BASE_URL")
    zhipu_model_name = "glm-4-flash"

    guiji_api_key = os.getenv("GUIJI_API_KEY")
    guiji_base_url = os.getenv("GUIJI_BASE_URL")
    guiji_model_name = "THUDM/GLM-4-9B-0414"

    client = AsyncFallbackOpenAIClient(
        primary_api_key=zhipu_api_key,
        primary_base_url=zhipu_base_url,
        primary_model_name=zhipu_model_name,
        fallback_api_key=guiji_api_key,
        fallback_base_url=guiji_base_url,
        fallback_model_name=guiji_model_name,
    )

    semaphore = asyncio.Semaphore(max_concurrent)

    async with client:
        tasks = []
        for idx, (title, content) in enumerate(chapters):
            tasks.append(clean_chapter_content(title, content, client, idx, len(chapters), semaphore))
        cleaned_list: List[str] = await asyncio.gather(*tasks)

        # ä¿å­˜æ¸…ç†åçš„ç« èŠ‚
        for idx, cleaned in enumerate(cleaned_list):
            filename = f"chapter_{idx+1:03d}.txt"
            out_path = os.path.join(output_dir, filename)
            with open(out_path, "w", encoding="utf-8") as f:
                f.write(cleaned)
            print(f"å·²ä¿å­˜æ¸…ç†åæ–‡ä»¶: {out_path}")

    print("å…¨éƒ¨ç« èŠ‚æ¸…ç†å®Œæˆï¼")

if __name__ == "__main__":
    asyncio.run(main())
