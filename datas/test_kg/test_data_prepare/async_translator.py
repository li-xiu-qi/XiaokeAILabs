# -*- coding: utf-8 -*-
"""
å¼‚æ­¥çº¢æ¥¼æ¢¦ç¹ä½“è½¬ç®€ä½“ç¿»è¯‘å™¨ - æ”¯æŒ200ä¸ªå¹¶å‘
"""

import os
import asyncio
import json
import time
from typing import List
from dotenv import load_dotenv
from fallback_openai_client import AsyncFallbackOpenAIClient 

load_dotenv(dotenv_path=".env")


def _split_text_into_smart_chunks_helper(
    text_block: str, target_chunk_size: int = 512, max_chunk_size: int = 4000
) -> List[str]:
    sub_chunks: List[str] = []
    if not text_block.strip():
        return sub_chunks

    sentence_end_punctuations = ["ã€‚", "ï¼", "ï¼Ÿ", "â€", "â€™", "â€¦", ".", "!", "?"]
    lines = text_block.splitlines(keepends=True)
    current_chunk_lines: List[str] = []
    current_char_count = 0

    def ends_with_punctuation(line_list: List[str]) -> bool:
        if not line_list:
            return False
        for line_idx in range(len(line_list) - 1, -1, -1):
            last_line_stripped = line_list[line_idx].rstrip()
            if last_line_stripped:
                return last_line_stripped[-1] in sentence_end_punctuations
        return False

    i = 0
    while i < len(lines):
        current_chunk_lines.append(lines[i])
        current_char_count += len(lines[i])

        # è¾¾åˆ°ç›®æ ‡å—å¤§å°ï¼Œå°è¯•åœ¨ç›®æ ‡å—é™„è¿‘ä¼˜å…ˆåˆ‡åˆ†
        if current_char_count >= target_chunk_size:
            # ä¼˜å…ˆåœ¨å½“å‰å—å†…çš„ç›®æ ‡åŒºé—´é™„è¿‘æ‰¾åˆ‡åˆ†ç‚¹
            split_at_line_idx_in_current_chunk = -1
            # å…è®¸æµ®åŠ¨åˆ°max_chunk_size
            search_end = len(current_chunk_lines) - 1
            search_start = 0
            # åªåœ¨ç›®æ ‡åŒºé—´åˆ°æœ€å¤§åŒºé—´å†…æ‰¾åˆ‡åˆ†ç‚¹
            for k in range(search_end, -1, -1):
                chunk_so_far = "".join(current_chunk_lines[:k+1])
                if len(chunk_so_far) < target_chunk_size:
                    break
                if len(chunk_so_far) <= max_chunk_size and ends_with_punctuation(current_chunk_lines[:k+1]):
                    split_at_line_idx_in_current_chunk = k
                    break
            # å¦‚æœæ²¡æ‰¾åˆ°åˆé€‚åˆ‡ç‚¹ï¼Œå…è®¸å—é•¿åº¦åˆ°max_chunk_size
            if split_at_line_idx_in_current_chunk == -1 and current_char_count >= max_chunk_size:
                split_at_line_idx_in_current_chunk = len(current_chunk_lines) - 1

            if split_at_line_idx_in_current_chunk != -1:
                content = "".join(current_chunk_lines[:split_at_line_idx_in_current_chunk+1]).strip()
                if content:
                    sub_chunks.append(content)
                current_chunk_lines = current_chunk_lines[split_at_line_idx_in_current_chunk+1:]
                current_char_count = sum(len(l) for l in current_chunk_lines)
        i += 1

    # å¤„ç†å‰©ä½™éƒ¨åˆ†
    if current_chunk_lines:
        content = "".join(current_chunk_lines).strip()
        if content:
            sub_chunks.append(content)
    return sub_chunks


# ä¿®æ”¹åçš„ç®€å•æ–‡æœ¬åˆ†å‰²å‡½æ•° (ç›®æ ‡512ï¼Œæœ€å¤§4000)
def simple_text_splitter(full_text: str, target_chunk_size: int = 512, max_chunk_size: int = 4000) -> List[str]:
    chunks: List[str] = []
    if not full_text.strip():
        chunks.append("")
        return chunks

    chunks.extend(_split_text_into_smart_chunks_helper(full_text, target_chunk_size, max_chunk_size))

    if not chunks and full_text.strip():
        chunks.append(full_text.strip())
    elif not chunks and not full_text.strip():
        chunks.append("")

    return chunks


class AsyncTraditionalToSimplifiedTranslator:
    """å¼‚æ­¥ç¹ä½“åˆ°ç®€ä½“çš„ç¿»è¯‘å™¨"""

    def __init__(self, max_concurrent: int = 200):
        """
        åˆå§‹åŒ–å¼‚æ­¥ç¿»è¯‘å™¨
        Args:
            max_concurrent: æœ€å¤§å¹¶å‘æ•°
        """
        zhipu_api_key = os.getenv("ZHIPU_API_KEY")
        zhipu_base_url = os.getenv("ZHIPU_BASE_URL")
        zhipu_model_name = "glm-4-flash"

        guiji_api_key = os.getenv("GUIJI_API_KEY")
        guiji_base_url = os.getenv("GUIJI_BASE_URL")
        guiji_model_name = "THUDM/GLM-4-9B-0414"

        if not zhipu_api_key or not zhipu_base_url:
            raise ValueError(
                "é”™è¯¯ï¼šä¸» API (ZHIPU_API_KEY, ZHIPU_BASE_URL) ç¯å¢ƒå˜é‡æœªå®Œå…¨è®¾ç½®ã€‚"
            )

        self.client = AsyncFallbackOpenAIClient(
            primary_api_key=zhipu_api_key,
            primary_base_url=zhipu_base_url,
            primary_model_name=zhipu_model_name,
            fallback_api_key=guiji_api_key,
            fallback_base_url=guiji_base_url,
            fallback_model_name=guiji_model_name,
        )

        self.max_concurrent = max_concurrent
        self.semaphore = asyncio.Semaphore(max_concurrent)

    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        await self.client.__aenter__()  # è°ƒç”¨å°è£…å®¢æˆ·ç«¯çš„ __aenter__
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡º"""
        await self.client.__aexit__(
            exc_type, exc_val, exc_tb
        )  # è°ƒç”¨å°è£…å®¢æˆ·ç«¯çš„ __aexit__

    async def translate_chunk(
        self, chunk: str, chunk_index: int, total_chunks: int
    ) -> str:
        """
        å¼‚æ­¥ç¿»è¯‘å•ä¸ªæ–‡æœ¬å—
        å‚æ•°:
            chunk: è¦ç¿»è¯‘çš„æ–‡æœ¬å—
            chunk_index: å½“å‰å—çš„ç´¢å¼•
            total_chunks: æ€»å—æ•°
        è¿”å›:
            ç¿»è¯‘åçš„æ–‡æœ¬å—
        """
        async with self.semaphore:  # æ§åˆ¶å¹¶å‘æ•°
            # æ£€æŸ¥ chunk.content æ˜¯å¦ä¸ºç©ºæˆ–ä»…åŒ…å«ç©ºç™½å­—ç¬¦
            if not chunk or chunk.isspace():
                print(f"â„¹ï¸ è·³è¿‡ç©ºæ–‡æœ¬å— [{chunk_index+1}/{total_chunks}]")
                return chunk
            try:
                prompt_content = f"""è¯·å°†ä»¥ä¸‹ç¹ä½“ä¸­æ–‡æ–‡æœ¬è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡ï¼Œä¿æŒåŸæ–‡çš„æ–‡å­¦é£æ ¼å’ŒéŸµå‘³ï¼Œä¸è¦æ”¹å˜ä»»ä½•å†…å®¹çš„å«ä¹‰ï¼š

{chunk}

è¦æ±‚ï¼š
1. åªè¿›è¡Œç¹ä½“åˆ°ç®€ä½“çš„è½¬æ¢
2. æ ‡ç‚¹ç¬¦å·åŒæ ·éœ€è¦è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡çš„å½¢å¼
3. ä¿æŒå¤å…¸æ–‡å­¦çš„è¯­è¨€é£æ ¼
4. ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ³¨é‡Š
5. ç›´æ¥è¾“å‡ºè½¬æ¢åçš„ç®€ä½“ä¸­æ–‡æ–‡æœ¬
"""
                full_prompt = f"{prompt_content}"

                messages = [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡ç¹ç®€è½¬æ¢åŠ©æ‰‹ï¼Œä¸“é—¨å°†ç¹ä½“ä¸­æ–‡è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡ã€‚",
                    },
                    {"role": "user", "content": full_prompt},
                ]

                try:
                    # ä½¿ç”¨å°è£…çš„å®¢æˆ·ç«¯è¿›è¡Œ API è°ƒç”¨
                    completion = await self.client.chat_completions_create(
                        messages=messages,
                        max_tokens=4096,
                        temperature=0.1,
                        top_p=0.7,
                        # model å‚æ•°ç”± AsyncFallbackOpenAIClient å†…éƒ¨å¤„ç†
                    )
                    translated_content = completion.choices[0].message.content.strip()
                    # å¯ä»¥åœ¨æ­¤å¤„æ ¹æ® completion.response_ms æˆ–å…¶ä»–è¿”å›ä¿¡æ¯åˆ¤æ–­æ˜¯å“ªä¸ª API æˆåŠŸçš„
                    # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬å‡è®¾æˆåŠŸå³æ˜¯ä¸» API æˆ–å¤‡ç”¨ API ä¹‹ä¸€
                    print(f"âœ… å·²ç¿»è¯‘ (API) [{chunk_index+1}/{total_chunks}]")
                    return translated_content
                # å¼‚å¸¸å¤„ç†ç°åœ¨ç”± AsyncFallbackOpenAIClient å†…éƒ¨å¤„ç†ä¸€éƒ¨åˆ†ï¼Œè¿™é‡Œæ•è·æœ€ç»ˆæœªèƒ½å¤„ç†çš„å¼‚å¸¸
                except Exception as e:
                    print(
                        f"âŒ API è°ƒç”¨æœ€ç»ˆå¤±è´¥ [{chunk_index+1}/{total_chunks}]: {type(e).__name__} - {str(e)}"
                    )

                # å¦‚æœ API è°ƒç”¨æœ€ç»ˆå¤±è´¥ (åŒ…æ‹¬ä¸» API å’Œå¤‡ç”¨ API)ï¼Œåˆ™ä½¿ç”¨åŸæ–‡
                print(f"â„¹ï¸ ç¿»è¯‘å¤±è´¥ï¼Œä½¿ç”¨åŸæ–‡ [{chunk_index+1}/{total_chunks}]")
                return chunk
            except Exception as e:  # æ•è· translate_chunk æ–¹æ³•å†…çš„å…¶ä»–æ‰€æœ‰æœªé¢„æœŸå¼‚å¸¸
                print(
                    f"âŒ ç¿»è¯‘å—å¤„ç†å¤±è´¥ [{chunk_index+1}/{total_chunks}]: {type(e).__name__}: {str(e)}"
                )
                return chunk

    async def translate_chunks(self, chunks: List[str]) -> List[str]:
        """
        å¼‚æ­¥ç¿»è¯‘æ‰€æœ‰æ–‡æœ¬å—
        å‚æ•°:
            chunks: æ–‡æœ¬å—åˆ—è¡¨
        è¿”å›:
            ç¿»è¯‘åçš„æ–‡æœ¬å—åˆ—è¡¨
        """
        print(f"ğŸš€ å¼€å§‹å¼‚æ­¥ç¿»è¯‘ {len(chunks)} ä¸ªæ–‡æœ¬å—ï¼Œå¹¶å‘æ•°: {self.max_concurrent}")
        start_time = time.time()

        # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡
        tasks = [
            self.translate_chunk(chunk, i, len(chunks))
            for i, chunk in enumerate(chunks)
        ]

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ç¿»è¯‘ä»»åŠ¡
        translated_chunks = await asyncio.gather(*tasks, return_exceptions=True)

        # å¤„ç†å¼‚å¸¸ç»“æœ
        final_chunks = []
        for i, result in enumerate(translated_chunks):
            if isinstance(result, Exception):
                print(f"âŒ ä»»åŠ¡ {i+1} æ‰§è¡Œå¼‚å¸¸: {result}")
                final_chunks.append(chunks[i])
            else:
                final_chunks.append(result)
            # æ–°å¢ï¼šæ‰“å°è¾“å…¥è¾“å‡ºé•¿åº¦å¯¹æ¯”
            input_len = len(chunks[i]) if i < len(chunks) else 0
            output_len = len(result) if not isinstance(result, Exception) else input_len
            print(f"å— {i+1}: è¾“å…¥é•¿åº¦={input_len}ï¼Œè¾“å‡ºé•¿åº¦={output_len}")

        end_time = time.time()
        print(f"âœ… æ‰€æœ‰æ–‡æœ¬å—ç¿»è¯‘å®Œæˆï¼è€—æ—¶: {end_time - start_time:.2f} ç§’")
        return final_chunks


def save_translated_text(chunks: List[str], output_path: str):
    """
    ä¿å­˜ç¿»è¯‘åçš„æ–‡æœ¬
    å‚æ•°:
        chunks: ç¿»è¯‘åçš„æ–‡æœ¬å—åˆ—è¡¨
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    with open(output_path, "w", encoding="utf-8") as f:
        for chunk in chunks:
            f.write(chunk)
            f.write("\n")
    print(f"ğŸ’¾ ç¿»è¯‘ç»“æœå·²ä¿å­˜åˆ°: {output_path}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ® å¼‚æ­¥çº¢æ¥¼æ¢¦ç¹ä½“è½¬ç®€ä½“ç¿»è¯‘å·¥å…·")
    print(f"ğŸš€ æ”¯æŒ 200 ä¸ªå¹¶å‘è¯·æ±‚")
    print("=" * 50)

    # è¾“å…¥è¾“å‡ºæ–‡ä»¶è·¯å¾„
    input_file = r"./çº¢æ¥¼æ¢¦ç¹ä½“ç‰ˆæœ¬.txt"
    output_file = r"./çº¢æ¥¼æ¢¦ç®€ä½“ç‰ˆæœ¬_async.txt"
    target_chunk_size = 512      # ç›®æ ‡å—å¤§å°
    max_chunk_size = 4000        # æœ€å¤§å—å¤§å°

    # è¯»å–åŸæ–‡
    print("ğŸ“– è¯»å–åŸæ–‡...")
    try:
        with open(input_file, "r", encoding="utf-8") as f:
            text = f.read()
        print(f"âœ… æˆåŠŸè¯»å–æ–‡ä»¶ï¼Œæ€»å­—ç¬¦æ•°: {len(text)}")
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return

    # åˆ†å‰²æ–‡æœ¬
    print("\nğŸ“‘ åˆ†å‰²æ–‡æœ¬...")
    print(f"ğŸ“ ç›®æ ‡å—å¤§å°: {target_chunk_size} å­—ç¬¦ï¼Œæœ€å¤§å—å¤§å°: {max_chunk_size} å­—ç¬¦")
    chunks = simple_text_splitter(text, target_chunk_size, max_chunk_size)
    print(f"âœ… æ–‡æœ¬åˆ†å‰²å®Œæˆï¼Œå…± {len(chunks)} ä¸ªå—")

    # æ˜¾ç¤ºåˆ†å‰²ç»“æœ
    print("\nğŸ“‹ åˆ†å‰²ç»“æœé¢„è§ˆ:")
    for i, chunk in enumerate(chunks[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
        display_content = chunk if len(chunk) <= 30 else chunk[:30] + "..."
        print(f"  å— {i+1}: '{display_content}'")
    if len(chunks) > 5:
        print(f"  ... è¿˜æœ‰ {len(chunks) - 5} ä¸ªå—")

    # å¼‚æ­¥ç¿»è¯‘æ–‡æœ¬
    print("\nğŸ”„ å¼€å§‹å¼‚æ­¥ç¿»è¯‘...")
    async with AsyncTraditionalToSimplifiedTranslator(max_concurrent=200) as translator:
        translated_chunks = await translator.translate_chunks(chunks)

    # ä¿å­˜ç»“æœ
    print("\nğŸ’¾ ä¿å­˜ç¿»è¯‘ç»“æœ...")
    save_translated_text(translated_chunks, output_file)

    print("\nğŸ‰ ç¿»è¯‘å®Œæˆï¼")
    print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {input_file}")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")


if __name__ == "__main__":
    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    asyncio.run(main())
