{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0064e48",
   "metadata": {},
   "source": [
    "# JINA-CLIP-V2 多模态模型能力测试\n",
    "\n",
    "本notebook测试JINA-CLIP-V2模型在跨模态理解和嵌入方面的能力。我们将测试以下几个方面:\n",
    "\n",
    "1. 多语言文本嵌入与相似度\n",
    "2. 图像嵌入与相似度\n",
    "3. 跨模态(文本-图像)检索\n",
    "4. 零样本分类能力\n",
    "5. 多语言理解能力\n",
    "\n",
    "这些测试将帮助我们理解模型的实际性能和应用场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90254242",
   "metadata": {},
   "source": [
    "## 1. 环境设置与模型初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bc9577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装必要的库\n",
    "!pip install sentence-transformers requests tqdm matplotlib seaborn pillow scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3ee874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib\n",
    "\n",
    "# 为中文显示设置字体\n",
    "matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']  \n",
    "matplotlib.rcParams['axes.unicode_minus'] = False  # 正确显示负号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39dcc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型路径设置\n",
    "model_path = r\"C:\\Users\\k\\Desktop\\BaiduSyncdisk\\baidu_sync_documents\\hf_models\\jina-colbert-v2\"  # 本地模型路径\n",
    "# model_path = \"jinaai/jina-clip-v2\"  # 远程模型路径\n",
    "\n",
    "# 初始化模型\n",
    "model = SentenceTransformer(model_path, trust_remote_code=True)\n",
    "print(\"模型加载完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805e2dfc",
   "metadata": {},
   "source": [
    "## 2. 辅助函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7193a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制热力图的工具函数\n",
    "def plot_similarity_heatmap(embeddings, labels, title='Embeddings Similarity Heatmap', figsize=(12, 10), rotation=45):\n",
    "    \"\"\"\n",
    "    绘制嵌入向量之间的相似度热力图\n",
    "    \n",
    "    Args:\n",
    "        embeddings: 嵌入向量\n",
    "        labels: 标签列表\n",
    "        title: 热力图标题\n",
    "        figsize: 图形大小\n",
    "        rotation: x轴标签旋转角度\n",
    "    \"\"\"\n",
    "    # 计算相似度矩阵\n",
    "    if not np.allclose(np.linalg.norm(embeddings, axis=1), 1.0, atol=1e-5):\n",
    "        print(\"警告：嵌入向量可能未归一化。计算点积，对于归一化向量，点积等于余弦相似度。\")\n",
    "    similarity_matrix = embeddings @ embeddings.T\n",
    "    \n",
    "    # 绘制热力图\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(\n",
    "        similarity_matrix, \n",
    "        annot=True, \n",
    "        cmap='viridis', \n",
    "        fmt=\".2f\", \n",
    "        xticklabels=labels, \n",
    "        yticklabels=labels\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=rotation, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_cross_modal_similarity(img_embeds, text_embeds, img_labels, text_labels, title='Cross-Modal Similarity'):\n",
    "    \"\"\"\n",
    "    绘制跨模态相似度热力图\n",
    "    \n",
    "    Args:\n",
    "        img_embeds: 图像嵌入向量\n",
    "        text_embeds: 文本嵌入向量\n",
    "        img_labels: 图像标签列表\n",
    "        text_labels: 文本标签列表\n",
    "        title: 热力图标题\n",
    "    \"\"\"\n",
    "    # 计算图像与文本的相似度矩阵\n",
    "    similarity_matrix = img_embeds @ text_embeds.T\n",
    "    \n",
    "    # 绘制热力图\n",
    "    plt.figure(figsize=(14, len(img_labels) * 0.7))\n",
    "    sns.heatmap(\n",
    "        similarity_matrix, \n",
    "        annot=True, \n",
    "        cmap='viridis', \n",
    "        fmt=\".2f\", \n",
    "        xticklabels=text_labels, \n",
    "        yticklabels=img_labels\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.xlabel('文本')\n",
    "    plt.ylabel('图像')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def download_image(url, save_path):\n",
    "    \"\"\"\n",
    "    下载图片并保存到指定路径\n",
    "    \n",
    "    Args:\n",
    "        url: 图片URL\n",
    "        save_path: 保存路径\n",
    "        \n",
    "    Returns:\n",
    "        成功则返回保存路径，失败则返回None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        with open(save_path, 'wb') as file:\n",
    "            for chunk in tqdm(response.iter_content(chunk_size=8192),\n",
    "                             desc=f\"下载 {os.path.basename(url)}\",\n",
    "                             unit='KB', unit_scale=True):\n",
    "                file.write(chunk)\n",
    "        return save_path\n",
    "    except Exception as e:\n",
    "        print(f\"下载 {url} 时出错: {e}\")\n",
    "        return None\n",
    "    \n",
    "def display_images(image_paths, titles=None, figsize=(15, 10), columns=3):\n",
    "    \"\"\"\n",
    "    显示多张图片\n",
    "    \n",
    "    Args:\n",
    "        image_paths: 图片路径列表\n",
    "        titles: 标题列表\n",
    "        figsize: 图形大小\n",
    "        columns: 列数\n",
    "    \"\"\"\n",
    "    rows = (len(image_paths) + columns - 1) // columns\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    \n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        img = Image.open(image_path)\n",
    "        ax = fig.add_subplot(rows, columns, i + 1)\n",
    "        \n",
    "        if titles is not None and i < len(titles):\n",
    "            ax.set_title(titles[i])\n",
    "            \n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3389f100",
   "metadata": {},
   "source": [
    "## 3. 准备多语言文本和图像数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e18f9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建保存目录\n",
    "save_dir = 'images'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# 多样化的图片URL\n",
    "image_urls = [\n",
    "    'https://i.ibb.co/nQNGqL0/beach1.jpg',  # 海滩日落\n",
    "    'https://i.ibb.co/r5w8hG8/beach2.jpg',  # 另一个海滩日落\n",
    "    'https://i.ibb.co/Sx3mLpB/city-night.jpg',  # 城市夜景\n",
    "    'https://i.ibb.co/6WyNVHM/mountain.jpg',  # 山脉\n",
    "    'https://i.ibb.co/KmpJGz2/cat.jpg',  # 猫\n",
    "    'https://i.ibb.co/4RxpzWC/food.jpg'   # 食物\n",
    "]\n",
    "\n",
    "# 下载图片\n",
    "image_paths = []\n",
    "for i, url in enumerate(image_urls):\n",
    "    name = url.split('/')[-1]\n",
    "    save_path = os.path.join(save_dir, name)\n",
    "    result = download_image(url, save_path)\n",
    "    if result:\n",
    "        print(f\"已下载: {result}\")\n",
    "        image_paths.append(result)\n",
    "    else:\n",
    "        print(f\"下载失败: {url}\")\n",
    "\n",
    "# 图片名称标签\n",
    "image_labels = [os.path.splitext(os.path.basename(path))[0] for path in image_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d614f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示下载的图片\n",
    "display_images(image_paths, image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af3bd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多语言文本数据 - 关于海滩日落\n",
    "sunset_texts = {\n",
    "    '阿拉伯语': 'غروب جميل على الشاطئ',\n",
    "    '中文': '海滩上美丽的日落', \n",
    "    '英语': 'A beautiful sunset over the beach',\n",
    "    '法语': 'Un beau coucher de soleil sur la plage', \n",
    "    '德语': 'Ein wunderschöner Sonnenuntergang am Strand', \n",
    "    '希腊语': 'Ένα όμορφο ηλιοβασίλεμα πάνω από την παραλία', \n",
    "    '印地语': 'समुद्र तट पर एक खूबसूरत सूर्यास्त', \n",
    "    '意大利语': 'Un bellissimo tramonto sulla spiaggia', \n",
    "    '日语': '浜辺に沈む美しい夕日', \n",
    "    '韩语': '해변 위로 아름다운 일몰',\n",
    "    '俄语': 'Красивый закат над пляжем',\n",
    "    '西班牙语': 'Una hermosa puesta de sol sobre la playa'\n",
    "}\n",
    "\n",
    "# 提取文本和标签\n",
    "sunset_labels = list(sunset_texts.keys())\n",
    "sunset_sentences = list(sunset_texts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08eac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备不同场景的多语言描述\n",
    "scene_descriptions = {\n",
    "    '海滩日落': {\n",
    "        '中文': '海滩上美丽的日落',\n",
    "        '英语': 'A beautiful sunset over the beach',\n",
    "        '法语': 'Un beau coucher de soleil sur la plage'\n",
    "    },\n",
    "    '城市夜景': {\n",
    "        '中文': '灯火辉煌的城市夜景',\n",
    "        '英语': 'A brightly lit city skyline at night',\n",
    "        '法语': 'Un paysage urbain brillamment illuminé la nuit'\n",
    "    },\n",
    "    '山脉': {\n",
    "        '中文': '雄伟的山脉风景',\n",
    "        '英语': 'Majestic mountain landscape',\n",
    "        '法语': 'Paysage montagneux majestueux'\n",
    "    },\n",
    "    '猫': {\n",
    "        '中文': '可爱的小猫',\n",
    "        '英语': 'A cute cat',\n",
    "        '法语': 'Un chat mignon'\n",
    "    },\n",
    "    '食物': {\n",
    "        '中文': '美味的食物',\n",
    "        '英语': 'Delicious food',\n",
    "        '法语': 'Nourriture délicieuse'\n",
    "    }\n",
    "}\n",
    "\n",
    "# 提取所有场景描述文本\n",
    "all_scene_texts = []\n",
    "scene_text_labels = []\n",
    "\n",
    "for scene, languages in scene_descriptions.items():\n",
    "    for lang, text in languages.items():\n",
    "        all_scene_texts.append(text)\n",
    "        scene_text_labels.append(f\"{scene} ({lang})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d79886",
   "metadata": {},
   "source": [
    "## 4. 多语言文本嵌入与相似度分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ce6713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编码多语言日落文本\n",
    "sunset_embeddings = model.encode(sunset_sentences, normalize_embeddings=True)\n",
    "print(f\"嵌入向量形状: {sunset_embeddings.shape}\")\n",
    "\n",
    "# 绘制多语言文本相似度热力图\n",
    "plot_similarity_heatmap(\n",
    "    sunset_embeddings, \n",
    "    sunset_labels, \n",
    "    title='不同语言中相同内容文本的嵌入相似度',\n",
    "    figsize=(14, 12)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fdb9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中文同义表达测试\n",
    "chinese_similar_sunset = [\n",
    "    '海滩上美丽的日落',\n",
    "    '海滩上美丽的夕阳',\n",
    "    '海滩上美丽的黄昏',\n",
    "    '海滩上美丽的晚霞',\n",
    "    '海边迷人的落日',\n",
    "    '沙滩上绚丽的日落',\n",
    "    '沿海壮观的夕阳'\n",
    "]\n",
    "\n",
    "# 编码中文同义句\n",
    "chinese_similar_sunset_embeddings = model.encode(chinese_similar_sunset, normalize_embeddings=True)\n",
    "\n",
    "# 绘制中文同义句相似度\n",
    "plot_similarity_heatmap(\n",
    "    chinese_similar_sunset_embeddings, \n",
    "    chinese_similar_sunset, \n",
    "    title='中文同义表达相似度分析',\n",
    "    figsize=(12, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3507d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中文不同主题测试\n",
    "chinese_diverse_texts = [\n",
    "    '海滩上美丽的日落',\n",
    "    '今天天气真好',\n",
    "    '我喜欢吃苹果',\n",
    "    '北京是中国的首都',\n",
    "    '人工智能正在改变世界',\n",
    "    '熊猫是中国的国宝',\n",
    "    '长城是世界奇迹之一',\n",
    "    '电影院里人很多',\n",
    "    '学校明天放假'\n",
    "]\n",
    "\n",
    "# 编码中文不同主题文本\n",
    "chinese_diverse_embeddings = model.encode(chinese_diverse_texts, normalize_embeddings=True)\n",
    "\n",
    "# 绘制中文不同主题相似度\n",
    "plot_similarity_heatmap(\n",
    "    chinese_diverse_embeddings, \n",
    "    chinese_diverse_texts, \n",
    "    title='中文不同主题文本相似度分析',\n",
    "    figsize=(12, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b579331f",
   "metadata": {},
   "source": [
    "## 5. 图像嵌入与相似度分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81fb751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编码图像\n",
    "image_embeddings = model.encode(image_paths, normalize_embeddings=True)\n",
    "print(f\"图像嵌入向量形状: {image_embeddings.shape}\")\n",
    "\n",
    "# 绘制图像相似度热力图\n",
    "plot_similarity_heatmap(\n",
    "    image_embeddings, \n",
    "    image_labels, \n",
    "    title='图像嵌入相似度热力图',\n",
    "    figsize=(10, 8)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c856f7f",
   "metadata": {},
   "source": [
    "## 6. 跨模态检索能力测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3095cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编码场景描述文本\n",
    "scene_text_embeddings = model.encode(all_scene_texts, normalize_embeddings=True)\n",
    "\n",
    "# 生成图像-文本相似度矩阵并可视化\n",
    "plot_cross_modal_similarity(\n",
    "    image_embeddings, \n",
    "    scene_text_embeddings, \n",
    "    image_labels, \n",
    "    scene_text_labels, \n",
    "    title='图像-文本跨模态相似度热力图'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1c788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本到图像检索\n",
    "def text_to_image_retrieval(query_text, image_paths, image_embeddings, top_k=3):\n",
    "    # 编码查询文本\n",
    "    query_embedding = model.encode(query_text, normalize_embeddings=True)\n",
    "    \n",
    "    # 计算相似度\n",
    "    similarities = query_embedding @ image_embeddings.T\n",
    "    \n",
    "    # 获取前k个相似度最高的图片\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    top_similarities = similarities[top_indices]\n",
    "    top_images = [image_paths[i] for i in top_indices]\n",
    "    \n",
    "    return top_images, top_similarities, top_indices\n",
    "\n",
    "# 测试用例 - 不同语言查询\n",
    "queries = {\n",
    "    '英语': 'A beautiful sunset by the ocean',\n",
    "    '中文': '城市的夜景',\n",
    "    '法语': 'Un chat mignon',\n",
    "    '西班牙语': 'Deliciosa comida en un plato',  # 盘子里美味的食物\n",
    "    '德语': 'Majestätische Berge mit Schnee'  # 雄伟的雪山\n",
    "}\n",
    "\n",
    "# 测试每个查询\n",
    "for language, query in queries.items():\n",
    "    print(f\"\\n查询 ({language}): {query}\")\n",
    "    top_images, similarities, _ = text_to_image_retrieval(query, image_paths, image_embeddings)\n",
    "    \n",
    "    # 显示结果\n",
    "    titles = [f\"{os.path.basename(img)} (相似度: {sim:.2f})\" for img, sim in zip(top_images, similarities)]\n",
    "    display_images(top_images, titles, figsize=(15, 5), columns=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b3cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像到文本检索\n",
    "def image_to_text_retrieval(query_image, texts, text_embeddings, top_k=5):\n",
    "    # 编码查询图像\n",
    "    query_embedding = model.encode(query_image, normalize_embeddings=True)\n",
    "    \n",
    "    # 计算相似度\n",
    "    similarities = query_embedding @ text_embeddings.T\n",
    "    \n",
    "    # 获取前k个相似度最高的文本\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    top_similarities = similarities[top_indices]\n",
    "    top_texts = [texts[i] for i in top_indices]\n",
    "    \n",
    "    return top_texts, top_similarities, top_indices\n",
    "\n",
    "# 合并所有文本用于检索\n",
    "all_texts = sunset_sentences + all_scene_texts + chinese_diverse_texts\n",
    "all_text_labels = sunset_labels + scene_text_labels + chinese_diverse_texts\n",
    "all_text_embeddings = model.encode(all_texts, normalize_embeddings=True)\n",
    "\n",
    "# 选择几张图片测试\n",
    "test_images = [image_paths[0], image_paths[2], image_paths[4]]\n",
    "test_image_labels = [image_labels[0], image_labels[2], image_labels[4]]\n",
    "\n",
    "for img_path, img_label in zip(test_images, test_image_labels):\n",
    "    print(f\"\\n图像查询: {img_label}\")\n",
    "    display_images([img_path], [img_label], figsize=(5, 5))\n",
    "    \n",
    "    top_texts, similarities, indices = image_to_text_retrieval(img_path, all_texts, all_text_embeddings)\n",
    "    \n",
    "    print(\"匹配到的文本:\")\n",
    "    for i, (text, sim) in enumerate(zip(top_texts, similarities)):\n",
    "        print(f\"{i+1}. 文本: '{text}' (相似度: {sim:.3f}) - 标签: {all_text_labels[indices[i]]}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbffc962",
   "metadata": {},
   "source": [
    "## 7. 零样本分类能力测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a983fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 零样本图像分类\n",
    "def zero_shot_image_classification(image_paths, class_names):\n",
    "    # 编码图像\n",
    "    image_embeddings = model.encode(image_paths, normalize_embeddings=True)\n",
    "    \n",
    "    # 编码类别名称\n",
    "    class_embeddings = model.encode(class_names, normalize_embeddings=True)\n",
    "    \n",
    "    # 计算每个图像与每个类别的相似度\n",
    "    similarities = image_embeddings @ class_embeddings.T\n",
    "    \n",
    "    # 对每个图像找到最相似的类别\n",
    "    predicted_classes = np.argmax(similarities, axis=1)\n",
    "    predicted_class_names = [class_names[i] for i in predicted_classes]\n",
    "    confidence_scores = np.max(similarities, axis=1)\n",
    "    \n",
    "    # 构建完整结果\n",
    "    results = []\n",
    "    for i, (img_path, pred_class, confidence) in enumerate(zip(image_paths, predicted_class_names, confidence_scores)):\n",
    "        results.append({\n",
    "            'image': img_path,\n",
    "            'predicted_class': pred_class,\n",
    "            'confidence': confidence,\n",
    "            'all_scores': {class_name: float(similarities[i, j]) for j, class_name in enumerate(class_names)}\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 定义分类类别 - 中英文各一组\n",
    "class_names_en = ['sunset at beach', 'cityscape at night', 'mountains', 'cat', 'food']\n",
    "class_names_zh = ['海滩日落', '城市夜景', '山脉', '猫', '食物']\n",
    "\n",
    "# 执行英文零样本分类\n",
    "results_en = zero_shot_image_classification(image_paths, class_names_en)\n",
    "\n",
    "# 可视化英文分类结果\n",
    "for result in results_en:\n",
    "    img_path = result['image']\n",
    "    pred_class = result['predicted_class']\n",
    "    confidence = result['confidence']\n",
    "    img_name = os.path.basename(img_path)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # 显示图像\n",
    "    plt.subplot(1, 2, 1)\n",
    "    img = Image.open(img_path)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"图像: {img_name}\\n预测类别: {pred_class} (置信度: {confidence:.2f})\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # 显示所有类别的得分\n",
    "    plt.subplot(1, 2, 2)\n",
    "    all_scores = result['all_scores']\n",
    "    classes = list(all_scores.keys())\n",
    "    scores = list(all_scores.values())\n",
    "    \n",
    "    y_pos = np.arange(len(classes))\n",
    "    plt.barh(y_pos, scores, align='center')\n",
    "    plt.yticks(y_pos, classes)\n",
    "    plt.xlabel('相似度得分')\n",
    "    plt.title('各类别得分')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 执行中文零样本分类\n",
    "results_zh = zero_shot_image_classification(image_paths, class_names_zh)\n",
    "\n",
    "# 比较英文和中文分类结果\n",
    "print(\"英文与中文零样本分类结果比较:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'图像':<15} | {'英文预测':<20} | {'英文置信度':<10} | {'中文预测':<20} | {'中文置信度':<10} | {'结果一致':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for en_result, zh_result in zip(results_en, results_zh):\n",
    "    img_name = os.path.basename(en_result['image'])\n",
    "    en_pred = en_result['predicted_class']\n",
    "    en_conf = en_result['confidence']\n",
    "    zh_pred = zh_result['predicted_class']\n",
    "    zh_conf = zh_result['confidence']\n",
    "    \n",
    "    # 判断结果是否一致 (比较类别索引)\n",
    "    en_idx = class_names_en.index(en_pred)\n",
    "    zh_idx = class_names_zh.index(zh_pred)\n",
    "    consistent = \"✓\" if en_idx == zh_idx else \"✗\"\n",
    "    \n",
    "    print(f\"{img_name:<15} | {en_pred:<20} | {en_conf:.4f} | {zh_pred:<20} | {zh_conf:.4f} | {consistent:<10}\")\n",
    "\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309f720d",
   "metadata": {},
   "source": [
    "## 8. 模型性能分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb4a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析不同语言的理解能力\n",
    "language_groups = {\n",
    "    '西方语言': ['英语', '法语', '德语', '意大利语', '西班牙语'],\n",
    "    '东亚语言': ['中文', '日语', '韩语'],\n",
    "    '其他语言': ['阿拉伯语', '希腊语', '印地语', '俄语']\n",
    "}\n",
    "\n",
    "# 计算组内平均相似度\n",
    "print(\"不同语言组内的平均相似度:\")\n",
    "for group_name, languages in language_groups.items():\n",
    "    # 提取该组语言的嵌入向量\n",
    "    indices = [sunset_labels.index(lang) for lang in languages if lang in sunset_labels]\n",
    "    if not indices:\n",
    "        continue\n",
    "    \n",
    "    group_embeddings = sunset_embeddings[indices]\n",
    "    similarity_matrix = group_embeddings @ group_embeddings.T\n",
    "    \n",
    "    # 计算上三角矩阵的平均值（排除对角线）\n",
    "    n = similarity_matrix.shape[0]\n",
    "    upper_triangle_sum = 0\n",
    "    upper_triangle_count = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            upper_triangle_sum += similarity_matrix[i, j]\n",
    "            upper_triangle_count += 1\n",
    "    \n",
    "    if upper_triangle_count > 0:\n",
    "        avg_similarity = upper_triangle_sum / upper_triangle_count\n",
    "        print(f\"{group_name}: {avg_similarity:.4f}\")\n",
    "\n",
    "# 计算组间平均相似度\n",
    "print(\"\\n不同语言组之间的平均相似度:\")\n",
    "for group1_name, languages1 in language_groups.items():\n",
    "    for group2_name, languages2 in language_groups.items():\n",
    "        if group1_name >= group2_name:  # 避免重复计算\n",
    "            continue\n",
    "        \n",
    "        # 提取两组语言的嵌入向量\n",
    "        indices1 = [sunset_labels.index(lang) for lang in languages1 if lang in sunset_labels]\n",
    "        indices2 = [sunset_labels.index(lang) for lang in languages2 if lang in sunset_labels]\n",
    "        \n",
    "        if not indices1 or not indices2:\n",
    "            continue\n",
    "        \n",
    "        group1_embeddings = sunset_embeddings[indices1]\n",
    "        group2_embeddings = sunset_embeddings[indices2]\n",
    "        \n",
    "        # 计算组间相似度\n",
    "        cross_similarity = group1_embeddings @ group2_embeddings.T\n",
    "        avg_cross_similarity = np.mean(cross_similarity)\n",
    "        \n",
    "        print(f\"{group1_name} vs {group2_name}: {avg_cross_similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a9227b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析跨模态检索性能\n",
    "\n",
    "# 准备场景-图片对应关系作为真实标签\n",
    "scene_to_image = {\n",
    "    '海滩日落': ['beach1.jpg', 'beach2.jpg'],\n",
    "    '城市夜景': ['city-night.jpg'],\n",
    "    '山脉': ['mountain.jpg'],\n",
    "    '猫': ['cat.jpg'],\n",
    "    '食物': ['food.jpg']\n",
    "}\n",
    "\n",
    "# 准备场景描述（每种语言）\n",
    "scene_descriptions_flat = []\n",
    "true_image_labels = []\n",
    "\n",
    "for scene, image_names in scene_to_image.items():\n",
    "    if scene not in scene_descriptions:\n",
    "        continue\n",
    "        \n",
    "    for lang, text in scene_descriptions[scene].items():\n",
    "        scene_descriptions_flat.append(text)\n",
    "        # 对于每个场景描述，记录其应匹配的图片\n",
    "        true_image_labels.append([os.path.splitext(img)[0] for img in image_names])\n",
    "\n",
    "# 文本到图像检索的评估\n",
    "text_to_image_results = []\n",
    "for i, query_text in enumerate(scene_descriptions_flat):\n",
    "    # 对每个场景描述进行检索\n",
    "    _, _, top_indices = text_to_image_retrieval(query_text, image_paths, image_embeddings, top_k=len(image_paths))\n",
    "    retrieved_image_labels = [image_labels[j] for j in top_indices]\n",
    "    \n",
    "    # 计算排名指标\n",
    "    true_labels = true_image_labels[i]\n",
    "    ranks = []\n",
    "    for true_label in true_labels:\n",
    "        if true_label in retrieved_image_labels:\n",
    "            ranks.append(retrieved_image_labels.index(true_label) + 1)\n",
    "        else:\n",
    "            ranks.append(float('inf'))\n",
    "    \n",
    "    # 计算平均排名\n",
    "    if ranks:\n",
    "        avg_rank = sum(r for r in ranks if r < float('inf')) / len([r for r in ranks if r < float('inf')])\n",
    "    else:\n",
    "        avg_rank = float('inf')\n",
    "    \n",
    "    # 计算准确率@1（最高排名的图片是否正确）\n",
    "    precision_at_1 = 1 if retrieved_image_labels[0] in true_labels else 0\n",
    "    \n",
    "    scene = next((s for s, langs in scene_descriptions.items() if query_text in langs.values()), \"未知\")\n",
    "    lang = next((l for l, text in scene_descriptions.get(scene, {}).items() if text == query_text), \"未知\")\n",
    "    \n",
    "    text_to_image_results.append({\n",
    "        'query': query_text,\n",
    "        'scene': scene,\n",
    "        'language': lang,\n",
    "        'true_labels': true_labels,\n",
    "        'retrieved_labels': retrieved_image_labels[:5],  # 只保留前5个\n",
    "        'average_rank': avg_rank,\n",
    "        'precision_at_1': precision_at_1\n",
    "    })\n",
    "\n",
    "# 输出结果汇总\n",
    "print(\"文本到图像检索性能分析:\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"{'场景':<15} | {'语言':<10} | {'查询文本':<40} | {'Precision@1':<15} | {'平均排名':<10}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for result in text_to_image_results:\n",
    "    print(f\"{result['scene']:<15} | {result['language']:<10} | {result['query'][:37]+'...' if len(result['query'])>40 else result['query']:<40} | {result['precision_at_1']:<15} | {result['average_rank']:.2f}\")\n",
    "\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# 按语言分组计算平均性能\n",
    "languages = set(result['language'] for result in text_to_image_results)\n",
    "print(\"\\n各语言的平均检索性能:\")\n",
    "print(f\"{'语言':<10} | {'平均 Precision@1':<20} | {'平均排名':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for lang in languages:\n",
    "    lang_results = [r for r in text_to_image_results if r['language'] == lang]\n",
    "    avg_precision = sum(r['precision_at_1'] for r in lang_results) / len(lang_results) if lang_results else 0\n",
    "    avg_rank = sum(r['average_rank'] for r in lang_results) / len(lang_results) if lang_results else float('inf')\n",
    "    \n",
    "    print(f\"{lang:<10} | {avg_precision:.2f}{' ':<17} | {avg_rank:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff9efaf",
   "metadata": {},
   "source": [
    "## 9. 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabd5db8",
   "metadata": {},
   "source": [
    "### JINA-CLIP-V2 多模态模型能力总结\n",
    "\n",
    "在这个测试中，我们对JINA-CLIP-V2模型在多模态理解方面的能力进行了全面的评估。以下是主要发现:\n",
    "\n",
    "1. **多语言理解能力**\n",
    "   - 模型能够理解并关联不同语言中表达相同概念的文本\n",
    "   - 同一语言中的同义表达具有很高的相似度\n",
    "   - 不同语言族之间(如东亚语言vs西方语言)的理解能力保持一致性\n",
    "\n",
    "2. **图像表示能力**\n",
    "   - 模型能够捕捉图像的语义内容，相似场景的图像具有较高的向量相似度\n",
    "   - 不同场景的图像表示在向量空间中能够有效区分\n",
    "\n",
    "3. **跨模态检索性能**\n",
    "   - 文本到图像检索：模型能够根据文本描述找到相关的图像\n",
    "   - 图像到文本检索：模型能够根据图像找到相关的文本描述\n",
    "   - 跨语言检索：不同语言描述的同一场景都能找到相应的图像\n",
    "\n",
    "4. **零样本分类能力**\n",
    "   - 模型展示了良好的零样本图像分类能力\n",
    "   - 用不同语言表述的类别都能获得一致的分类结果\n",
    "\n",
    "### 应用场景\n",
    "\n",
    "基于测试结果，JINA-CLIP-V2模型适用于以下应用场景：\n",
    "\n",
    "1. **多语言图像检索系统**\n",
    "2. **跨语言内容推荐**\n",
    "3. **零样本图像分类**\n",
    "4. **多语言内容理解**\n",
    "5. **语义搜索引擎**\n",
    "\n",
    "### 限制与改进方向\n",
    "\n",
    "1. 提高细粒度场景区分能力\n",
    "2. 加强对特定领域文本和图像的理解\n",
    "3. 优化对长文本的处理能力\n",
    "\n",
    "这些测试结果为后续应用开发和研究提供了重要的基础。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
