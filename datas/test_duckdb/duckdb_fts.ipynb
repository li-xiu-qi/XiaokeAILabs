{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "# DuckDB 全文检索扩展\n",
        "\n",
        "Full-Text Search 是 DuckDB 的一个扩展，允许对字符串进行搜索，类似于 SQLite 的 FTS5 扩展。\n",
        "\n",
        "## 安装和加载\n",
        "\n",
        "`fts` 扩展会从官方扩展库中在首次使用时透明地自动加载。如果想要手动安装和加载，可以运行相应的命令。\n",
        "\n",
        "## 使用方法\n",
        "\n",
        "该扩展向 DuckDB 添加了两个 `PRAGMA` 语句：一个用于创建索引，一个用于删除索引。此外，还添加了一个标量宏 `stem`，它在扩展内部使用。\n",
        "\n",
        "### `PRAGMA create_fts_index`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c630914",
      "metadata": {
        "language": "sql"
      },
      "source": [
        "-- 创建全文检索索引的PRAGMA语句\n",
        "create_fts_index(input_table, input_id, *input_values, stemmer = 'porter',\n",
        "                 stopwords = 'english', ignore = '(\\\\.|[^a-z])+',\n",
        "                 strip_accents = 1, lower = 1, overwrite = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14dd5a54",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "这是一个创建指定表的 FTS 索引的 `PRAGMA`。\n",
        "\n",
        "| 参数 | 类型 | 描述 |\n",
        "|------|------|------|\n",
        "| `input_table` | `VARCHAR` | 指定表的限定名称，例如 `'table_name'` 或 `'main.table_name'` |\n",
        "| `input_id` | `VARCHAR` | 文档标识符的列名，例如 `'document_identifier'` |\n",
        "| `input_values...` | `VARCHAR` | 要索引的文本字段的列名（可变参数），例如 `'text_field_1'`, `'text_field_2'`, …, `'text_field_N'`，或者用 `'*'` 表示输入表中所有类型为 `VARCHAR` 的列 |\n",
        "| `stemmer` | `VARCHAR` | 要使用的词干提取器类型。可选值：`'arabic'`, `'basque'`, `'catalan'`, `'danish'`, `'dutch'`, `'english'`, `'finnish'`, `'french'`, `'german'`, `'greek'`, `'hindi'`, `'hungarian'`, `'indonesian'`, `'irish'`, `'italian'`, `'lithuanian'`, `'nepali'`, `'norwegian'`, `'porter'`, `'portuguese'`, `'romanian'`, `'russian'`, `'serbian'`, `'spanish'`, `'swedish'`, `'tamil'`, `'turkish'`，或者 `'none'`（如果不想使用词干提取）。默认为 `'porter'` |\n",
        "| `stopwords` | `VARCHAR` | 包含所需停用词的单列 `VARCHAR` 表的限定名称，或者 `'none'`（如果不使用停用词）。默认为 `'english'`，即预定义的 571 个英语停用词列表 |\n",
        "| `ignore` | `VARCHAR` | 要忽略的模式的正则表达式。默认为 `'(\\\\.|[^a-z])+'`，忽略所有转义的和非小写英文字母的字符 |\n",
        "| `strip_accents` | `BOOLEAN` | 是否去除重音（例如，将 `á` 转换为 `a`）。默认为 `1` |\n",
        "| `lower` | `BOOLEAN` | 是否将所有文本转换为小写。默认为 `1` |\n",
        "| `overwrite` | `BOOLEAN` | 是否覆盖表上已有的索引。默认为 `0` |\n",
        "\n",
        "该 `PRAGMA` 在新创建的模式下构建索引。模式将根据输入表命名：如果在表 `'main.table_name'` 上创建索引，则模式将命名为 `'fts_main_table_name'`。\n",
        "\n",
        "### `PRAGMA drop_fts_index`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2665bba",
      "metadata": {
        "language": "sql"
      },
      "source": [
        "-- 删除全文检索索引的PRAGMA语句\n",
        "drop_fts_index(input_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4b2bec6",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "删除指定表的 FTS 索引。\n",
        "\n",
        "| 参数 | 类型 | 描述 |\n",
        "|------|------|------|\n",
        "| `input_table` | `VARCHAR` | 输入表的限定名称，例如 `'table_name'` 或 `'main.table_name'` |\n",
        "\n",
        "### `match_bm25` 函数\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f469ff25",
      "metadata": {
        "language": "sql"
      },
      "source": [
        "-- BM25检索函数，用于在索引中搜索文档\n",
        "match_bm25(input_id, query_string, fields := NULL, k := 1.2, b := 0.75, conjunctive := 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bbe2b22",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "当构建索引时，会创建这个检索宏，可用于搜索索引。\n",
        "\n",
        "| 参数 | 类型 | 描述 |\n",
        "|------|------|------|\n",
        "| `input_id` | `VARCHAR` | 文档标识符的列名，例如 `'document_identifier'` |\n",
        "| `query_string` | `VARCHAR` | 要在索引中搜索的字符串 |\n",
        "| `fields` | `VARCHAR` | 要搜索的字段的逗号分隔列表，例如 `'text_field_2, text_field_N'`。默认为 `NULL`，表示搜索所有已索引的字段 |\n",
        "| `k` | `DOUBLE` | Okapi BM25 检索模型中的参数 _k1_。默认为 `1.2` |\n",
        "| `b` | `DOUBLE` | Okapi BM25 检索模型中的参数 _b_。默认为 `0.75` |\n",
        "| `conjunctive` | `BOOLEAN` | 是否使查询为合取的，即查询字符串中的所有术语都必须存在，文档才会被检索到 |\n",
        "\n",
        "### `stem` 函数\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "347664c7",
      "metadata": {
        "language": "sql"
      },
      "source": [
        "-- 词干提取函数，将单词转换为其基本形式\n",
        "stem(input_string, stemmer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0c82884",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "将单词缩减为基本形式。在扩展内部使用。\n",
        "\n",
        "| 参数 | 类型 | 描述 |\n",
        "|------|------|------|\n",
        "| `input_string` | `VARCHAR` | 要进行词干提取的列或常量 |\n",
        "| `stemmer` | `VARCHAR` | 要使用的词干提取器类型。可以是 `'arabic'`, `'basque'`, 等多种语言类型，或 `'none'` |\n",
        "\n",
        "## 使用示例\n",
        "\n",
        "### 创建测试数据\n",
        "\n",
        "创建一个表并用文本数据填充：\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "514d62e0",
      "metadata": {
        "language": "sql"
      },
      "source": [
        "-- 创建文档表，包含文档ID、内容、作者和版本信息\n",
        "CREATE TABLE documents (\n",
        "    document_identifier VARCHAR,  -- 文档唯一标识符\n",
        "    text_content VARCHAR,         -- 文档文本内容\n",
        "    author VARCHAR,               -- 文档作者\n",
        "    doc_version INTEGER           -- 文档版本号\n",
        ");\n",
        "\n",
        "-- 插入两条示例文档数据\n",
        "INSERT INTO documents\n",
        "    VALUES ('doc1',\n",
        "            'The mallard is a dabbling duck that breeds throughout the temperate.',\n",
        "            'Hannes Mühleisen',\n",
        "            3),\n",
        "           ('doc2',\n",
        "            'The cat is a domestic species of small carnivorous mammal.',\n",
        "            'Laurens Kuiper',\n",
        "            2\n",
        "           );"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a46dc4d",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "**Python实现**：\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "a91003ac",
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "已插入的文档数据:\n",
            "('doc1', 'The mallard is a dabbling duck that breeds throughout the temperate.', 'Hannes Mühleisen', 3)\n",
            "('doc2', 'The cat is a domestic species of small carnivorous mammal.', 'Laurens Kuiper', 2)\n"
          ]
        }
      ],
      "source": [
        "import duckdb\n",
        "\n",
        "# 创建DuckDB内存数据库连接\n",
        "conn = duckdb.connect(':memory:')\n",
        "\n",
        "# 创建文档表，包含文档ID、内容、作者和版本字段\n",
        "conn.execute(\"\"\"\n",
        "CREATE TABLE documents (\n",
        "    document_identifier VARCHAR,  -- 文档唯一标识符\n",
        "    text_content VARCHAR,         -- 文档文本内容\n",
        "    author VARCHAR,               -- 文档作者\n",
        "    doc_version INTEGER           -- 文档版本号\n",
        ")\n",
        "\"\"\")\n",
        "\n",
        "# 插入两条示例文档数据\n",
        "conn.execute(\"\"\"\n",
        "INSERT INTO documents\n",
        "    VALUES ('doc1',\n",
        "            'The mallard is a dabbling duck that breeds throughout the temperate.',\n",
        "            'Hannes Mühleisen',\n",
        "            3),\n",
        "           ('doc2',\n",
        "            'The cat is a domestic species of small carnivorous mammal.',\n",
        "            'Laurens Kuiper',\n",
        "            2\n",
        "           )\n",
        "\"\"\")\n",
        "\n",
        "# 验证数据是否成功插入，并打印结果\n",
        "result = conn.execute(\"SELECT * FROM documents\").fetchall()\n",
        "print(\"已插入的文档数据:\")\n",
        "for row in result:\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb8cc66f",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "### 构建索引\n",
        "\n",
        "构建索引，并使 `text_content` 和 `author` 列可搜索。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8342f5c5",
      "metadata": {
        "language": "sql"
      },
      "source": [
        "-- 为documents表创建全文检索索引，索引document_identifier列，并对text_content和author列建立搜索索引\n",
        "PRAGMA create_fts_index(\n",
        "    'documents', 'document_identifier', 'text_content', 'author'\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9310d7c5",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "**Python实现**：\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "451dca89",
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "全文检索索引已创建\n"
          ]
        }
      ],
      "source": [
        "# 安装并加载全文检索(FTS)扩展\n",
        "conn.execute(\"INSTALL fts\")  # 安装FTS扩展\n",
        "conn.execute(\"LOAD fts\")     # 加载FTS扩展到当前连接\n",
        "\n",
        "# 为documents表创建全文检索索引\n",
        "# 参数说明: 表名、ID列名、要索引的文本列(这里同时索引text_content和author两列)\n",
        "conn.execute(\"\"\"\n",
        "PRAGMA create_fts_index(\n",
        "    'documents', 'document_identifier', 'text_content', 'author'\n",
        ")\n",
        "\"\"\")\n",
        "print(\"全文检索索引已创建\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2db00568",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "### 搜索示例\n",
        "\n",
        "在 `author` 字段索引中搜索由 `Muhleisen` 撰写的文档。这会检索到 `doc1` ：\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbbcf628",
      "metadata": {
        "language": "sql"
      },
      "source": [
        "-- 在author字段中搜索包含\"Muhleisen\"的文档\n",
        "-- 并且仅返回doc_version大于2的文档\n",
        "-- 按相关性得分降序排列结果\n",
        "SELECT document_identifier, text_content, score\n",
        "FROM (\n",
        "    SELECT *, fts_main_documents.match_bm25(\n",
        "        document_identifier,  -- 文档标识符列\n",
        "        'Muhleisen',         -- 搜索关键词\n",
        "        fields := 'author'   -- 限定只在author字段中搜索\n",
        "    ) AS score\n",
        "    FROM documents\n",
        ") sq\n",
        "WHERE score IS NOT NULL      -- 仅保留匹配的文档(有分数的)\n",
        "  AND doc_version > 2        -- 文档版本必须大于2\n",
        "ORDER BY score DESC;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07949673",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "**Python实现**：\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "5e4857b9",
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "按作者 'Muhleisen' 搜索结果:\n",
            "文档ID: doc1, 内容: The mallard is a dabbling duck that breeds throughout the temperate., 得分: 0.3094700890003546\n"
          ]
        }
      ],
      "source": [
        "# 按作者搜索，在author字段中查找\"Muhleisen\"\n",
        "query = \"\"\"\n",
        "SELECT document_identifier, text_content, score\n",
        "FROM (\n",
        "    SELECT *, fts_main_documents.match_bm25(\n",
        "        document_identifier,  -- 文档标识符列\n",
        "        'Muhleisen',         -- 搜索关键词\n",
        "        fields := 'author'   -- 限定只在author字段中搜索\n",
        "    ) AS score\n",
        "    FROM documents\n",
        ") sq\n",
        "WHERE score IS NOT NULL      -- 仅保留匹配的文档(有分数的)\n",
        "  AND doc_version > 2        -- 文档版本必须大于2\n",
        "ORDER BY score DESC          -- 按相关性得分降序排列\n",
        "\"\"\"\n",
        "\n",
        "# 执行搜索查询并获取结果\n",
        "result = conn.execute(query).fetchall()\n",
        "print(\"\\n按作者 'Muhleisen' 搜索结果:\")\n",
        "for row in result:\n",
        "    print(f\"文档ID: {row[0]}, 内容: {row[1]}, 得分: {row[2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbcc82d0",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "搜索关于 `small cats` 的文档。这会检索到 `doc2` ：\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ac0cab3",
      "metadata": {
        "language": "sql"
      },
      "source": [
        "-- 搜索包含\"small cats\"相关内容的文档\n",
        "-- 在所有已索引的字段(text_content和author)中搜索\n",
        "-- 按相关性得分降序排列结果\n",
        "SELECT document_identifier, text_content, score\n",
        "FROM (\n",
        "    SELECT *, fts_main_documents.match_bm25(\n",
        "        document_identifier,  -- 文档标识符列\n",
        "        'small cats'         -- 搜索关键词\n",
        "    ) AS score               -- 未指定fields参数，将在所有索引字段中搜索\n",
        "    FROM documents\n",
        ") sq\n",
        "WHERE score IS NOT NULL      -- 仅保留匹配的文档(有分数的)\n",
        "ORDER BY score DESC;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a6c9c2d",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "**Python实现**：\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "80abcfa2",
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "搜索 'small cats' 的结果:\n",
            "文档ID: doc2, 内容: The cat is a domestic species of small carnivorous mammal., 得分: 0.5860760977528838\n"
          ]
        }
      ],
      "source": [
        "# 按内容关键词搜索，查找包含\"small cats\"的文档\n",
        "query = \"\"\"\n",
        "SELECT document_identifier, text_content, score\n",
        "FROM (\n",
        "    SELECT *, fts_main_documents.match_bm25(\n",
        "        document_identifier,  -- 文档标识符列\n",
        "        'small cats'         -- 搜索关键词\n",
        "    ) AS score               -- 未指定fields参数，将在所有索引字段中搜索\n",
        "    FROM documents\n",
        ") sq\n",
        "WHERE score IS NOT NULL      -- 仅保留匹配的文档(有分数的)\n",
        "ORDER BY score DESC          -- 按相关性得分降序排列\n",
        "\"\"\"\n",
        "\n",
        "# 执行搜索查询并获取结果\n",
        "result = conn.execute(query).fetchall()\n",
        "print(\"\\n搜索 'small cats' 的结果:\")\n",
        "for row in result:\n",
        "    print(f\"文档ID: {row[0]}, 内容: {row[1]}, 得分: {row[2]}\")\n",
        "\n",
        "# 关闭数据库连接\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61496d90",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "> **警告**\n",
        ">\n",
        "> 当输入表发生变化时，FTS 索引不会自动更新。\n",
        "> 可以通过重新创建索引来解决此限制。\n",
        "\n",
        "## 完整Python示例代码\n",
        "\n",
        "以下是一个完整的Python脚本，包含所有上述操作：\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "0e201af9",
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FTS扩展已加载\n",
            "文档表已创建并填充数据\n",
            "全文检索索引已创建\n",
            "\n",
            "按作者 'Muhleisen' 搜索结果:\n",
            "文档ID: doc1, 内容: The mallard is a dabbling duck that breeds throughout the temperate., 得分: 0.3094700890003546\n",
            "\n",
            "搜索 'small cats' 的结果:\n",
            "文档ID: doc2, 内容: The cat is a domestic species of small carnivorous mammal., 得分: 0.5860760977528838\n",
            "\n",
            "DuckDB连接已关闭\n"
          ]
        }
      ],
      "source": [
        "import duckdb\n",
        "\n",
        "def run_duckdb_fts_demo():\n",
        "    # 创建内存数据库连接\n",
        "    conn = duckdb.connect(':memory:')\n",
        "    \n",
        "    try:\n",
        "        # 步骤1: 安装并加载全文检索扩展\n",
        "        conn.execute(\"INSTALL fts\")  # 安装FTS扩展包\n",
        "        conn.execute(\"LOAD fts\")     # 加载FTS扩展到当前会话\n",
        "        print(\"FTS扩展已加载\")\n",
        "        \n",
        "        # 步骤2: 创建文档数据表\n",
        "        conn.execute(\"\"\"\n",
        "        CREATE TABLE documents (\n",
        "            document_identifier VARCHAR,  -- 文档唯一标识符\n",
        "            text_content VARCHAR,         -- 文档文本内容\n",
        "            author VARCHAR,               -- 文档作者\n",
        "            doc_version INTEGER           -- 文档版本号\n",
        "        )\n",
        "        \"\"\")\n",
        "        \n",
        "        # 步骤3: 插入示例数据\n",
        "        conn.execute(\"\"\"\n",
        "        INSERT INTO documents\n",
        "            VALUES ('doc1',\n",
        "                    'The mallard is a dabbling duck that breeds throughout the temperate.',\n",
        "                    'Hannes Mühleisen',\n",
        "                    3),\n",
        "                   ('doc2',\n",
        "                    'The cat is a domestic species of small carnivorous mammal.',\n",
        "                    'Laurens Kuiper',\n",
        "                    2\n",
        "                   )\n",
        "        \"\"\")\n",
        "        \n",
        "        print(\"文档表已创建并填充数据\")\n",
        "        \n",
        "        # 步骤4: 创建全文检索索引\n",
        "        # 为documents表创建索引，以document_identifier为ID列，索引text_content和author字段\n",
        "        conn.execute(\"\"\"\n",
        "        PRAGMA create_fts_index(\n",
        "            'documents', 'document_identifier', 'text_content', 'author'\n",
        "        )\n",
        "        \"\"\")\n",
        "        print(\"全文检索索引已创建\")\n",
        "        \n",
        "        # 步骤5: 按作者搜索示例\n",
        "        # 在author字段中搜索'Muhleisen'，并限制只返回版本大于2的文档\n",
        "        author_query = \"\"\"\n",
        "        SELECT document_identifier, text_content, score\n",
        "        FROM (\n",
        "            SELECT *, fts_main_documents.match_bm25(\n",
        "                document_identifier,\n",
        "                'Muhleisen',\n",
        "                fields := 'author'\n",
        "            ) AS score\n",
        "            FROM documents\n",
        "        ) sq\n",
        "        WHERE score IS NOT NULL\n",
        "          AND doc_version > 2\n",
        "        ORDER BY score DESC\n",
        "        \"\"\"\n",
        "        \n",
        "        # 执行作者搜索查询并显示结果\n",
        "        author_results = conn.execute(author_query).fetchall()\n",
        "        print(\"\\n按作者 'Muhleisen' 搜索结果:\")\n",
        "        for row in author_results:\n",
        "            print(f\"文档ID: {row[0]}, 内容: {row[1]}, 得分: {row[2]}\")\n",
        "        \n",
        "        # 步骤6: 按内容关键词搜索示例\n",
        "        # 在所有索引字段中搜索包含'small cats'的文档\n",
        "        content_query = \"\"\"\n",
        "        SELECT document_identifier, text_content, score\n",
        "        FROM (\n",
        "            SELECT *, fts_main_documents.match_bm25(\n",
        "                document_identifier,\n",
        "                'small cats'\n",
        "            ) AS score\n",
        "            FROM documents\n",
        "        ) sq\n",
        "        WHERE score IS NOT NULL\n",
        "        ORDER BY score DESC\n",
        "        \"\"\"\n",
        "        \n",
        "        # 执行内容搜索查询并显示结果\n",
        "        content_results = conn.execute(content_query).fetchall()\n",
        "        print(\"\\n搜索 'small cats' 的结果:\")\n",
        "        for row in content_results:\n",
        "            print(f\"文档ID: {row[0]}, 内容: {row[1]}, 得分: {row[2]}\")\n",
        "            \n",
        "    finally:\n",
        "        # 步骤7: 清理资源，关闭数据库连接\n",
        "        conn.close()\n",
        "        print(\"\\nDuckDB连接已关闭\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_duckdb_fts_demo()  # 执行演示程序"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51d7536b",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "## DuckDB中文全文检索实现\n",
        "\n",
        "DuckDB自带的全文检索(FTS)扩展不直接支持中文分词，因此无法有效索引和搜索中文内容。但我们可以结合jieba等中文分词工具，对中文文本进行预处理，使其适用于DuckDB的FTS索引。\n",
        "\n",
        "### 基本思路\n",
        "\n",
        "1. 使用jieba对中文文本进行分词\n",
        "2. 将分词结果用空格连接，转换为类似英文的形式\n",
        "3. 对处理后的文本创建FTS索引\n",
        "4. 查询时，对查询关键词也进行分词处理\n",
        "5. 使用处理后的关键词在索引中搜索\n",
        "\n",
        "### 实现方案\n",
        "\n",
        "#### 第一步：安装必要的库\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bd343cd",
      "metadata": {
        "language": "python"
      },
      "source": [
        "pip install duckdb jieba"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fa6a6c8",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "#### 第二步：创建中文文本预处理函数\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "e2ade951",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "import jieba\n",
        "import re\n",
        "\n",
        "# 定义中文停用词列表 (可根据实际需求扩展或使用更完善的停用词库)\n",
        "# 这里仅为示例，实际应用中建议使用更全面的停用词表\n",
        "CHINESE_STOPWORDS = {\n",
        "    \"的\", \"了\", \"是\", \"在\", \"也\", \"和\", \"就\", \"都\", \"而\", \"及\", \"与\", \"著\", \"啊\",\n",
        "    \"嗯\", \"哦\", \"哈\", \"嘿\", \"喂\", \"哎\", \"呢\", \"吧\", \"吗\", \"啦\", \"嘛\", \"哇\",\n",
        "    \"我\", \"你\", \"他\", \"她\", \"它\", \"我们\", \"你们\", \"他们\", \"她们\", \"它们\",\n",
        "    \"这\", \"那\", \"这些\", \"那些\", \"这个\", \"那个\",\n",
        "    \"一\", \"一些\", \"一种\", \"一下\", \"一个\", \"一切\", \"一旦\",\n",
        "    \"不\", \"没\", \"有\", \"无\", \"很\", \"太\", \"更\", \"最\",\n",
        "    \"会\", \"能\", \"可\", \"要\", \"想\", \"得\", \"应\", \"该\",\n",
        "    \"通过\", \"根据\", \"由于\", \"为了\", \"因为\", \"所以\",\n",
        "    \"如果\", \"那么\", \"但是\", \"然而\",\n",
        "    \"对\", \"从\", \"向\", \"于\", \"以\", \"之\", \"其\", \"或\", \"或者\",\n",
        "    \"等\", \"等等\", \"例如\", \"比如\", \"其他\", \"其它\", \"另外\", \"还有\", \"以及\"\n",
        "}\n",
        "\n",
        "def preprocess_chinese_text(text):\n",
        "    \"\"\"\n",
        "    对中文文本进行预处理，包括分词、去除停用词和格式化\n",
        "    \n",
        "    Args:\n",
        "        text (str): 原始中文文本\n",
        "        \n",
        "    Returns:\n",
        "        str: 分词并去除停用词后的文本，词语间以空格分隔\n",
        "    \"\"\"\n",
        "    if not text or not isinstance(text, str):\n",
        "        return \"\"\n",
        "    \n",
        "    # 使用jieba进行分词\n",
        "    words = jieba.cut(text)\n",
        "    \n",
        "    # 过滤掉停用词、标点符号、单个字符（可选，视情况而定）等\n",
        "    filtered_words = [word for word in words \n",
        "                     if word.strip() and \n",
        "                     not re.match(r'[^\\w\\u4e00-\\u9fff]+', word) and \n",
        "                     word not in CHINESE_STOPWORDS and\n",
        "                     len(word) > 0]  # 确保词不为空且不在停用词表中\n",
        "    \n",
        "    # 将分词结果用空格连接\n",
        "    return \" \".join(filtered_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bc6fdce",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "#### 第三步：创建数据表并进行文本预处理\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "a58bcbe7",
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<duckdb.duckdb.DuckDBPyConnection at 0x1ae46feb3f0>"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import duckdb\n",
        "\n",
        "# 创建数据库连接\n",
        "conn = duckdb.connect(':memory:')\n",
        "\n",
        "# 安装和加载FTS扩展\n",
        "conn.execute(\"INSTALL fts\")\n",
        "conn.execute(\"LOAD fts\")\n",
        "\n",
        "# 创建原始中文文档表\n",
        "conn.execute(\"\"\"\n",
        "CREATE TABLE chinese_documents (\n",
        "    doc_id VARCHAR,       -- 文档ID\n",
        "    title VARCHAR,        -- 文档标题\n",
        "    content VARCHAR       -- 文档内容(中文)\n",
        ")\n",
        "\"\"\")\n",
        "\n",
        "# 插入中文示例数据\n",
        "conn.execute(\"\"\"\n",
        "INSERT INTO chinese_documents VALUES\n",
        "    ('doc1', '人工智能简介', '人工智能是计算机科学的一个分支，致力于开发能够模拟人类智能的系统。'),\n",
        "    ('doc2', '机器学习基础', '机器学习是人工智能的一个子领域，专注于让计算机从数据中学习。'),\n",
        "    ('doc3', '深度学习技术', '深度学习是机器学习的一种方法，使用多层神经网络进行复杂模式识别。')\n",
        "\"\"\")\n",
        "\n",
        "# 创建预处理后的中文文档表\n",
        "conn.execute(\"\"\"\n",
        "CREATE TABLE preprocessed_chinese_docs (\n",
        "    doc_id VARCHAR,           -- 文档ID\n",
        "    title_processed VARCHAR,  -- 经过分词处理的标题\n",
        "    content_processed VARCHAR -- 经过分词处理的内容\n",
        ")\n",
        "\"\"\")\n",
        "\n",
        "# 从Python中获取原始数据并进行预处理\n",
        "documents = conn.execute(\"SELECT * FROM chinese_documents\").fetchall()\n",
        "for doc in documents:\n",
        "    doc_id, title, content = doc\n",
        "    # 对标题和内容进行分词处理\n",
        "    title_processed = preprocess_chinese_text(title)\n",
        "    content_processed = preprocess_chinese_text(content)\n",
        "    \n",
        "    # 将处理后的文本插入到新表中\n",
        "    conn.execute(\"\"\"\n",
        "    INSERT INTO preprocessed_chinese_docs VALUES (?, ?, ?)\n",
        "    \"\"\", (doc_id, title_processed, content_processed))\n",
        "\n",
        "# 为预处理后的中文文档创建FTS索引\n",
        "conn.execute(\"\"\"\n",
        "PRAGMA create_fts_index(\n",
        "    'preprocessed_chinese_docs', 'doc_id', 'title_processed', 'content_processed'\n",
        ")\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8672d6e",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "#### 第四步：执行中文搜索\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "c940323b",
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "文档ID: doc2, 标题: 机器学习基础\n",
            "内容: 机器学习是人工智能的一个子领域，专注于让计算机从数据中学习。...\n",
            "相关性得分: 0.4000569815973582\n",
            "\n",
            "文档ID: doc1, 标题: 人工智能简介\n",
            "内容: 人工智能是计算机科学的一个分支，致力于开发能够模拟人类智能的系统。...\n",
            "相关性得分: 0.21282652220049034\n",
            "\n",
            "文档ID: doc3, 标题: 深度学习技术\n",
            "内容: 深度学习是机器学习的一种方法，使用多层神经网络进行复杂模式识别。...\n",
            "相关性得分: 0.2000284907986791\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def search_chinese(conn, query_text):\n",
        "    \"\"\"\n",
        "    执行中文搜索\n",
        "    \n",
        "    Args:\n",
        "        conn: DuckDB连接\n",
        "        query_text (str): 中文查询文本\n",
        "        \n",
        "    Returns:\n",
        "        list: 搜索结果列表\n",
        "    \"\"\"\n",
        "    # 对查询文本进行分词\n",
        "    processed_query = preprocess_chinese_text(query_text)\n",
        "    \n",
        "    # 执行搜索\n",
        "    results = conn.execute(\"\"\"\n",
        "    SELECT sq.doc_id, cd.title, cd.content, score\n",
        "    FROM (\n",
        "        SELECT *, fts_main_preprocessed_chinese_docs.match_bm25(\n",
        "            doc_id, \n",
        "            ?,  -- 使用处理后的查询字符串\n",
        "            fields := 'title_processed, content_processed'\n",
        "        ) AS score\n",
        "        FROM preprocessed_chinese_docs\n",
        "    ) sq\n",
        "    JOIN chinese_documents cd ON sq.doc_id = cd.doc_id\n",
        "    WHERE score IS NOT NULL\n",
        "    ORDER BY score DESC\n",
        "    \"\"\", (processed_query,)).fetchall()\n",
        "    \n",
        "    return results\n",
        "\n",
        "# 执行搜索示例\n",
        "search_results = search_chinese(conn, \"机器学习和人工智能\")\n",
        "for result in search_results:\n",
        "    doc_id, title, content, score = result\n",
        "    print(f\"文档ID: {doc_id}, 标题: {title}\")\n",
        "    print(f\"内容: {content[:50]}...\")\n",
        "    print(f\"相关性得分: {score}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e81d0fea",
      "metadata": {
        "language": "markdown"
      },
      "source": [
        "### 完整示例\n",
        "\n",
        "下面是一个完整的中文全文检索演示程序：\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "9853ffa6",
      "metadata": {
        "language": "python"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FTS扩展已加载\n",
            "中文文档表已创建并填充数据\n",
            "中文文本已成功预处理\n",
            "\n",
            "预处理后的文档示例：\n",
            "ID: doc1\n",
            "处理后标题: 人工智能 简介\n",
            "处理后内容: 人工智能 计算机科学 分支 致力于 开发 能够 模拟 人类 智能 系统\n",
            "--------------------------------------------------\n",
            "ID: doc2\n",
            "处理后标题: 机器 学习 基础\n",
            "处理后内容: 机器 学习 人工智能 子 领域 专注 让 计算机 数据 中 学习\n",
            "--------------------------------------------------\n",
            "已为预处理后的中文文档创建FTS索引\n",
            "\n",
            "搜索示例1：\n",
            "原始查询: '机器学习和人工智能'\n",
            "处理后的查询: '机器 学习 人工智能'\n",
            "文档ID: doc2, 标题: 机器学习基础\n",
            "相关性得分: 0.578844\n",
            "文档ID: doc3, 标题: 深度学习技术\n",
            "相关性得分: 0.289422\n",
            "文档ID: doc1, 标题: 人工智能简介\n",
            "相关性得分: 0.158721\n",
            "\n",
            "搜索示例2：\n",
            "原始查询: '神经网络'\n",
            "处理后的查询: '神经网络'\n",
            "未找到匹配结果\n",
            "\n",
            "DuckDB连接已关闭\n"
          ]
        }
      ],
      "source": [
        "import duckdb\n",
        "import jieba\n",
        "import re\n",
        "\n",
        "# 定义中文停用词列表 (可根据实际需求扩展或使用更完善的停用词库)\n",
        "# 这里仅为示例，实际应用中建议使用更全面的停用词表\n",
        "CHINESE_STOPWORDS = {\n",
        "    \"的\", \"了\", \"是\", \"在\", \"也\", \"和\", \"就\", \"都\", \"而\", \"及\", \"与\", \"著\", \"啊\",\n",
        "    \"嗯\", \"哦\", \"哈\", \"嘿\", \"喂\", \"哎\", \"呢\", \"吧\", \"吗\", \"啦\", \"嘛\", \"哇\",\n",
        "    \"我\", \"你\", \"他\", \"她\", \"它\", \"我们\", \"你们\", \"他们\", \"她们\", \"它们\",\n",
        "    \"这\", \"那\", \"这些\", \"那些\", \"这个\", \"那个\",\n",
        "    \"一\", \"一些\", \"一种\", \"一下\", \"一个\", \"一切\", \"一旦\",\n",
        "    \"不\", \"没\", \"有\", \"无\", \"很\", \"太\", \"更\", \"最\",\n",
        "    \"会\", \"能\", \"可\", \"要\", \"想\", \"得\", \"应\", \"该\",\n",
        "    \"通过\", \"根据\", \"由于\", \"为了\", \"因为\", \"所以\",\n",
        "    \"如果\", \"那么\", \"但是\", \"然而\",\n",
        "    \"对\", \"从\", \"向\", \"于\", \"以\", \"之\", \"其\", \"或\", \"或者\",\n",
        "    \"等\", \"等等\", \"例如\", \"比如\", \"其他\", \"其它\", \"另外\", \"还有\", \"以及\"\n",
        "}\n",
        "\n",
        "def preprocess_chinese_text(text):\n",
        "    \"\"\"对中文文本进行分词和去除停用词处理\"\"\"\n",
        "    if not text or not isinstance(text, str):\n",
        "        return \"\"\n",
        "    words = jieba.cut(text)\n",
        "    # 过滤掉停用词、标点符号、单个字符（可选）等\n",
        "    filtered_words = [word for word in words \n",
        "                     if word.strip() and \n",
        "                     not re.match(r'[^\\w\\u4e00-\\u9fff]+', word) and\n",
        "                     word not in CHINESE_STOPWORDS and\n",
        "                     len(word) > 0] # 确保词不为空且不在停用词表中\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "def run_chinese_fts_demo():\n",
        "    # 创建内存数据库连接\n",
        "    conn = duckdb.connect(':memory:')\n",
        "    \n",
        "    try:\n",
        "        # 安装和加载FTS扩展\n",
        "        conn.execute(\"INSTALL fts\")\n",
        "        conn.execute(\"LOAD fts\")\n",
        "        print(\"FTS扩展已加载\")\n",
        "        \n",
        "        # 创建原始中文文档表\n",
        "        conn.execute(\"\"\"\n",
        "        CREATE TABLE chinese_documents (\n",
        "            doc_id VARCHAR,\n",
        "            title VARCHAR,\n",
        "            content VARCHAR\n",
        "        )\n",
        "        \"\"\")\n",
        "        \n",
        "        # 插入示例数据\n",
        "        conn.execute(\"\"\"\n",
        "        INSERT INTO chinese_documents VALUES\n",
        "            ('doc1', '人工智能简介', '人工智能是计算机科学的一个分支，致力于开发能够模拟人类智能的系统。'),\n",
        "            ('doc2', '机器学习基础', '机器学习是人工智能的一个子领域，专注于让计算机从数据中学习。'),\n",
        "            ('doc3', '深度学习技术', '深度学习是机器学习的一种方法，使用多层神经网络进行复杂模式识别。'),\n",
        "            ('doc4', '自然语言处理', '自然语言处理是人工智能的一个分支，研究计算机与人类语言的交互。')\n",
        "        \"\"\")\n",
        "        print(\"中文文档表已创建并填充数据\")\n",
        "        \n",
        "        # 创建预处理后的中文文档表\n",
        "        conn.execute(\"\"\"\n",
        "        CREATE TABLE preprocessed_chinese_docs (\n",
        "            doc_id VARCHAR,\n",
        "            title_processed VARCHAR,\n",
        "            content_processed VARCHAR\n",
        "        )\n",
        "        \"\"\")\n",
        "        \n",
        "        # 获取原始数据并进行预处理\n",
        "        documents = conn.execute(\"SELECT * FROM chinese_documents\").fetchall()\n",
        "        for doc in documents:\n",
        "            doc_id, title, content = doc\n",
        "            # 对标题和内容进行分词处理\n",
        "            title_processed = preprocess_chinese_text(title)\n",
        "            content_processed = preprocess_chinese_text(content)\n",
        "            \n",
        "            # 将处理后的文本插入到新表中\n",
        "            conn.execute(\"\"\"\n",
        "            INSERT INTO preprocessed_chinese_docs VALUES (?, ?, ?)\n",
        "            \"\"\", (doc_id, title_processed, content_processed))\n",
        "            \n",
        "        print(\"中文文本已成功预处理\")\n",
        "        \n",
        "        # 检查预处理后的表数据\n",
        "        processed_docs = conn.execute(\"SELECT * FROM preprocessed_chinese_docs\").fetchall()\n",
        "        print(\"\\n预处理后的文档示例：\")\n",
        "        for doc in processed_docs[:2]:  # 只显示前两个\n",
        "            print(f\"ID: {doc[0]}\")\n",
        "            print(f\"处理后标题: {doc[1]}\")\n",
        "            print(f\"处理后内容: {doc[2]}\")\n",
        "            print(\"-\" * 50)\n",
        "        \n",
        "        # 为预处理后的中文文档创建FTS索引\n",
        "        conn.execute(\"\"\"\n",
        "        PRAGMA create_fts_index(\n",
        "            'preprocessed_chinese_docs', 'doc_id', 'title_processed', 'content_processed'\n",
        "        )\n",
        "        \"\"\")\n",
        "        print(\"已为预处理后的中文文档创建FTS索引\")\n",
        "        \n",
        "        # 定义搜索函数\n",
        "        def search_chinese(query_text):\n",
        "            # 对查询文本进行分词\n",
        "            processed_query = preprocess_chinese_text(query_text)\n",
        "            print(f\"原始查询: '{query_text}'\")\n",
        "            print(f\"处理后的查询: '{processed_query}'\")\n",
        "            \n",
        "            # 执行搜索\n",
        "            results = conn.execute(\"\"\"\n",
        "            SELECT sq.doc_id, cd.title, cd.content, score\n",
        "            FROM (\n",
        "                SELECT *, fts_main_preprocessed_chinese_docs.match_bm25(\n",
        "                    doc_id, \n",
        "                    ?,  -- 使用处理后的查询字符串\n",
        "                    fields := 'title_processed, content_processed'\n",
        "                ) AS score\n",
        "                FROM preprocessed_chinese_docs\n",
        "            ) sq\n",
        "            JOIN chinese_documents cd ON sq.doc_id = cd.doc_id\n",
        "            WHERE score IS NOT NULL\n",
        "            ORDER BY score DESC\n",
        "            \"\"\", (processed_query,)).fetchall()\n",
        "            \n",
        "            return results\n",
        "        \n",
        "        # 执行搜索示例\n",
        "        print(\"\\n搜索示例1：\")\n",
        "        results1 = search_chinese(\"机器学习和人工智能\")\n",
        "        if results1:\n",
        "            for result in results1:\n",
        "                doc_id, title, content, score = result\n",
        "                print(f\"文档ID: {doc_id}, 标题: {title}\")\n",
        "                print(f\"相关性得分: {score:.6f}\")\n",
        "        else:\n",
        "            print(\"未找到匹配结果\")\n",
        "        \n",
        "        print(\"\\n搜索示例2：\")\n",
        "        results2 = search_chinese(\"神经网络\")\n",
        "        if results2:\n",
        "            for result in results2:\n",
        "                doc_id, title, content, score = result\n",
        "                print(f\"文档ID: {doc_id}, 标题: {title}\")\n",
        "                print(f\"相关性得分: {score:.6f}\")\n",
        "        else:\n",
        "            print(\"未找到匹配结果\")\n",
        "            \n",
        "    finally:\n",
        "        # 清理资源，关闭数据库连接\n",
        "        conn.close()\n",
        "        print(\"\\nDuckDB连接已关闭\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_chinese_fts_demo()  # 执行中文FTS演示程序"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
