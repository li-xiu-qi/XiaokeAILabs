#!/usr/bin/env python3
"""
ReAct æ™ºèƒ½ä½“ V6 - AI æ™ºèƒ½åˆ¤æ–­å·¥å…·é€‰æ‹©
åŸºäº MCP å·¥å…·çš„ååº”å¼æ¨ç†æ™ºèƒ½ä½“ï¼Œä½¿ç”¨ AI æ™ºèƒ½åˆ¤æ–­æ˜¯å¦ä½¿ç”¨å·¥å…·
å®ç° Reasoning and Acting æ¨¡å¼ï¼šæ€è€ƒ -> è¡ŒåŠ¨ -> è§‚å¯Ÿ -> å†æ€è€ƒ
æ ¸å¿ƒæ”¹è¿›ï¼šç§»é™¤ç®€å•å…³é”®è¯åŒ¹é…ï¼Œä½¿ç”¨ AI è¿›è¡Œæ™ºèƒ½å·¥å…·é€‰æ‹©åˆ¤æ–­
"""

import os
import json
import requests
import asyncio
import re
from dotenv import load_dotenv
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class ReActAgentV6:
    def __init__(self):
        self.api_key = os.getenv("GUIJI_API_KEY")
        self.base_url = os.getenv("GUIJI_BASE_URL")
        self.model = os.getenv("GUIJI_MODEL")
        self.mcp_session = None
        self.available_tools = {}
        self.max_iterations = 10
        
    async def start_mcp_connection(self):
        """å¯åŠ¨ MCP è¿æ¥"""
        server_params = StdioServerParameters(
            command="python",
            args=["mcp_tools_server.py"],
        )
        
        self.server_connection = stdio_client(server_params)
        self.read, self.write = await self.server_connection.__aenter__()
        self.mcp_session = ClientSession(self.read, self.write)
        await self.mcp_session.__aenter__()
        await self.mcp_session.initialize()
        
        # è·å–å¯ç”¨å·¥å…·
        tools = await self.mcp_session.list_tools()
        for tool in tools.tools:
            self.available_tools[tool.name] = tool.description
            
        print(f"âœ… MCP å·¥å…·æœåŠ¡å™¨å·²è¿æ¥ï¼Œå¯ç”¨å·¥å…·: {list(self.available_tools.keys())}")
    
    async def call_mcp_tool(self, tool_name: str, arguments: dict) -> str:
        """è°ƒç”¨ MCP å·¥å…·"""
        try:
            result = await self.mcp_session.call_tool(tool_name, arguments)
            return result.content[0].text
        except Exception as e:
            return f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}"
    
    def analyze_need_tools_with_ai(self, user_message: str) -> dict:
        """ä½¿ç”¨ AI åˆ†ææ˜¯å¦éœ€è¦å·¥å…·ä»¥åŠéœ€è¦å“ªäº›å·¥å…·"""
        tools_description = "\n".join([f"- {name}: {desc}" for name, desc in self.available_tools.items()])
        
        analysis_prompt = f"""ä½ æ˜¯ä¸€ä¸ªå·¥å…·é€‰æ‹©åˆ†æä¸“å®¶ã€‚è¯·åˆ†æç”¨æˆ·è¯·æ±‚æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·ï¼Œä»¥åŠéœ€è¦ä½¿ç”¨å“ªäº›å·¥å…·ã€‚

ğŸ”§ å¯ç”¨å·¥å…·ï¼š
{tools_description}

ğŸ¯ ç”¨æˆ·è¯·æ±‚ï¼š{user_message}

è¯·åˆ†æä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š
1. ç”¨æˆ·è¯·æ±‚æ˜¯å¦å¯ä»¥ç›´æ¥å›ç­”ï¼Œæ— éœ€å·¥å…·ï¼Ÿ
2. å¦‚æœéœ€è¦å·¥å…·ï¼Œå…·ä½“éœ€è¦å“ªäº›å·¥å…·ï¼Ÿ
3. å·¥å…·ä½¿ç”¨çš„ä¼˜å…ˆçº§é¡ºåºæ˜¯ä»€ä¹ˆï¼Ÿ

è¯·ä»¥ JSON æ ¼å¼å›å¤ï¼š
{{
    "need_tools": true/false,
    "reason": "åˆ†æåŸå› ",
    "suggested_tools": ["tool1", "tool2", ...],
    "can_answer_directly": true/false,
    "direct_answer_confidence": 0.0-1.0
}}

æ³¨æ„ï¼š
- å¦‚æœæ˜¯å¸¸è¯†æ€§é—®é¢˜ã€ä¸€èˆ¬æ€§çŸ¥è¯†é—®ç­”ï¼Œå¯ä»¥ç›´æ¥å›ç­”
- å¦‚æœéœ€è¦å®æ—¶ä¿¡æ¯ã€è®¡ç®—ã€æ–‡ä»¶æ“ä½œã€å‘½ä»¤æ‰§è¡Œç­‰ï¼Œéœ€è¦ä½¿ç”¨å·¥å…·
- åªæ¨èç¡®å®å­˜åœ¨çš„å·¥å…·åç§°"""

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        messages = [
            {"role": "system", "content": analysis_prompt},
            {"role": "user", "content": f"è¯·åˆ†æè¿™ä¸ªè¯·æ±‚ï¼š{user_message}"}
        ]
        
        data = {
            "model": self.model,
            "messages": messages,
            "temperature": 0.1,
            "max_tokens": 500
        }
        
        try:
            response = requests.post(f"{self.base_url}/chat/completions", 
                                   headers=headers, json=data, timeout=30)
            if response.status_code == 200:
                ai_response = response.json()["choices"][0]["message"]["content"]
                # å°è¯•è§£æ JSON
                try:
                    # æå– JSON éƒ¨åˆ†
                    json_match = re.search(r'\{.*\}', ai_response, re.DOTALL)
                    if json_match:
                        json_str = json_match.group()
                        analysis_result = json.loads(json_str)
                        return analysis_result
                    else:
                        return {
                            "need_tools": False,
                            "reason": "æ— æ³•è§£æAIåˆ†æç»“æœ",
                            "suggested_tools": [],
                            "can_answer_directly": True,
                            "direct_answer_confidence": 0.5
                        }
                except json.JSONDecodeError:
                    return {
                        "need_tools": False,
                        "reason": f"AIåˆ†æç»“æœè§£æå¤±è´¥: {ai_response}",
                        "suggested_tools": [],
                        "can_answer_directly": True,
                        "direct_answer_confidence": 0.5
                    }
            else:
                return {
                    "need_tools": False,
                    "reason": f"AIåˆ†æè¯·æ±‚å¤±è´¥: {response.status_code}",
                    "suggested_tools": [],
                    "can_answer_directly": True,
                    "direct_answer_confidence": 0.5
                }
        except Exception as e:
            return {
                "need_tools": False,
                "reason": f"AIåˆ†æé”™è¯¯: {str(e)}",
                "suggested_tools": [],
                "can_answer_directly": True,
                "direct_answer_confidence": 0.5
            }
            
    def call_ai_with_react_prompt(self, user_message: str, conversation_history: list, is_first_turn: bool = False, tool_analysis: dict = None) -> str:
        """ä½¿ç”¨ ReAct æç¤ºè¯è°ƒç”¨ AI - AI æ™ºèƒ½åˆ¤æ–­ç‰ˆæœ¬"""
        tools_description = "\n".join([f"- {name}: {desc}" for name, desc in self.available_tools.items()])
        
        if is_first_turn:
            # ç¬¬ä¸€è½®ï¼šåŸºäº AI åˆ†æç»“æœå†³å®šç­–ç•¥
            analysis_info = ""
            if tool_analysis:
                analysis_info = f"""
ğŸ¤– AI å·¥å…·éœ€æ±‚åˆ†æç»“æœï¼š
- æ˜¯å¦éœ€è¦å·¥å…·ï¼š{tool_analysis.get('need_tools', False)}
- åˆ†æåŸå› ï¼š{tool_analysis.get('reason', '')}
- å»ºè®®å·¥å…·ï¼š{tool_analysis.get('suggested_tools', [])}
- å¯ç›´æ¥å›ç­”ï¼š{tool_analysis.get('can_answer_directly', False)}
- ç›´æ¥å›ç­”ä¿¡å¿ƒåº¦ï¼š{tool_analysis.get('direct_answer_confidence', 0.0)}
"""

            system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªåŸºäºå·¥å…·çš„ReActæ™ºèƒ½åŠ©æ‰‹ï¼Œæ“…é•¿é€šè¿‡å·¥å…·è·å–å‡†ç¡®ä¿¡æ¯æ¥è§£å†³é—®é¢˜ã€‚

ğŸ”§ å¯ç”¨å·¥å…·ï¼š
{tools_description}

ğŸ¯ ç”¨æˆ·è¯·æ±‚ï¼š{user_message}
{analysis_info}

ğŸ“‹ ReActå·¥ä½œæµç¨‹ï¼š
1. Thought: åˆ†æé—®é¢˜ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦å·¥å…·
2. Action: å¦‚æœéœ€è¦å·¥å…·ï¼Œæ‰§è¡Œä¸€ä¸ªå·¥å…·è·å–ä¿¡æ¯
3. Observation: è§‚å¯Ÿå·¥å…·è¿”å›ç»“æœ
4. é‡å¤1-3ç›´åˆ°æœ‰è¶³å¤Ÿä¿¡æ¯
5. Final Answer: åŸºäºå·²æœ‰ä¿¡æ¯ç»™å‡ºå®Œæ•´ç­”æ¡ˆ

âš ï¸ é‡è¦è§„åˆ™ï¼š
- å‚è€ƒAIåˆ†æç»“æœï¼Œä½†æœ€ç»ˆå†³ç­–æƒåœ¨ä½ 
- å¦‚æœé—®é¢˜å¯ä»¥ç›´æ¥å›ç­”ä¸”ä¸éœ€è¦å®æ—¶ä¿¡æ¯ï¼Œå¯ä»¥ç›´æ¥ç»™å‡ºç­”æ¡ˆ
- å¦‚æœéœ€è¦è·å–å®æ—¶ä¿¡æ¯ã€è®¡ç®—ã€æ–‡ä»¶æ“ä½œç­‰ï¼Œä½¿ç”¨ç›¸åº”å·¥å…·
- æ¯æ¬¡åªæ‰§è¡Œä¸€ä¸ªå·¥å…·
- å·¥å…·å‚æ•°å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼

è¾“å‡ºæ ¼å¼ï¼š
æ–¹æ¡ˆAï¼ˆä½¿ç”¨å·¥å…·ï¼‰ï¼š
Thought: [åˆ†æä¸ºä»€ä¹ˆéœ€è¦ä½¿ç”¨å·¥å…·]
Action: [å·¥å…·å] [JSONå‚æ•°]

æ–¹æ¡ˆBï¼ˆç›´æ¥å›ç­”ï¼‰ï¼š
Thought: [åˆ†æä¸ºä»€ä¹ˆå¯ä»¥ç›´æ¥å›ç­”]
Final Answer: [å®Œæ•´çš„å›ç­”]

ç°åœ¨å¼€å§‹å¤„ç†ç”¨æˆ·è¯·æ±‚ï¼"""
        else:
            # åç»­è½®æ¬¡ï¼šåŸºäºå·²æœ‰ä¿¡æ¯å†³å®šä¸‹ä¸€æ­¥
            system_prompt = f"""ç»§ç»­ReActæ¨ç†æµç¨‹ã€‚

ğŸ”§ å¯ç”¨å·¥å…·ï¼š
{tools_description}

ğŸ¯ åŸå§‹è¯·æ±‚ï¼š{user_message}

ğŸ“Š å½“å‰çŠ¶æ€åˆ†æï¼š
å›é¡¾ä¸Šä¸€æ­¥çš„ Observationã€‚æ ¹æ®å·²æ‰§è¡Œçš„å·¥å…·å’Œè·å¾—çš„ä¿¡æ¯ï¼Œç°åœ¨éœ€è¦åˆ¤æ–­ï¼š

æ–¹æ¡ˆA - ç»§ç»­ä½¿ç”¨å·¥å…·ï¼ˆå¦‚æœéœ€è¦æ›´å¤šä¿¡æ¯ï¼‰ï¼š
Thought: [åˆ†æä¸ºä»€ä¹ˆè¿˜éœ€è¦æ›´å¤šä¿¡æ¯ï¼Œä»¥åŠéœ€è¦å“ªä¸ªå·¥å…·æ¥è·å–è¿™äº›ä¿¡æ¯ã€‚]
Action: [å·¥å…·å] [JSONå‚æ•°]

æ–¹æ¡ˆB - ç»™å‡ºæœ€ç»ˆç­”æ¡ˆï¼ˆå¦‚æœä¿¡æ¯å·²è¶³å¤Ÿï¼‰:
Thought: [åˆ†æå·²æœ‰ä¿¡æ¯æ˜¯å¦è¶³å¤Ÿå›ç­”ç”¨æˆ·é—®é¢˜ã€‚ç¡®è®¤ä¿¡æ¯å·²è¶³å¤Ÿã€‚]
Final Answer: [åŸºäºå·²æœ‰ä¿¡æ¯çš„å®Œæ•´ã€å‡†ç¡®ç­”æ¡ˆã€‚]

âš ï¸ å†³ç­–æ ‡å‡†ï¼š
- å¦‚æœå·²æœ‰ä¿¡æ¯è¶³å¤Ÿå›ç­”ç”¨æˆ·é—®é¢˜ï¼Œç›´æ¥é€‰æ‹©æ–¹æ¡ˆB
- å¦‚æœç¡®å®è¿˜éœ€è¦è·å–æ–°ä¿¡æ¯ï¼Œé€‰æ‹©æ–¹æ¡ˆA
- ç­”æ¡ˆå¿…é¡»åŸºäºçœŸå®çš„å·¥å…·ç»“æœï¼Œä¸èƒ½ç¼–é€ 

è¯·é€‰æ‹©åˆé€‚çš„æ–¹æ¡ˆå¹¶æ‰§è¡Œï¼š"""

        # æ„å»ºå¯¹è¯å†å²
        messages = [{"role": "system", "content": system_prompt}]
        
        # æ·»åŠ å¯¹è¯å†å²
        for entry in conversation_history:
            messages.append({"role": "user", "content": entry["content"]})
        
        # å¦‚æœä¸æ˜¯ç¬¬ä¸€è½®ï¼Œæ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        if not is_first_turn:
            messages.append({"role": "user", "content": "åŸºäºä¸Šè¿°å·¥å…·æ‰§è¡Œç»“æœï¼Œç»§ç»­æ¨ç†ã€‚"})
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": self.model,
            "messages": messages,
            "temperature": 0.1,
            "max_tokens": 1000
        }
        
        try:
            response = requests.post(f"{self.base_url}/chat/completions", 
                                   headers=headers, json=data, timeout=30)
            if response.status_code == 200:
                return response.json()["choices"][0]["message"]["content"]
            else:
                return f"API è°ƒç”¨å¤±è´¥: {response.status_code}"
        except Exception as e:
            return f"API é”™è¯¯: {str(e)}"
    
    def parse_react_response(self, response: str) -> dict:
        """è§£æ ReAct å“åº”"""
        result = {
            "thought": "",
            "action": None,
            "action_params": {},
            "final_answer": "",
            "type": "unknown"
        }
        
        lines = response.strip().split('\n')
        current_section = None
        
        for line in lines:
            line = line.strip()
            if line.startswith("Thought:"):
                current_section = "thought"
                result["thought"] = line[8:].strip()
                result["type"] = "thought"
            elif line.startswith("Action:"):
                current_section = "action"
                action_content = line[7:].strip()
                # è§£æ Action: tool_name {params}
                parts = action_content.split(' ', 1)
                if len(parts) >= 1:
                    result["action"] = parts[0]
                    if len(parts) > 1:
                        try:
                            result["action_params"] = json.loads(parts[1])
                        except:
                            result["action_params"] = {}
                result["type"] = "action"
            elif line.startswith("Final Answer:"):
                current_section = "final"
                result["final_answer"] = line[13:].strip()
                result["type"] = "final"
            elif current_section and line:
                if current_section == "thought":
                    result["thought"] += " " + line
                elif current_section == "final":
                    result["final_answer"] += " " + line
        
        return result
    
    async def react_reasoning_loop(self, user_message: str) -> str:
        """æ‰§è¡Œ ReAct æ¨ç†å¾ªç¯ - AI æ™ºèƒ½åˆ¤æ–­ç‰ˆæœ¬"""
        conversation_history = []
        iteration = 0
        
        print(f"\nğŸ¤– å¼€å§‹ ReAct æ¨ç†å¾ªç¯å¤„ç† (AIæ™ºèƒ½åˆ¤æ–­ V6): {user_message}\n")
        
        # ä½¿ç”¨ AI åˆ†ææ˜¯å¦éœ€è¦å·¥å…·
        print("ğŸ§  æ­£åœ¨è¿›è¡Œ AI å·¥å…·éœ€æ±‚åˆ†æ...")
        tool_analysis = self.analyze_need_tools_with_ai(user_message)
        print(f"ğŸ¯ AI åˆ†æç»“æœ: {tool_analysis}")
        
        while iteration < self.max_iterations:
            iteration += 1
            print(f"ğŸ”„ ç¬¬ {iteration} è½®æ¨ç†")
            
            is_first_turn = (iteration == 1)
            ai_response = self.call_ai_with_react_prompt(user_message, conversation_history, is_first_turn, tool_analysis if is_first_turn else None)
            parsed = self.parse_react_response(ai_response)
            
            print(f"ğŸ’­ Thought: {parsed['thought']}")
            
            if parsed["type"] == "final":
                print(f"âœ… Final Answer: {parsed['final_answer']}\n")
                return parsed['final_answer']
            
            elif parsed["type"] == "action":
                action_name = parsed["action"]
                action_params = parsed["action_params"]
                
                print(f"ğŸ”§ Action: {action_name} {json.dumps(action_params, ensure_ascii=False)}")
                
                if action_name in self.available_tools:
                    tool_result = await self.call_mcp_tool(action_name, action_params)
                    print(f"ğŸ‘ï¸ Observation: {tool_result}")
                    conversation_history.append({
                        "content": f"Thought: {parsed['thought']}\nAction: {action_name} {json.dumps(action_params)}\nObservation: {tool_result}"
                    })
                else:
                    error_msg = f"å·¥å…· {action_name} ä¸å­˜åœ¨æˆ–ä¸å¯ç”¨ã€‚å¯ç”¨å·¥å…·: {list(self.available_tools.keys())}"
                    print(f"âŒ Error: {error_msg}")
                    conversation_history.append({
                        "content": f"Thought: {parsed['thought']}\nAction: {action_name} {json.dumps(action_params)}\nObservation: {error_msg}"
                    })
            else:
                # AIåªç»™å‡ºäº†æ€è€ƒï¼Œæé†’å®ƒæ‰§è¡Œå·¥å…·æˆ–ç»™å‡ºæœ€ç»ˆç­”æ¡ˆ
                print("âš ï¸ AIåªç»™å‡ºäº†æ€è€ƒï¼Œè¦æ±‚æ‰§è¡Œå·¥å…·æˆ–ç»™å‡ºæœ€ç»ˆç­”æ¡ˆ")
                conversation_history.append({
                    "content": f"ä½ åˆšæ‰åªè¿›è¡Œäº†æ€è€ƒï¼š{parsed['thought']}ï¼Œè¯·æ‰§è¡Œä¸€ä¸ªå·¥å…·æ¥è·å–ä¿¡æ¯ï¼Œæˆ–è€…åŸºäºå·²æœ‰ä¿¡æ¯ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚"
                })
            
            print()
        
        # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå°è¯•æ€»ç»“ç­”æ¡ˆ
        print(f"âš ï¸ æ¨ç†å¾ªç¯è¾¾åˆ°æœ€å¤§æ¬¡æ•° ({self.max_iterations})ï¼Œå°è¯•åŸºäºå·²æœ‰ä¿¡æ¯æ€»ç»“ç­”æ¡ˆ")
        
        summary_prompt_messages = [{"role": "system", "content": "è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯å†å²ï¼Œæ€»ç»“å‡ºä¸€ä¸ªæœ€ç»ˆç­”æ¡ˆæ¥å›åº”ç”¨æˆ·çš„åŸå§‹è¯·æ±‚ã€‚"}]
        summary_prompt_messages.append({"role": "user", "content": f"åŸå§‹è¯·æ±‚: {user_message}"})
        for entry in conversation_history:
            summary_prompt_messages.append({"role": "assistant", "content": entry["content"]})
        summary_prompt_messages.append({"role": "user", "content": "è¯·æ€»ç»“æœ€ç»ˆç­”æ¡ˆã€‚"})

        headers = {"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"}
        data = {"model": self.model, "messages": summary_prompt_messages, "temperature": 0.1, "max_tokens": 500}
        
        try:
            response = requests.post(f"{self.base_url}/chat/completions", headers=headers, json=data, timeout=30)
            if response.status_code == 200:
                summary_answer = response.json()["choices"][0]["message"]["content"]
                print(f"âœ… Final Answer (summarized): {summary_answer}\n")
                return summary_answer
            else:
                return f"æ¨ç†å¾ªç¯è¾¾åˆ°æœ€å¤§æ¬¡æ•°ï¼Œä¸”æ— æ³•ç”Ÿæˆæ€»ç»“æ€§ç­”æ¡ˆã€‚API é”™è¯¯: {response.status_code}"
        except Exception as e:
            return f"æ¨ç†å¾ªç¯è¾¾åˆ°æœ€å¤§æ¬¡æ•°ï¼Œä¸”æ€»ç»“ç­”æ¡ˆæ—¶å‘ç”ŸAPIé”™è¯¯: {str(e)}"

    async def chat(self, user_message: str) -> str:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯ - ReAct AI æ™ºèƒ½åˆ¤æ–­æ¨¡å¼ V6"""
        try:
            return await self.react_reasoning_loop(user_message)
        except Exception as e:
            return f"å¤„ç†é”™è¯¯: {str(e)}"
    
    async def close(self):
        """å…³é—­ MCP è¿æ¥"""
        if self.mcp_session:
            await self.mcp_session.__aexit__(None, None, None)
        if hasattr(self, 'server_connection'):
            await self.server_connection.__aexit__(None, None, None)

async def main():
    agent = ReActAgentV6()
    
    try:
        await agent.start_mcp_connection()
        
        print("\nğŸ§  ReAct æ™ºèƒ½ä½“ V6 å·²å¯åŠ¨ï¼(AIæ™ºèƒ½åˆ¤æ–­æ¨¡å¼)")
        print("ğŸ’¡ æˆ‘ä¼šä½¿ç”¨ AI æ™ºèƒ½åˆ†ææ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·")
        print("ğŸ“ è¾“å…¥ 'q' é€€å‡º\n")
        
        while True:
            try:
                user_input = input("ğŸ‘¤ æ‚¨: ")
                if user_input.lower() in ['q', 'quit', 'exit', 'é€€å‡º']:
                    break
                
                if not user_input.strip():
                    continue
                
                response = await agent.chat(user_input)
                print(f"ğŸ¤– æœ€ç»ˆå›ç­” (V6): {response}\n")
                print("-" * 50)
                
            except KeyboardInterrupt:
                break
            except Exception as e:
                print(f"âŒ é”™è¯¯: {str(e)}\n")
    
    finally:
        await agent.close()
        print("\nğŸ‘‹ ReAct æ™ºèƒ½ä½“ V6 å·²å…³é—­")

if __name__ == "__main__":
    asyncio.run(main())
