# 评估重排器

重排器通常能更好地捕捉句子之间的潜在语义。但与使用嵌入模型相比，它对整个数据集的运行时间是二次方级别的$O(N^2)$。因此，重排器在信息检索或RAG中最常见的用例是对根据嵌入相似度检索到的前k个答案进行重新排序。

重排器的评估思想类似。我们比较重排器能够多大程度上改进由同一个嵌入器搜索到的候选项的排序。在本教程中，我们将在BEIR基准上评估两个重排器的性能，使用bge-large-en-v1.5作为基础嵌入模型。

注意：我们强烈建议使用GPU运行此笔记本。整个流程非常耗时。为简单起见，我们仅使用BEIR中的单个任务FiQA。

## 0. 安装

首先安装所需依赖

```python
%pip install FlagEmbedding
```

## 1. bge-reranker-large

第一个模型是bge-reranker-large，一个类似BERT的重排器，约有560M参数。

我们可以使用FlagEmbedding的评估流程直接运行整个过程：

```python
%%bash
python -m FlagEmbedding.evaluation.beir \
--eval_name beir \
--dataset_dir ./beir/data \
--dataset_names fiqa \
--splits test dev \
--corpus_embd_save_dir ./beir/corpus_embd \
--output_dir ./beir/search_results \
--search_top_k 1000 \
--rerank_top_k 100 \
--cache_path /root/.cache/huggingface/hub \
--overwrite True \
--k_values 10 100 \
--eval_output_method markdown \
--eval_output_path ./beir/beir_eval_results.md \
--eval_metrics ndcg_at_10 recall_at_100 \
--ignore_identical_ids True \
--embedder_name_or_path BAAI/bge-large-en-v1.5 \
--reranker_name_or_path BAAI/bge-reranker-large \
--embedder_batch_size 1024 \
--reranker_batch_size 1024 \
--devices cuda:0 \
```

输出:

```
Split 'dev' not found in the dataset. Removing it from the list.
ignore_identical_ids is set to True. This means that the search results will not contain identical ids. Note: Dataset such as MIRACL should NOT set this to True.
pre tokenize: 100%|██████████| 57/57 [00:03<00:00, 14.68it/s]
You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/share/project/xzy/Envs/ft/lib/python3.11/site-packages/_distutils_hack/__init__.py:54: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(
Inference Embeddings: 100%|██████████| 57/57 [00:44<00:00,  1.28it/s]
pre tokenize: 100%|██████████| 1/1 [00:00<00:00, 61.59it/s]
Inference Embeddings: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]
Searching: 100%|██████████| 21/21 [00:00<00:00, 68.26it/s]
pre tokenize:   0%|          | 0/64 [00:00<?, ?it/s]You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
pre tokenize: 100%|██████████| 64/64 [00:08<00:00,  7.15it/s]
Compute Scores: 100%|██████████| 64/64 [01:39<00:00,  1.56s/it]

```

## 2. bge-reranker-v2-gemma

第二个模型是bge-reranker-v2-m3

```python
%%bash
python -m FlagEmbedding.evaluation.beir \
--eval_name beir \
--dataset_dir ./beir/data \
--dataset_names fiqa \
--splits test dev \
--corpus_embd_save_dir ./beir/corpus_embd \
--output_dir ./beir/search_results \
--search_top_k 1000 \
--rerank_top_k 100 \
--cache_path /root/.cache/huggingface/hub \
--overwrite True \
--k_values 10 100 \
--eval_output_method markdown \
--eval_output_path ./beir/beir_eval_results.md \
--eval_metrics ndcg_at_10 recall_at_100 \
--ignore_identical_ids True \
--embedder_name_or_path BAAI/bge-large-en-v1.5 \
--reranker_name_or_path BAAI/bge-reranker-v2-m3 \
--embedder_batch_size 1024 \
--reranker_batch_size 1024 \
--devices cuda:0 cuda:1 cuda:2 cuda:3 \
--reranker_max_length 1024 \
```

输出:

```
Split 'dev' not found in the dataset. Removing it from the list.
ignore_identical_ids is set to True. This means that the search results will not contain identical ids. Note: Dataset such as MIRACL should NOT set this to True.
initial target device: 100%|██████████| 4/4 [01:14<00:00, 18.51s/it]
pre tokenize: 100%|██████████| 15/15 [00:01<00:00, 11.21it/s]
You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
pre tokenize: 100%|██████████| 15/15 [00:01<00:00, 11.32it/s]
You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
pre tokenize: 100%|██████████| 15/15 [00:01<00:00, 10.29it/s]
You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
pre tokenize: 100%|██████████| 15/15 [00:01<00:00, 13.99it/s]
You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/share/project/xzy/Envs/ft/lib/python3.11/site-packages/_distutils_hack/__init__.py:54: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(
/share/project/xzy/Envs/ft/lib/python3.11/site-packages/_distutils_hack/__init__.py:54: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(
/share/project/xzy/Envs/ft/lib/python3.11/site-packages/_distutils_hack/__init__.py:54: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(
/share/project/xzy/Envs/ft/lib/python3.11/site-packages/_distutils_hack/__init__.py:54: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(
Inference Embeddings: 100%|██████████| 15/15 [00:12<00:00,  1.24it/s]
Inference Embeddings: 100%|██████████| 15/15 [00:12<00:00,  1.23it/s]
Inference Embeddings: 100%|██████████| 15/15 [00:12<00:00,  1.22it/s]
Inference Embeddings: 100%|██████████| 15/15 [00:12<00:00,  1.21it/s]
Chunks: 100%|██████████| 4/4 [00:30<00:00,  7.70s/it]
Chunks: 100%|██████████| 4/4 [00:00<00:00, 47.90it/s]
Searching: 100%|██████████| 21/21 [00:00<00:00, 128.34it/s]
initial target device: 100%|██████████| 4/4 [01:09<00:00, 17.43s/it]
pre tokenize:   0%|          | 0/16 [00:00<?, ?it/s]You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
pre tokenize:  12%|█▎        | 2/16 [00:00<00:02,  6.46it/s]You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
pre tokenize:  12%|█▎        | 2/16 [00:00<00:03,  4.60it/s]You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
pre tokenize:  25%|██▌       | 4/16 [00:00<00:02,  4.61it/s]You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
pre tokenize: 100%|██████████| 16/16 [00:03<00:00,  4.12it/s]
pre tokenize: 100%|██████████| 16/16 [00:04<00:00,  3.78it/s]
pre tokenize: 100%|██████████| 16/16 [00:04<00:00,  3.95it/s]
pre tokenize: 100%|██████████| 16/16 [00:04<00:00,  3.81it/s]
Compute Scores: 100%|██████████| 67/67 [00:29<00:00,  2.30it/s]
Compute Scores: 100%|██████████| 67/67 [00:29<00:00,  2.27it/s]
Compute Scores: 100%|██████████| 67/67 [00:29<00:00,  2.27it/s]
Compute Scores: 100%|██████████| 67/67 [00:30<00:00,  2.19it/s]
Chunks: 100%|██████████| 4/4 [00:51<00:00, 12.97s/it]
/share/project/xzy/Envs/ft/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 8 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '

```

## 3. 比较

```python
import json

with open('beir/search_results/bge-large-en-v1.5/bge-reranker-large/EVAL/eval_results.json') as f:
    results_1 = json.load(f)
    print(results_1)
    
with open('beir/search_results/bge-large-en-v1.5/bge-reranker-v2-m3/EVAL/eval_results.json') as f:
    results_2 = json.load(f)
    print(results_2)
```

输出:

```
{'fiqa-test': {'ndcg_at_10': 0.40991, 'ndcg_at_100': 0.48028, 'map_at_10': 0.32127, 'map_at_100': 0.34227, 'recall_at_10': 0.50963, 'recall_at_100': 0.75987, 'precision_at_10': 0.11821, 'precision_at_100': 0.01932, 'mrr_at_10': 0.47786, 'mrr_at_100': 0.4856}}
{'fiqa-test': {'ndcg_at_10': 0.44828, 'ndcg_at_100': 0.51525, 'map_at_10': 0.36551, 'map_at_100': 0.38578, 'recall_at_10': 0.519, 'recall_at_100': 0.75987, 'precision_at_10': 0.12299, 'precision_at_100': 0.01932, 'mrr_at_10': 0.53382, 'mrr_at_100': 0.54108}}

```

从上述结果可以看出，bge-reranker-v2-m3在几乎所有指标上都具有优势。
