# 重排器（Reranker）

重排器采用交叉编码器（cross-encoder）架构设计，同时接收查询和文本作为输入，并直接输出它们的相似度得分。它在评估查询-文本相关性方面能力更强，但代价是速度较慢。因此，一个完整的检索系统通常在第一阶段包含检索器进行大范围检索，然后使用重排器对结果进行更精确的重新排序。

在本教程中，我们将介绍带有重排器的文本检索流程，并评估重排前后的结果。

注意：步骤1-4与[评估](https://github.com/FlagOpen/FlagEmbedding/tree/master/Tutorials/4_Evaluation)教程相同。如果您不熟悉检索，我们建议先阅读该教程。

## 0. 设置

在环境中安装依赖项。

```python
%pip install -U FlagEmbedding faiss-cpu
```

## 1. 数据集

下载并预处理MS Marco数据集

```python
from datasets import load_dataset
import numpy as np

data = load_dataset("namespace-Pt/msmarco", split="dev")
```

```python
queries = np.array(data[:100]["query"])
corpus = sum(data[:5000]["positive"], [])
```

## 2. 嵌入

```python
from FlagEmbedding import FlagModel

# 获取BGE嵌入模型
model = FlagModel('BAAI/bge-base-en-v1.5',
                  query_instruction_for_retrieval="Represent this sentence for searching relevant passages:",
                  use_fp16=True)

# 获取语料库的嵌入
corpus_embeddings = model.encode(corpus)

print("语料库嵌入的形状：", corpus_embeddings.shape)
print("嵌入的数据类型：", corpus_embeddings.dtype)
```

输出:

```
Inference Embeddings: 100%|██████████| 21/21 [01:59<00:00,  5.68s/it]
```

输出:

```
语料库嵌入的形状： (5331, 768)
嵌入的数据类型： float32

```

输出:

```


```

## 3. 建立索引

```python
import faiss

# 获取嵌入向量的长度，bge-base-en-v1.5生成的向量长度为768
dim = corpus_embeddings.shape[-1]

# 创建faiss索引并将语料库嵌入存储到向量空间中
index = faiss.index_factory(dim, 'Flat', faiss.METRIC_INNER_PRODUCT)
corpus_embeddings = corpus_embeddings.astype(np.float32)
index.train(corpus_embeddings)
index.add(corpus_embeddings)

print(f"向量总数：{index.ntotal}")
```

输出:

```
向量总数：5331

```

## 4. 检索

```python
query_embeddings = model.encode_queries(queries)
ground_truths = [d["positive"] for d in data]
corpus = np.asarray(corpus)
```

```python
from tqdm import tqdm

res_scores, res_ids, res_text = [], [], []
query_size = len(query_embeddings)
batch_size = 256
# 我们将在评估中使用的截断点，并将k设置为截断点的最大值。
cut_offs = [1, 10]
k = max(cut_offs)

for i in tqdm(range(0, query_size, batch_size), desc="Searching"):
    q_embedding = query_embeddings[i: min(i+batch_size, query_size)].astype(np.float32)
    # 为每个查询搜索前k个答案
    score, idx = index.search(q_embedding, k=k)
    res_scores += list(score)
    res_ids += list(idx)
    res_text += list(corpus[idx])
```

输出:

```
Searching: 100%|██████████| 1/1 [00:00<00:00, 22.35it/s]

```

## 5. 重排序

现在我们将使用重排器对通过索引检索到的答案列表进行重新排序。希望这将带来更好的结果。

下表列出了可用的BGE重排器。欢迎尝试它们以了解它们之间的差异！

| 模型  | 语言 |   参数量   |    描述    |   基础模型     |
|:-------|:--------:|:----:|:-----------------:|:--------------------------------------:|
| [BAAI/bge-reranker-v2-m3](https://huggingface.co/BAAI/bge-reranker-v2-m3) | 多语言 |     568M     | 轻量级交叉编码器模型，具有强大的多语言能力，易于部署，推理速度快。 | XLM-RoBERTa-Large |
| [BAAI/bge-reranker-v2-gemma](https://huggingface.co/BAAI/bge-reranker-v2-gemma) | 多语言 |     2.51B     | 适用于多语言环境的交叉编码器模型，在英语熟练度和多语言能力方面表现良好。 | Gemma2-2B |
| [BAAI/bge-reranker-v2-minicpm-layerwise](https://huggingface.co/BAAI/bge-reranker-v2-minicpm-layerwise) | 多语言 |    2.72B    | 适用于多语言环境的交叉编码器模型，在英语和中文熟练度方面表现良好，允许自由选择层输出，促进加速推理。 | MiniCPM |
| [BAAI/bge-reranker-v2.5-gemma2-lightweight](https://huggingface.co/BAAI/bge-reranker-v2.5-gemma2-lightweight) | 多语言 |    9.24B    | 适用于多语言环境的交叉编码器模型，在英语和中文熟练度方面表现良好，允许自由选择层、压缩比和压缩层输出，促进加速推理。 | Gemma2-9B |
| [BAAI/bge-reranker-large](https://huggingface.co/BAAI/bge-reranker-large) | 中文和英文 |     560M     | 交叉编码器模型，更准确但效率较低 | XLM-RoBERTa-Large |
| [BAAI/bge-reranker-base](https://huggingface.co/BAAI/bge-reranker-base) | 中文和英文 |     278M     | 交叉编码器模型，更准确但效率较低 | XLM-RoBERTa-Base |

首先，让我们用一个小例子看看重排器是如何工作的：

```python
from FlagEmbedding import FlagReranker

reranker = FlagReranker('BAAI/bge-reranker-large', use_fp16=True) 
# 设置use_fp16为True可以加速计算，但性能会略有下降

# 使用compute_score()函数计算每个输入句子对的得分
scores = reranker.compute_score([
    ['what is panda?', 'Today is a sunny day'], 
    ['what is panda?', 'The tiger (Panthera tigris) is a member of the genus Panthera and the largest living cat species native to Asia.'],
    ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']
    ])
print(scores)
```

输出:

```
[-9.474676132202148, -2.823843240737915, 5.76226806640625]

```

现在，让我们使用重排器对之前检索到的结果进行重新排序：

```python
new_ids, new_scores, new_text = [], [], []
for i in range(len(queries)):
    # 获取之前检索结果的新得分
    new_score = reranker.compute_score([[queries[i], text] for text in res_text[i]])
    # 按新得分对ID和得分列表进行排序
    new_id = [tup[1] for tup in sorted(list(zip(new_score, res_ids[i])), reverse=True)]
    new_scores.append(sorted(new_score, reverse=True))
    new_ids.append(new_id)
    new_text.append(corpus[new_id])
```

## 6. 评估

关于这些指标的详细信息，请查看[评估](https://github.com/FlagOpen/FlagEmbedding/tree/master/Tutorials/4_Evaluation)教程。

### 6.1 召回率（Recall）

```python
def calc_recall(preds, truths, cutoffs):
    recalls = np.zeros(len(cutoffs))
    for text, truth in zip(preds, truths):
        for i, c in enumerate(cutoffs):
            recall = np.intersect1d(truth, text[:c])
            recalls[i] += len(recall) / max(min(len(recall), len(truth)), 1)
    recalls /= len(preds)
    return recalls
```

重排序前：

```python
recalls_init = calc_recall(res_text, ground_truths, cut_offs)
for i, c in enumerate(cut_offs):
    print(f"recall@{c}:\t{recalls_init[i]}")
```

输出:

```
recall@1:	0.97
recall@10:	1.0

```

重排序后：

```python
recalls_rerank = calc_recall(new_text, ground_truths, cut_offs)
for i, c in enumerate(cut_offs):
    print(f"recall@{c}:\t{recalls_rerank[i]}")
```

输出:

```
recall@1:	0.99
recall@10:	1.0

```

### 6.2 平均倒数排名（MRR）

```python
def MRR(preds, truth, cutoffs):
    mrr = [0 for _ in range(len(cutoffs))]
    for pred, t in zip(preds, truth):
        for i, c in enumerate(cutoffs):
            for j, p in enumerate(pred):
                if j < c and p in t:
                    mrr[i] += 1/(j+1)
                    break
    mrr = [k/len(preds) for k in mrr]
    return mrr
```

重排序前：

```python
mrr_init = MRR(res_text, ground_truths, cut_offs)
for i, c in enumerate(cut_offs):
    print(f"MRR@{c}:\t{mrr_init[i]}")
```

输出:

```
MRR@1:	0.97
MRR@10:	0.9825

```

重排序后：

```python
mrr_rerank = MRR(new_text, ground_truths, cut_offs)
for i, c in enumerate(cut_offs):
    print(f"MRR@{c}:\t{mrr_rerank[i]}")
```

输出:

```
MRR@1:	0.99
MRR@10:	0.995

```

### 6.3 归一化折损累积增益（nDCG）

重排序前：

```python
from sklearn.metrics import ndcg_score

pred_hard_encodings = []
for pred, label in zip(res_text, ground_truths):
    pred_hard_encoding = list(np.isin(pred, label).astype(int))
    pred_hard_encodings.append(pred_hard_encoding)

for i, c in enumerate(cut_offs):
    nDCG = ndcg_score(pred_hard_encodings, res_scores, k=c)
    print(f"nDCG@{c}: {nDCG}")
```

输出:

```
nDCG@1: 0.97
nDCG@10: 0.9869253606521631

```

重排序后：

```python
pred_hard_encodings_rerank = []
for pred, label in zip(new_text, ground_truths):
    pred_hard_encoding = list(np.isin(pred, label).astype(int))
    pred_hard_encodings_rerank.append(pred_hard_encoding)

for i, c in enumerate(cut_offs):
    nDCG = ndcg_score(pred_hard_encodings_rerank, new_scores, k=c)
    print(f"nDCG@{c}: {nDCG}")
```

输出:

```
nDCG@1: 0.99
nDCG@10: 0.9963092975357145

```
